#!/usr/bin/env python3
"""
æœ€ç»ˆçš„é¡µé¢åˆ†å‰²æµ‹è¯•è„šæœ¬
ç¡®ä¿ç»“æœä¿å­˜åˆ°parser_outputç›®å½•ï¼Œå¹¶åŒ…å«å®Œæ•´çš„æ–‡ä»¶ç»“æ„
"""

import os
import sys
import json
import tempfile
import shutil
import datetime
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent.absolute()))

from src.pdf_processing.pdf_parser_tool import PDFParserTool

def create_parser_output_directory():
    """åˆ›å»ºparser_outputç›®å½•"""
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    output_dir = f"parser_output/{timestamp}_page_split"
    os.makedirs(output_dir, exist_ok=True)
    return output_dir

def test_page_split_final():
    """
    æœ€ç»ˆçš„é¡µé¢åˆ†å‰²æµ‹è¯•
    """
    print("ğŸ¯ æœ€ç»ˆé¡µé¢åˆ†å‰²æµ‹è¯• - å®Œæ•´æ–‡ä»¶ç»“æ„")
    print("=" * 60)
    
    # æµ‹è¯•PDFæ–‡ä»¶
    test_pdf = "testfiles/åŒ»çµå¤åº™è®¾è®¡æ–¹æ¡ˆ.pdf"
    
    if not os.path.exists(test_pdf):
        print(f"âŒ æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {test_pdf}")
        return
    
    # åˆ›å»ºè§£æå™¨
    parser = PDFParserTool()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = create_parser_output_directory()
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    
    # æµ‹è¯•é¡µé¢åˆ†å‰²æ–¹æ³•
    print("\nğŸš€ å¼€å§‹é¡µé¢åˆ†å‰²å¤„ç†...")
    print("-" * 40)
    
    try:
        # ç¦ç”¨å¹¶è¡Œå¤„ç†ä»¥é¿å…PyTorché”™è¯¯
        result = parser.execute(
            action="parse_page_split",
            pdf_path=test_pdf,
            output_dir=output_dir,
            enable_ai_enhancement=False,
            parallel_processing=False  # ç¦ç”¨å¹¶è¡Œå¤„ç†é¿å…PyTorché”™è¯¯
        )
        
        print("âœ… é¡µé¢åˆ†å‰²å¤„ç†å®Œæˆ")
        
        # è§£æç»“æœ
        result_data = json.loads(result)
        
        if result_data.get("status") == "success":
            pages_count = result_data.get('pages_count', 0)
            processing_time = result_data.get('processing_time', 0)
            
            print(f"ğŸ“Š æˆåŠŸå¤„ç†äº† {pages_count} ä¸ªé¡µé¢")
            print(f"â±ï¸ å¤„ç†æ—¶é—´: {processing_time:.2f} ç§’")
            
            # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶ç»“æ„
            print("\nğŸ“‚ æ£€æŸ¥è¾“å‡ºæ–‡ä»¶ç»“æ„:")
            
            # 1. æ£€æŸ¥JSONç»“æœæ–‡ä»¶
            json_file = os.path.join(output_dir, "page_split_processing_result.json")
            if os.path.exists(json_file):
                print(f"  âœ… JSONç»“æœæ–‡ä»¶: {json_file}")
                with open(json_file, 'r', encoding='utf-8') as f:
                    json_data = json.load(f)
                    print(f"     ğŸ“Š åŒ…å« {len(json_data.get('pages', []))} ä¸ªé¡µé¢æ•°æ®")
            else:
                print(f"  âŒ JSONç»“æœæ–‡ä»¶ä¸å­˜åœ¨: {json_file}")
            
            # 2. æ£€æŸ¥å›¾ç‰‡æ–‡ä»¶
            image_count = 0
            table_count = 0
            pages = result_data.get("pages", [])
            
            for page in pages:
                for img in page.get("images", []):
                    image_path = img.get("image_path", "")
                    if image_path and os.path.exists(image_path):
                        image_count += 1
                
                for table in page.get("tables", []):
                    table_path = table.get("table_path", "")
                    if table_path and os.path.exists(table_path):
                        table_count += 1
            
            print(f"  ğŸ“¸ å›¾ç‰‡æ–‡ä»¶: {image_count} ä¸ª")
            print(f"  ğŸ“Š è¡¨æ ¼æ–‡ä»¶: {table_count} ä¸ª")
            
            # 3. éªŒè¯é¡µç æ ‡æ³¨å‡†ç¡®æ€§
            print("\nğŸ” é¡µç æ ‡æ³¨å‡†ç¡®æ€§éªŒè¯:")
            accurate_count = 0
            failed_count = 0
            
            for i, page in enumerate(pages):
                expected_page = i + 1
                actual_page = page.get('page_number', 'N/A')
                raw_text = page.get('raw_text', '')
                
                if "å¤„ç†å¤±è´¥" in raw_text:
                    failed_count += 1
                    print(f"  é¡µé¢ {expected_page}: âš ï¸ å¤„ç†å¤±è´¥ï¼ˆPyTorché”™è¯¯ï¼‰")
                elif actual_page == expected_page:
                    accurate_count += 1
                    print(f"  é¡µé¢ {expected_page}: âœ… å‡†ç¡®")
                else:
                    print(f"  é¡µé¢ {expected_page}: âŒ æ ‡æ³¨ä¸º {actual_page}")
            
            success_count = accurate_count + failed_count
            accuracy_rate = (accurate_count / success_count) * 100 if success_count > 0 else 0
            
            print(f"\nğŸ“Š å¤„ç†ç»Ÿè®¡:")
            print(f"  âœ… æˆåŠŸé¡µé¢: {accurate_count}")
            print(f"  âš ï¸ å¤±è´¥é¡µé¢: {failed_count} (PyTorchå¹¶è¡Œé”™è¯¯)")
            print(f"  ğŸ“ˆ å‡†ç¡®ç‡: {accuracy_rate:.1f}% ({accurate_count}/{success_count})")
            
            # 4. æ˜¾ç¤ºæˆåŠŸé¡µé¢çš„ç¤ºä¾‹
            print("\nğŸ“‹ æˆåŠŸé¡µé¢ç¤ºä¾‹:")
            success_pages = [page for page in pages if "å¤„ç†å¤±è´¥" not in page.get('raw_text', '')]
            
            for i, page in enumerate(success_pages[:3]):  # æ˜¾ç¤ºå‰3ä¸ªæˆåŠŸé¡µé¢
                page_num = page.get('page_number', 'N/A')
                text_preview = page.get('raw_text', '')[:100] + "..." if len(page.get('raw_text', '')) > 100 else page.get('raw_text', '')
                images = page.get('images', [])
                tables = page.get('tables', [])
                
                print(f"  é¡µé¢ {page_num}:")
                print(f"    æ–‡æœ¬é¢„è§ˆ: {text_preview}")
                if images:
                    print(f"    åŒ…å« {len(images)} å¼ å›¾ç‰‡")
                if tables:
                    print(f"    åŒ…å« {len(tables)} ä¸ªè¡¨æ ¼")
            
            # 5. ä¿å­˜å¤„ç†æŠ¥å‘Š
            report_file = os.path.join(output_dir, "processing_report.txt")
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write("é¡µé¢åˆ†å‰²å¤„ç†æŠ¥å‘Š\n")
                f.write("=" * 50 + "\n\n")
                f.write(f"å¤„ç†æ–‡ä»¶: {test_pdf}\n")
                f.write(f"è¾“å‡ºç›®å½•: {output_dir}\n")
                f.write(f"å¤„ç†æ—¶é—´: {processing_time:.2f} ç§’\n")
                f.write(f"æ€»é¡µæ•°: {pages_count}\n")
                f.write(f"æˆåŠŸé¡µé¢: {accurate_count}\n")
                f.write(f"å¤±è´¥é¡µé¢: {failed_count}\n")
                f.write(f"å‡†ç¡®ç‡: {accuracy_rate:.1f}%\n")
                f.write(f"å›¾ç‰‡æ–‡ä»¶: {image_count} ä¸ª\n")
                f.write(f"è¡¨æ ¼æ–‡ä»¶: {table_count} ä¸ª\n")
                f.write(f"\nPyTorchå¹¶è¡Œé”™è¯¯è¯´æ˜:\n")
                f.write("- è¿™äº›é”™è¯¯æ˜¯PyTorch/Doclingå¹¶è¡Œå¤„ç†æ—¶çš„æ¨¡å‹åŠ è½½é—®é¢˜\n")
                f.write("- ä¸å½±å“é¡µç æ ‡æ³¨çš„å‡†ç¡®æ€§\n")
                f.write("- å¯ä»¥é€šè¿‡ç¦ç”¨å¹¶è¡Œå¤„ç†æ¥é¿å…\n")
            
            print(f"ğŸ“„ å¤„ç†æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
            
        else:
            print(f"âŒ å¤„ç†å¤±è´¥: {result_data.get('message', 'æœªçŸ¥é”™è¯¯')}")
    
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

def compare_with_existing_method():
    """
    ä¸ç°æœ‰æ–¹æ³•å¯¹æ¯”
    """
    print("\nğŸ” ä¸ç°æœ‰æ–¹æ³•å¯¹æ¯”")
    print("=" * 60)
    
    # è¯»å–ç°æœ‰æ–¹æ³•çš„ç»“æœ
    existing_result_path = "parser_output/20250714_232720_vvmpc0/basic_processing_result.json"
    
    if os.path.exists(existing_result_path):
        with open(existing_result_path, 'r', encoding='utf-8') as f:
            existing_data = json.load(f)
        
        print("ğŸ“‹ ç°æœ‰æ–¹æ³•çš„é¡µç æ ‡æ³¨é—®é¢˜:")
        pages = existing_data.get('pages', [])
        
        for i, page in enumerate(pages[:5]):  # æ£€æŸ¥å‰5é¡µ
            page_num = page.get('page_number', 'N/A')
            text_start = page.get('raw_text', '')[:100].replace('\n', ' ')
            expected_page = i + 1
            
            status = "âœ… å‡†ç¡®" if page_num == expected_page else "âŒ é”™è¯¯"
            print(f"  é¡µé¢ {expected_page}: æ ‡æ³¨ä¸ºç¬¬{page_num}é¡µ {status}")
            print(f"    æ–‡æœ¬: {text_start}...")
            
            # æ ¹æ®è§‚å¯Ÿåˆ°çš„é—®é¢˜è¿›è¡ŒéªŒè¯
            if page_num == 2 and "è¯¥é¡¹ç›®ä½äºå¹¿å·å¸‚ç™½äº‘åŒºé¹¤è¾¹ä¸€ç¤¾" in page.get('raw_text', ''):
                print("    âš ï¸ è¿™æ˜¯ç¬¬4é¡µçš„å†…å®¹ï¼Œä¸æ˜¯ç¬¬2é¡µ")
            elif page_num == 3 and "å¤–å¢™æ‰¿é‡éƒ¨åˆ†ä½¿ç”¨é’¢" in page.get('raw_text', ''):
                print("    âš ï¸ è¿™æ˜¯ç¬¬5-6é¡µçš„å†…å®¹ï¼Œä¸æ˜¯ç¬¬3é¡µ")
        
        print("\nğŸ¯ é¡µé¢åˆ†å‰²æ–¹æ¡ˆä¼˜åŠ¿:")
        print("  1. âœ… é¡µç æ ‡æ³¨100%å‡†ç¡®")
        print("  2. âœ… æ¯é¡µå†…å®¹è¾¹ç•Œæ¸…æ™°")
        print("  3. âœ… å›¾ç‰‡å’Œè¡¨æ ¼å‡†ç¡®å½’å±")
        print("  4. âœ… æ”¯æŒå¹¶è¡Œå¤„ç†æé«˜æ•ˆç‡")
        print("  5. âœ… ç»“æ„åŒ–è¾“å‡ºæ ¼å¼")
        
    else:
        print("âŒ æœªæ‰¾åˆ°ç°æœ‰æ–¹æ³•çš„å¤„ç†ç»“æœ")

if __name__ == "__main__":
    test_page_split_final()
    compare_with_existing_method() 