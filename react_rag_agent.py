"""
è‡ªçœå¼React RAG Agent - é‡æ„ä¸ºä¸¤ä¸ªæ ¸å¿ƒå·¥å…·
æ¨¡ç‰ˆæœç´¢å·¥å…·ï¼ˆElasticSearch + LLMé‡æ’åºï¼‰ + search_documentå·¥å…·ï¼ˆè‡ªçœå¼æœç´¢ï¼ŒåŠ¨æ€è°ƒæ•´å‚æ•°ï¼‰
"""
import os
import json
import yaml
import logging
from typing import Dict, List, Any, Optional, Union
from dataclasses import dataclass, asdict
from enum import Enum
import time
from datetime import datetime
from dotenv import load_dotenv
from elasticsearch import Elasticsearch
from elasticsearch.exceptions import ConnectionError, NotFoundError
import pymysql  # æ·»åŠ MySQLè¿æ¥æ”¯æŒ

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# å¯¼å…¥ç»„ä»¶
from llm_client import LLMClient, LLMConfig, format_prompt
from rag_tool_chroma import RAGTool, ChromaVectorStore
from hybrid_search_engine import HybridSearchEngine

logger = logging.getLogger(__name__)

class SimplifiedSearchTool(Enum):
    """ç®€åŒ–æœç´¢å·¥å…·æšä¸¾ - ä¸¤ä¸ªæ ¸å¿ƒå·¥å…·"""
    # æ¨¡ç‰ˆæœç´¢å·¥å…·ï¼šElasticSearch + LLMé‡æ’åºï¼Œä¸€æ¬¡æ€§å®Œæˆ
    TEMPLATE_SEARCH = "template_search_tool"
    
    # æ–‡æ¡£æœç´¢å·¥å…·ï¼šè‡ªçœå¼æœç´¢ï¼ŒåŠ¨æ€è°ƒæ•´å‚æ•°
    SEARCH_DOCUMENT = "search_document"

@dataclass
class ReactStep:
    """Reactæ­¥éª¤"""
    step_number: int
    thought: str
    action: str
    action_input: Dict[str, Any]
    observation: str
    timestamp: str

@dataclass
class AgentResponse:
    """Agentå“åº”"""
    success: bool
    final_answer: str
    react_steps: List[ReactStep]
    total_steps: int
    execution_time: float
    metadata: Dict[str, Any]

import hashlib
from functools import lru_cache
from mysql_connection_manager import mysql_manager

class QueryCache:
    """æŸ¥è¯¢ç»“æœç¼“å­˜"""
    
    def __init__(self, max_size=100):
        self.cache = {}
        self.max_size = max_size
        self.enabled = os.getenv("ENABLE_QUERY_CACHE", "false").lower() == "true"
    
    def get_cache_key(self, query: str) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        return hashlib.md5(query.encode('utf-8')).hexdigest()
    
    def get(self, query: str):
        """è·å–ç¼“å­˜ç»“æœ"""
        if not self.enabled:
            return None
        
        key = self.get_cache_key(query)
        return self.cache.get(key)
    
    def set(self, query: str, result: Any):
        """è®¾ç½®ç¼“å­˜ç»“æœ"""
        if not self.enabled:
            return
        
        key = self.get_cache_key(query)
        
        # å¦‚æœç¼“å­˜å·²æ»¡ï¼Œåˆ é™¤æœ€æ—§çš„æ¡ç›®
        if len(self.cache) >= self.max_size:
            oldest_key = next(iter(self.cache))
            del self.cache[oldest_key]
        
        self.cache[key] = {
            'result': result,
            'timestamp': time.time()
        }
    
    def clear(self):
        """æ¸…ç©ºç¼“å­˜"""
        self.cache.clear()
class SimplifiedReactAgent:
    """è‡ªçœå¼React Agent - ä¸¤ä¸ªæ ¸å¿ƒå·¥å…· (template_search_tool + search_document)"""
    
    def __init__(self, storage_dir: str = None):
        """åˆå§‹åŒ–ç®€åŒ–ç‰ˆReact Agent"""
        # ä½¿ç”¨pdf_embedding_storageä½œä¸ºé»˜è®¤å­˜å‚¨ç›®å½•
        self.storage_dir = storage_dir or os.getenv("RAG_STORAGE_DIR", "pdf_embedding_storage")
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.llm_client = LLMClient(LLMConfig())
        
        # åˆå§‹åŒ–å†…ç½®MySQLè¿æ¥ï¼ˆæ›¿ä»£å¤–éƒ¨mysql_retrieverï¼‰
        self._init_mysql_connection()
        
        # åˆå§‹åŒ–ElasticSearchå®¢æˆ·ç«¯
        self.es_client = None
        self.es_index_name = "template_search_index"
        self._init_elasticsearch()
        
        # åˆå§‹åŒ–RAGå·¥å…·å’Œæ··åˆæœç´¢ï¼Œä½¿ç”¨pdf_embedding_storage
        self.rag_tool = RAGTool(self.storage_dir, self.llm_client)
        self.hybrid_searcher = HybridSearchEngine(
            self.rag_tool.vector_store, 
            self.llm_client
        )
        
        # é…ç½®å‚æ•° - æç®€ä¸º1æ­¥
        self.max_steps = int(os.getenv("MAX_REACT_STEPS", "1"))
        
        # åŠ è½½æ‰€æœ‰promptæ¨¡æ¿
        self.rerank_prompt_template = self._load_rerank_prompt()
        self.step_prompts = self._load_step_prompts()
        
        logger.info("âœ… ç®€åŒ–ç‰ˆReact Agentåˆå§‹åŒ–å®Œæˆ - æç®€ç‰ˆ (DeepSeek+Qwen + 1æ­¥å¾ªç¯)")
        logger.info(f"ğŸ“Š æœ€å¤§æ­¥éª¤æ•°: {self.max_steps} (æç®€é…ç½®)")
        logger.info("ğŸ§  æ”¯æŒå·¥å…·: template_search_tool (ElasticSearch+LLM) + search_document (è‡ªçœå¼æœç´¢)")
        logger.info("ğŸš€ ä¼˜åŒ–ç‰¹æ€§: DeepSeek+Qwenæ··åˆAPI + æ™ºèƒ½ç»ˆæ­¢ + ç¼“å­˜æœºåˆ¶")
    
    def _load_rerank_prompt(self) -> str:
        """ä»YAMLæ–‡ä»¶åŠ è½½LLMé‡æ’åºpromptæ¨¡æ¿"""
        try:
            prompt_file = os.path.join(os.path.dirname(__file__), "prompt", "template_rerank.yaml")
            with open(prompt_file, 'r', encoding='utf-8') as f:
                prompt_data = yaml.safe_load(f)
                template = prompt_data.get('template_rerank_prompt', '')
                if not template:
                    raise ValueError("template_rerank_prompt not found in yaml file")
                logger.info("âœ… æˆåŠŸåŠ è½½LLMé‡æ’åºpromptæ¨¡æ¿")
                return template
        except Exception as e:
            logger.error(f"âŒ åŠ è½½LLMé‡æ’åºpromptå¤±è´¥: {e}")
            raise RuntimeError(f"æ— æ³•åŠ è½½LLMé‡æ’åºpromptæ¨¡æ¿: {e}")
    
    def _load_step_prompts(self) -> Dict[str, str]:
        """ä»YAMLæ–‡ä»¶åŠ è½½Reactæ­¥éª¤promptæ¨¡æ¿"""
        try:
            prompt_file = os.path.join(os.path.dirname(__file__), "prompt", "react_step_prompts.yaml")
            with open(prompt_file, 'r', encoding='utf-8') as f:
                prompt_data = yaml.safe_load(f)
                required_prompts = ['first_step_prompt', 'continue_step_prompt', 'final_answer_format']
                for prompt_name in required_prompts:
                    if not prompt_data.get(prompt_name):
                        raise ValueError(f"{prompt_name} not found in yaml file")
                logger.info("âœ… æˆåŠŸåŠ è½½Reactæ­¥éª¤promptæ¨¡æ¿")
                return prompt_data
        except Exception as e:
            logger.error(f"âŒ åŠ è½½Reactæ­¥éª¤promptå¤±è´¥: {e}")
            raise RuntimeError(f"æ— æ³•åŠ è½½Reactæ­¥éª¤promptæ¨¡æ¿: {e}")
    
    def process_query(self, user_query: str) -> str:
        """
        å¤„ç†ç”¨æˆ·æŸ¥è¯¢ - æ™ºèƒ½é€‰æ‹©ä¸¤ä¸ªæ ¸å¿ƒå·¥å…·
        
        Args:
            user_query: ç”¨æˆ·æŸ¥è¯¢
            
        Returns:
            åŒ…å«å®Œæ•´Reactè¿‡ç¨‹çš„JSONå­—ç¬¦ä¸²
        """
        start_time = time.time()
        
        # ä¿å­˜å½“å‰ç”¨æˆ·æŸ¥è¯¢ä¾›æ™ºèƒ½å‚æ•°æå–ä½¿ç”¨
        self._current_user_query = user_query
        
        print(f"\nğŸš€ ===== ç®€åŒ–ç‰ˆReact Agentå¯åŠ¨ (ä¸¤ä¸ªæ ¸å¿ƒå·¥å…·) =====")
        print(f"ğŸ“ ç”¨æˆ·æŸ¥è¯¢: {user_query}")
        print(f"ğŸ§  å³å°†å¼€å§‹AIæ™ºèƒ½å·¥å…·é€‰æ‹©...")
        
        logger.info(f"ğŸš€ å¼€å§‹å¤„ç†æŸ¥è¯¢: {user_query}")
        
        # åˆå§‹åŒ–å“åº”
        response = AgentResponse(
            success=False,
            final_answer="",
            react_steps=[],
            total_steps=0,
            execution_time=0.0,
            metadata={}
        )
        
        try:
            # Reactå¾ªç¯ - æ™ºèƒ½å·¥å…·é€‰æ‹©å’Œè‡ªåŠ¨æ”¾å®½ç­–ç•¥
            for step_num in range(1, self.max_steps + 1):
                print(f"\nğŸ”„ ===== Reactæ­¥éª¤ {step_num} =====")
                logger.info(f"ğŸ”„ å¼€å§‹Reactæ­¥éª¤ {step_num}")
                
                # 1. æ€è€ƒé˜¶æ®µ - AIæ™ºèƒ½åˆ†æå·¥å…·é€‰æ‹©
                print(f"ğŸ¤” æ€è€ƒé˜¶æ®µ...")
                logger.info(f"ğŸ¤” THOUGHT é˜¶æ®µå¼€å§‹ - æ­¥éª¤{step_num}")
                thought, action, action_input = self._think_step(user_query, response.react_steps, step_num)
                
                print(f"ğŸ’­ AIæ€è€ƒ: {thought}")
                print(f"ğŸ¯ å†³å®šè¡ŒåŠ¨: {action}")
                print(f"ğŸ“ è¡ŒåŠ¨å‚æ•°: {action_input}")
                
                # è¯¦ç»†è®°å½•æ€è€ƒè¿‡ç¨‹
                logger.info(f"ğŸ’­ THOUGHT: {thought}")
                logger.info(f"ğŸ¯ ACTION: {action}")
                logger.info(f"ğŸ“ ACTION_INPUT: {json.dumps(action_input, ensure_ascii=False)}")
                
                # 2. è¡ŒåŠ¨é˜¶æ®µ - æ‰§è¡Œå·¥å…·
                print(f"âš¡ è¡ŒåŠ¨é˜¶æ®µ...")
                logger.info(f"âš¡ ACTION æ‰§è¡Œé˜¶æ®µå¼€å§‹ - å·¥å…·: {action}")
                observation = self._action_step(action, action_input)
                
                print(f"ğŸ‘€ è§‚å¯Ÿç»“æœ: {observation}")
                logger.info(f"ğŸ‘€ OBSERVATION: {observation}")
                
                # 3. è®°å½•æ­¥éª¤
                react_step = ReactStep(
                    step_number=step_num,
                    thought=thought,
                    action=action,
                    action_input=action_input,
                    observation=observation,
                    timestamp=datetime.now().isoformat()
                )
                response.react_steps.append(react_step)
                
                # 4. æ£€æŸ¥æ˜¯å¦å®Œæˆ
                if self._should_finish(thought, action, observation, step_num):
                    print(f"âœ… Reactå¾ªç¯å®Œæˆï¼Œå…±æ‰§è¡Œ{step_num}æ­¥")
                    break
                    
                print(f"â¡ï¸ ç»§ç»­ä¸‹ä¸€æ­¥...")
            
            # ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
            response.final_answer = self._generate_final_answer(user_query, response.react_steps)
            response.success = True
            response.total_steps = len(response.react_steps)
            response.execution_time = time.time() - start_time
            
            print(f"\nğŸ¯ ===== React Agentå®Œæˆ =====")
            print(f"ğŸ“Š æ€»æ­¥éª¤: {response.total_steps}")
            print(f"â±ï¸ æ‰§è¡Œæ—¶é—´: {response.execution_time:.2f}ç§’")
            print(f"âœ… æœ€ç»ˆç­”æ¡ˆé•¿åº¦: {len(response.final_answer)}å­—ç¬¦")
            
            # æ„å»ºè¯¦ç»†å“åº”
            detailed_response = {
                "status": "success",
                "query": user_query,
                "react_process": {
                    "total_steps": response.total_steps,
                    "steps": [
                        {
                            "step_number": step.step_number,
                            "thought": step.thought,
                            "action": step.action,
                            "action_input": step.action_input,
                            "observation": step.observation,
                            "timestamp": step.timestamp
                        } for step in response.react_steps
                    ]
                },
                "final_answer": response.final_answer,
                "execution_time": response.execution_time,
                "metadata": {
                    "max_steps_reached": response.total_steps >= self.max_steps,
                    "tools_used": list(set([step.action for step in response.react_steps])),
                    "success": response.success
                }
            }
            
            return json.dumps(detailed_response, ensure_ascii=False, indent=2)
            
        except Exception as e:
            logger.error(f"âŒ React Agentå¤„ç†å¤±è´¥: {e}")
            error_response = {
                "status": "error",
                "query": user_query,
                "error": str(e),
                "react_process": {
                    "total_steps": len(response.react_steps),
                    "steps": [asdict(step) for step in response.react_steps]
                },
                "execution_time": time.time() - start_time
            }
            return json.dumps(error_response, ensure_ascii=False, indent=2)
    
    def _think_step(self, user_query: str, previous_steps: List[ReactStep], step_num: int) -> tuple:
        """
        æ€è€ƒæ­¥éª¤ - AIæ™ºèƒ½é€‰æ‹©å·¥å…·å’Œæ”¾å®½ç­–ç•¥
        
        Args:
            user_query: ç”¨æˆ·æŸ¥è¯¢
            previous_steps: ä¹‹å‰çš„æ­¥éª¤
            step_num: å½“å‰æ­¥éª¤å·
            
        Returns:
            (thought, action, action_input) å…ƒç»„
        """
        try:
            # ğŸ”’ è®°å½•å·¥å…·è·¯å¾„é”å®šçŠ¶æ€
            if previous_steps and previous_steps[0].action != "FINISH":
                locked_tool = previous_steps[0].action
                logger.info(f"ğŸ”’ æ­¥éª¤{step_num}: å·¥å…·è·¯å¾„å·²é”å®šä¸º {locked_tool}")
                logger.info(f"ğŸ“ ç¬¬1æ­¥é€‰æ‹©: {locked_tool}, å½“å‰æ­¥éª¤: {step_num}")
            else:
                logger.info(f"ğŸ†• æ­¥éª¤{step_num}: è¿™æ˜¯é¦–æ¬¡å·¥å…·é€‰æ‹©æ­¥éª¤")
            
            # æ„å»ºæ€è€ƒprompt
            if step_num == 1:
                # ç¬¬ä¸€æ­¥ï¼šAIé¦–æ¬¡åˆ†æé€‰æ‹©å·¥å…·
                prompt = self._build_first_step_prompt(user_query)
            else:
                # æ£€æŸ¥ä¸Šä¸€æ­¥ä½¿ç”¨çš„å·¥å…·ç±»å‹
                last_action = previous_steps[-1].action if previous_steps else ""
                
                # å¦‚æœä½¿ç”¨çš„æ˜¯template_search_toolï¼Œç›´æ¥ç»“æŸï¼Œä¸éœ€è¦é‡è¯•
                if last_action == SimplifiedSearchTool.TEMPLATE_SEARCH.value:
                    logger.info("ğŸš€ template_search_toolå·²å®Œæˆï¼Œæ— éœ€é‡è¯•ï¼Œç›´æ¥ç»“æŸ")
                    return "template_search_toolå·²å®Œæˆä¸€æ¬¡æ€§ElasticSearch + LLMæœç´¢ï¼Œç›´æ¥è¿”å›æœ€ä½³ç»“æœ", "FINISH", {}
                
                # åªæœ‰chapter_content_search_tooléœ€è¦å¤šè½®ä¼˜åŒ–
                prompt = self._build_continue_step_prompt(user_query, previous_steps)
            
            logger.info(f"ğŸ¤” AIå¼€å§‹æ€è€ƒæ­¥éª¤{step_num}")
            logger.info(f"ğŸ“ å‘é€ç»™AIçš„PROMPT:\n{prompt}")
            
            # è®©AIè¿›è¡Œæ€è€ƒ
            response = self.llm_client.chat([{"role": "user", "content": prompt}])
            
            logger.info(f"ğŸ¤– AIåŸå§‹å›å¤:\n{response}")
            
            # è§£æAIçš„æ€è€ƒç»“æœ
            thought, action, action_input = self._parse_thinking_response(response, previous_steps)
            
            logger.info(f"âœ… æ€è€ƒè§£æå®Œæˆ: action={action}")
            logger.info(f"ğŸ“Š è§£æç»“æœ - thought: {thought}")
            logger.info(f"ğŸ“Š è§£æç»“æœ - action: {action}")
            logger.info(f"ğŸ“Š è§£æç»“æœ - action_input: {action_input}")
            return thought, action, action_input
            
        except Exception as e:
            logger.error(f"âŒ æ€è€ƒæ­¥éª¤å¤±è´¥: {e}")
            # é»˜è®¤å›é€€åˆ°æ¨¡ç‰ˆæœç´¢
            return (
                f"æ€è€ƒå‡ºé”™ï¼Œä½¿ç”¨é»˜è®¤æ¨¡ç‰ˆæœç´¢ç­–ç•¥: {str(e)}",
                SimplifiedSearchTool.TEMPLATE_SEARCH.value,
                {"queries": [user_query]}
            )
    
    def _build_first_step_prompt(self, user_query: str) -> str:
        """æ„å»ºç¬¬ä¸€æ­¥æ€è€ƒprompt"""
        try:
            template = self.step_prompts.get('first_step_prompt', '')
            if not template:
                raise RuntimeError("first_step_promptæ¨¡æ¿æœªæ‰¾åˆ°")
            return template.format(user_query=user_query)
        except Exception as e:
            logger.error(f"âŒ æ„å»ºç¬¬ä¸€æ­¥promptå¤±è´¥: {e}")
            raise RuntimeError(f"æ— æ³•æ„å»ºç¬¬ä¸€æ­¥prompt: {e}")

    def _build_continue_step_prompt(self, user_query: str, previous_steps: List[ReactStep]) -> str:
        """æ„å»ºåç»­æ­¥éª¤æ€è€ƒprompt"""
        try:
            # åˆ†æä¸Šä¸€æ­¥çš„ç»“æœ
            last_step = previous_steps[-1]
            last_action = last_step.action
            last_observation = last_step.observation
            
            # æ„å»ºæ‰§è¡Œå†å²
            history = []
            for step in previous_steps:
                history.append(f"æ­¥éª¤{step.step_number}:")
                history.append(f"  æ€è€ƒ: {step.thought}")
                history.append(f"  è¡ŒåŠ¨: {step.action}")
                history.append(f"  å‚æ•°: {step.action_input}")
                history.append(f"  è§‚å¯Ÿ: {step.observation[:200]}...")
                history.append("")
            
            history_text = "\n".join(history)
            
            # ä½¿ç”¨yamlæ¨¡æ¿
            template = self.step_prompts.get('continue_step_prompt', '')
            if not template:
                raise RuntimeError("continue_step_promptæ¨¡æ¿æœªæ‰¾åˆ°")
            
            return template.format(
                user_query=user_query,
                history_text=history_text,
                last_action=last_action,
                last_observation=last_observation[:300] + "..." if len(last_observation) > 300 else last_observation
            )
        except Exception as e:
            logger.error(f"âŒ æ„å»ºåç»­æ­¥éª¤promptå¤±è´¥: {e}")
            raise RuntimeError(f"æ— æ³•æ„å»ºåç»­æ­¥éª¤prompt: {e}")

    def _parse_thinking_response(self, response: str, previous_steps: List[ReactStep]) -> tuple:
        """
        è§£æAIçš„æ€è€ƒå“åº”ï¼Œå¼ºåˆ¶æ‰§è¡Œå·¥å…·è·¯å¾„æ’ä»–æ€§åŸåˆ™
        
        Args:
            response: AIçš„æ€è€ƒå“åº”
            previous_steps: ä¹‹å‰çš„æ­¥éª¤
            
        Returns:
            (thought, action, action_input) å…ƒç»„
        """
        try:
            thought = ""
            action = ""
            action_input = {}
            
            # ğŸ”’ å¼ºåˆ¶æ‰§è¡Œå·¥å…·è·¯å¾„æ’ä»–æ€§æ£€æŸ¥
            locked_tool = None
            if previous_steps:
                # è·å–ç¬¬ä¸€æ­¥é€‰æ‹©çš„å·¥å…·
                first_tool = previous_steps[0].action
                if first_tool != "FINISH":
                    locked_tool = first_tool
                    logger.info(f"ğŸ”’ å·¥å…·è·¯å¾„å·²é”å®š: {locked_tool} (æ­¥éª¤1é€‰æ‹©)")
                    logger.info(f"ğŸš« ç¦æ­¢åˆ‡æ¢å·¥å…·ï¼Œå¼ºåˆ¶ä½¿ç”¨: {locked_tool}")
            
            # è§£æThought
            if "Thought:" in response:
                thought_start = response.find("Thought:") + len("Thought:")
                if "Action:" in response:
                    thought_end = response.find("Action:")
                else:
                    thought_end = len(response)
                thought = response[thought_start:thought_end].strip()
            
            # è§£æAction
            if "Action:" in response:
                action_start = response.find("Action:") + len("Action:")
                if "Action Input:" in response:
                    action_end = response.find("Action Input:")
                else:
                    action_end = response.find("\n", action_start)
                    if action_end == -1:
                        action_end = len(response)
                
                action = response[action_start:action_end].strip()
                
                # å¤„ç†ç»“æŸæŒ‡ä»¤
                if action.upper() == "FINISH":
                    return thought, "FINISH", {}
                
                # ğŸ”’ å·¥å…·è·¯å¾„æ’ä»–æ€§å¼ºåˆ¶æ‰§è¡Œ
                if locked_tool and action != locked_tool:
                    logger.warning(f"âš ï¸ AIå°è¯•åˆ‡æ¢å·¥å…·: {action} â†’ {locked_tool}")
                    logger.info(f"ğŸ”’ å¼ºåˆ¶è¦†ç›–ä¸ºé”å®šå·¥å…·: {locked_tool}")
                    original_action = action
                    action = locked_tool
                    thought = f"[ç³»ç»Ÿå¼ºåˆ¶æ‰§è¡Œå·¥å…·è·¯å¾„æ’ä»–æ€§] å°è¯•åˆ‡æ¢åˆ°{original_action}è¢«é˜»æ­¢ï¼Œç»§ç»­ä½¿ç”¨{locked_tool}ã€‚{thought}"
                
                # éªŒè¯actionæ˜¯å¦æœ‰æ•ˆ
                valid_actions = [tool.value for tool in SimplifiedSearchTool]
                if action not in valid_actions:
                    # æ™ºèƒ½ä¿®æ­£action
                    if any(keyword in action.lower() for keyword in ["template", "æ¨¡æ¿", "æŠ¥å‘Š", "æŒ‡å—"]):
                        action = SimplifiedSearchTool.TEMPLATE_SEARCH.value
                    elif any(keyword in action.lower() for keyword in ["search_document", "document", "å†…å®¹", "ç« èŠ‚", "æœç´¢", "èƒŒæ™¯", "å†å²"]):
                        action = SimplifiedSearchTool.SEARCH_DOCUMENT.value
                    else:
                        # å¦‚æœæœ‰å‰ä¸€æ­¥ï¼Œä¿æŒä¸€è‡´æ€§
                        if previous_steps:
                            action = previous_steps[0].action
                        else:
                            action = SimplifiedSearchTool.TEMPLATE_SEARCH.value  # é»˜è®¤
            
            # è§£æAction Input
            input_text = ""  # åˆå§‹åŒ–å˜é‡é¿å…UnboundLocalError
            action_input = {}
            
            if "Action Input:" in response:
                input_start = response.find("Action Input:") + len("Action Input:")
                input_text = response[input_start:].strip()
                
                # ğŸ¯ æ™ºèƒ½å‚æ•°è§£æ - æ”¯æŒå¤šç§æ ¼å¼
                try:
                    # å…ˆå°è¯•ç›´æ¥è§£æ
                    action_input = json.loads(input_text)
                except json.JSONDecodeError:
                    # JSONè§£æå¤±è´¥ï¼Œå°è¯•æå–JSONç‰‡æ®µ
                    logger.info("ğŸ“ JSONè§£æå¤±è´¥ï¼Œå°è¯•æ™ºèƒ½æå–")
                    
                    # å°è¯•ä»å¤æ‚æ–‡æœ¬ä¸­æå–JSON
                    import re
                    json_pattern = r'\{[^{}]*\}'
                    json_matches = re.findall(json_pattern, input_text)
                    
                    action_input = None
                    for match in json_matches:
                        try:
                            action_input = json.loads(match)
                            logger.info(f"âœ… æˆåŠŸæå–JSON: {action_input}")
                            break
                        except json.JSONDecodeError:
                            continue
                    
                    # å¦‚æœä»ç„¶å¤±è´¥ï¼Œæ™ºèƒ½æ„é€ å‚æ•°
                    if not action_input:
                        logger.info("ğŸ“ æ™ºèƒ½æ„é€ é»˜è®¤å‚æ•°")
                        # ä½¿ç”¨å½“å‰ç”¨æˆ·æŸ¥è¯¢ä½œä¸ºé»˜è®¤æŸ¥è¯¢
                        default_query = getattr(self, '_current_user_query', 'ç”¨æˆ·æŸ¥è¯¢')
                        logger.info(f"ğŸ“ è·å–åˆ°ç”¨æˆ·æŸ¥è¯¢: '{default_query}'")
                        action_input = {
                            "query_text": default_query,
                            "content_type": "all", 
                            "project_name": "è¶Šç§€å…¬å›­",
                            "top_k": 5
                        }
                        logger.info(f"âœ… æ™ºèƒ½æ„é€ å‚æ•°: {action_input}")
            
            # åˆå§‹åŒ–action_inputå¦‚æœä¸ºç©º
            if not action_input:
                action_input = {}
            
            # ğŸ¯ æ™ºèƒ½å‚æ•°æå–å’Œä¼˜åŒ–
            if action == SimplifiedSearchTool.TEMPLATE_SEARCH.value:
                # template_search_toolä½¿ç”¨åŸæœ‰çš„querieså‚æ•°æ ¼å¼
                if "queries" not in action_input or not action_input["queries"]:
                    action_input["queries"] = self._extract_intelligent_query(
                        getattr(self, '_current_user_query', ''), 
                        input_text
                    )
                    
            elif action == SimplifiedSearchTool.SEARCH_DOCUMENT.value:
                # search_documentä½¿ç”¨æ–°çš„query_textå‚æ•°æ ¼å¼
                current_user_query = getattr(self, '_current_user_query', '')
                logger.info(f"ğŸ“ å½“å‰ç”¨æˆ·æŸ¥è¯¢: '{current_user_query}'")
                
                if "query_text" not in action_input or not action_input["query_text"]:
                    # æå–æŸ¥è¯¢æ–‡æœ¬
                    if "queries" in action_input:
                        queries = action_input["queries"]
                        action_input["query_text"] = " ".join(queries) if isinstance(queries, list) else str(queries)
                    elif current_user_query:
                        # ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·åŸå§‹æŸ¥è¯¢
                        action_input["query_text"] = current_user_query
                        logger.info(f"âœ… ä½¿ç”¨ç”¨æˆ·åŸå§‹æŸ¥è¯¢: '{current_user_query}'")
                    else:
                        action_input["query_text"] = self._extract_intelligent_query_text(
                            current_user_query, 
                            input_text
                        )
                
                # ç¡®ä¿å¿…è¦å‚æ•°å­˜åœ¨
                if "content_type" not in action_input:
                    action_input["content_type"] = "all"
                if "project_name" not in action_input:
                    action_input["project_name"] = "è¶Šç§€å…¬å›­"
                if "top_k" not in action_input:
                    action_input["top_k"] = 5
                
                # ç§»é™¤ä¸æ”¯æŒçš„å‚æ•°
                unsupported_params = ["metadata_filter", "queries"]
                for param in unsupported_params:
                    if param in action_input:
                        logger.info(f"ğŸ—‘ï¸ ç§»é™¤ä¸æ”¯æŒçš„å‚æ•°: {param}")
                        del action_input[param]
            
            logger.info(f"ğŸ¯ æœ€ç»ˆä¼˜åŒ–å‚æ•°: {action_input}")
            
            # å¦‚æœæ²¡æœ‰è§£æåˆ°æœ‰æ•ˆå†…å®¹ï¼Œä½¿ç”¨æ™ºèƒ½é»˜è®¤å€¼
            if not thought:
                thought = f"æ™ºèƒ½åˆ†ææŸ¥è¯¢ç±»å‹ï¼Œé€‰æ‹©{action}å·¥å…·æ‰§è¡Œæœç´¢"
            
            if not action:
                # å·¥å…·è·¯å¾„æ’ä»–æ€§ï¼šå¦‚æœæœ‰é”å®šå·¥å…·ï¼Œå¿…é¡»ä½¿ç”¨
                if locked_tool:
                    action = locked_tool
                    logger.info(f"ğŸ”’ ä½¿ç”¨é”å®šå·¥å…·: {action}")
                else:
                    action = SimplifiedSearchTool.TEMPLATE_SEARCH.value
                    logger.info(f"ğŸ†• é¦–æ¬¡é€‰æ‹©é»˜è®¤å·¥å…·: {action}")
            
            return thought, action, action_input
            
        except Exception as e:
            logger.error(f"âŒ è§£ææ€è€ƒå“åº”å¤±è´¥: {e}")
            
            # å¼‚å¸¸æƒ…å†µä¸‹çš„å·¥å…·è·¯å¾„æ’ä»–æ€§å¤„ç†
            if previous_steps and previous_steps[0].action != "FINISH":
                locked_tool = previous_steps[0].action
                logger.error(f"âŒ è§£æå¤±è´¥ï¼Œä½¿ç”¨é”å®šå·¥å…·: {locked_tool}")
                return (
                    f"[è§£æå¼‚å¸¸ï¼Œå¼ºåˆ¶ä½¿ç”¨é”å®šå·¥å…·] {str(e)}",
                    locked_tool,
                    {"queries": ["è§£æå¤±è´¥çš„æŸ¥è¯¢"]}
                )
            else:
                logger.error(f"âŒ è§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å·¥å…·: {SimplifiedSearchTool.TEMPLATE_SEARCH.value}")
            return (
                f"è§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤ç­–ç•¥: {str(e)}",
                    SimplifiedSearchTool.TEMPLATE_SEARCH.value,
                    {"queries": ["è§£æå¤±è´¥çš„æŸ¥è¯¢"]}
                )
    

    
    def _action_step(self, action: str, action_input: Dict[str, Any]) -> str:
        """
        æ‰§è¡Œè¡ŒåŠ¨æ­¥éª¤ - ç®€åŒ–ä¸ºä¸¤ä¸ªæ ¸å¿ƒå·¥å…·
        
        Args:
            action: å·¥å…·åç§°
            action_input: å·¥å…·å‚æ•°
            
        Returns:
            è§‚å¯Ÿç»“æœ
        """
        try:
            if action == "FINISH":
                return "Reactå¾ªç¯ç»“æŸï¼Œå‡†å¤‡ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ"
            
            logger.info(f"âš¡ å¼€å§‹æ‰§è¡Œå·¥å…·: {action}")
            logger.info(f"ğŸ“ å·¥å…·å‚æ•°è¯¦æƒ…: {json.dumps(action_input, ensure_ascii=False, indent=2)}")
            
            start_time = time.time()
            
            if action == SimplifiedSearchTool.TEMPLATE_SEARCH.value:
                result = self._execute_template_search(action_input)
            elif action == SimplifiedSearchTool.SEARCH_DOCUMENT.value:
                result = self._execute_chapter_content_search(action_input)
            else:
                result = f"âŒ æœªçŸ¥å·¥å…·: {action}"
            
            execution_time = time.time() - start_time
            logger.info(f"âœ… å·¥å…·æ‰§è¡Œå®Œæˆ - è€—æ—¶: {execution_time:.2f}ç§’")
            logger.info(f"ğŸ“Š å·¥å…·æ‰§è¡Œç»“æœé•¿åº¦: {len(result)}å­—ç¬¦")
            logger.info(f"ğŸ” å·¥å…·æ‰§è¡Œç»“æœé¢„è§ˆ: {result[:200]}...")
            
            return result
                
        except Exception as e:
            logger.error(f"âŒ å·¥å…·æ‰§è¡Œå¼‚å¸¸: {action} - {e}")
            import traceback
            logger.error(f"âŒ å¼‚å¸¸å †æ ˆ:\n{traceback.format_exc()}")
            return f"å·¥å…·æ‰§è¡Œå¤±è´¥: {str(e)}"
    
    def _init_elasticsearch(self):
        """åˆå§‹åŒ–ElasticSearchå®¢æˆ·ç«¯å¹¶åˆ·æ–°æ¨¡æ¿ç´¢å¼•"""
        try:
            # ElasticSearché…ç½®
            es_host = os.getenv("ELASTICSEARCH_HOST", "localhost")
            es_port = int(os.getenv("ELASTICSEARCH_PORT", "9200"))
            es_scheme = os.getenv("ELASTICSEARCH_SCHEME", "http")
            
            # åˆ›å»ºESå®¢æˆ·ç«¯ - ä½¿ç”¨8.xæ¨èçš„è¿æ¥æ–¹å¼
            es_url = f"{es_scheme}://{es_host}:{es_port}"
            self.es_client = Elasticsearch(
                hosts=[es_url],
                verify_certs=False,
                ssl_show_warn=False,
                request_timeout=30
            )
            
            # æµ‹è¯•è¿æ¥
            if self.es_client.ping():
                logger.info("âœ… ElasticSearchè¿æ¥æˆåŠŸ")
                
                # æ¯æ¬¡åˆå§‹åŒ–æ—¶éƒ½åˆ·æ–°ç´¢å¼•
                self._refresh_template_index()
            else:
                logger.warning("âš ï¸ ElasticSearchè¿æ¥å¤±è´¥")
                self.es_client = None
                
        except Exception as e:
            logger.error(f"âŒ ElasticSearchåˆå§‹åŒ–å¤±è´¥: {e}")
            self.es_client = None
    
    def _refresh_template_index(self):
        """åˆ·æ–°æ¨¡æ¿ç´¢å¼• - æ¯æ¬¡ç³»ç»Ÿåˆå§‹åŒ–æ—¶è¿è¡Œ"""
        try:
            logger.info("ğŸ”„ å¼€å§‹åˆ·æ–°æ¨¡æ¿ç´¢å¼•...")
            
            # 1. åˆ é™¤ç°æœ‰ç´¢å¼•ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if self.es_client.indices.exists(index=self.es_index_name):
                logger.info(f"ğŸ—‘ï¸ åˆ é™¤ç°æœ‰ç´¢å¼•: {self.es_index_name}")
                self.es_client.indices.delete(index=self.es_index_name)
            
            # 2. åˆ›å»ºæ–°ç´¢å¼•
            logger.info(f"ğŸ”¨ åˆ›å»ºæ–°ç´¢å¼•: {self.es_index_name}")
            mapping = {
                "mappings": {
                    "properties": {
                        "guide_id": {"type": "keyword"},
                        "template_name": {
                            "type": "text",
                            "analyzer": "standard",
                            "search_analyzer": "standard"
                        },
                        "guide_summary": {
                            "type": "text",
                            "analyzer": "standard",
                            "search_analyzer": "standard"
                        },
                        "usage_frequency": {"type": "integer"},
                        "created_at": {"type": "date"}
                    }
                },
                "settings": {
                    "number_of_shards": 1,
                    "number_of_replicas": 0
                }
            }
            
            self.es_client.indices.create(index=self.es_index_name, body=mapping)
            logger.info("âœ… ç´¢å¼•åˆ›å»ºå®Œæˆ")
                
            # 3. ä»MySQLåŒæ­¥æœ€æ–°æ•°æ®
            self._sync_latest_templates_to_es()
                
        except Exception as e:
            logger.error(f"âŒ åˆ·æ–°æ¨¡æ¿ç´¢å¼•å¤±è´¥: {e}")
    
    def _sync_latest_templates_to_es(self):
        """ä»MySQLåŒæ­¥æœ€æ–°æ¨¡æ¿æ•°æ®åˆ°ElasticSearch"""
        try:
            logger.info("ğŸ“¥ å¼€å§‹åŒæ­¥æœ€æ–°æ¨¡æ¿æ•°æ®...")
            
            # ç¡®ä¿MySQLè¿æ¥å¯ç”¨åå†è·å–æ¨¡æ¿æ•°æ®
            try:
                self._ensure_mysql_connection()
                templates = self._mysql_search_report_guides("", limit=1000)
            except Exception as mysql_error:
                logger.error(f"âŒ MySQLè¿æ¥å¤±è´¥ï¼Œè·³è¿‡æ•°æ®åŒæ­¥: {mysql_error}")
                return
            
            if not templates:
                logger.warning("âš ï¸ MySQLä¸­æ²¡æœ‰æ‰¾åˆ°æ¨¡æ¿æ•°æ®")
                return
            
            # å‡†å¤‡æ‰¹é‡ç´¢å¼•æ•°æ®ï¼ˆåªä¿ç•™æ ¸å¿ƒå­—æ®µï¼‰
            actions = []
            for template in templates:
                doc = {
                    "guide_id": template.get("guide_id"),
                    "template_name": template.get("template_name", ""),
                    "guide_summary": template.get("guide_summary", ""),
                    "usage_frequency": template.get("usage_frequency", 0),
                    "created_at": template.get("created_at", "")
                }
                
                action = {
                    "_index": self.es_index_name,
                    "_id": template.get("guide_id"),
                    "_source": doc
                }
                actions.append(action)
            
            # æ‰§è¡Œæ‰¹é‡ç´¢å¼•
            if actions:
                from elasticsearch.helpers import bulk
                bulk(self.es_client, actions)
                logger.info(f"âœ… æˆåŠŸåŒæ­¥ {len(actions)} ä¸ªæ¨¡æ¿åˆ°ElasticSearch")
                
                # å¼ºåˆ¶åˆ·æ–°ç´¢å¼•ï¼Œç¡®ä¿æ•°æ®ç«‹å³å¯æœç´¢
                self.es_client.indices.refresh(index=self.es_index_name)
                logger.info("âœ… ç´¢å¼•åˆ·æ–°å®Œæˆï¼Œæ•°æ®å·²å¯æœç´¢")
            else:
                logger.warning("âš ï¸ æ²¡æœ‰æ•°æ®éœ€è¦åŒæ­¥")
            
        except Exception as e:
            logger.error(f"âŒ åŒæ­¥æœ€æ–°æ¨¡æ¿æ•°æ®å¤±è´¥: {e}")
    
    def _search_templates_with_es(self, query: str, size: int = 3) -> List[Dict[str, Any]]:
        """ä½¿ç”¨ElasticSearchæœç´¢æ¨¡æ¿ï¼ˆå¬å›é˜¶æ®µï¼‰- åªæœç´¢æ ¸å¿ƒå­—æ®µ"""
        try:
            # æ„å»ºåŒå­—æ®µæŸ¥è¯¢ï¼šåªæœç´¢template_nameå’Œguide_summary
            search_body = {
                "size": size,
                "query": {
                    "multi_match": {
                        "query": query,
                        "fields": [
                            "template_name^2",    # æ¨¡æ¿åç§°æƒé‡è¾ƒé«˜
                            "guide_summary^3"     # æŒ‡å—æ€»ç»“æƒé‡æœ€é«˜ï¼ˆæ›´é‡è¦ï¼‰
                        ],
                        "type": "best_fields",
                        "fuzziness": "AUTO"
                    }
                },
                "sort": [
                    {"_score": {"order": "desc"}},
                    {"usage_frequency": {"order": "desc"}}
                ]
            }
            
            response = self.es_client.search(index=self.es_index_name, body=search_body)
            
            results = []
            for hit in response['hits']['hits']:
                result = hit['_source']
                result['es_score'] = hit['_score']
                results.append(result)
            
            logger.info(f"ğŸ” ElasticSearchå¬å› {len(results)} ä¸ªå€™é€‰æ¨¡æ¿")
            return results
            
        except Exception as e:
            logger.error(f"âŒ ElasticSearchæœç´¢å¤±è´¥: {e}")
            return []
    
    def _llm_rerank_templates(self, query: str, candidates: List[Dict[str, Any]]) -> Optional[str]:
        """ä½¿ç”¨LLMå¯¹å€™é€‰æ¨¡æ¿è¿›è¡Œè¯­ä¹‰é‡æ’åºï¼Œè¿”å›æœ€ä½³åŒ¹é…çš„report_guideå†…å®¹"""
        if not candidates:
            return None
        
        try:
            # ä»MySQLè·å–æ¯ä¸ªå€™é€‰æ¨¡æ¿çš„å®Œæ•´report_guideå†…å®¹
            enriched_candidates = []
            for candidate in candidates:
                guide_id = candidate.get('guide_id')
                if guide_id:
                    full_template = self._mysql_get_report_guide_by_id(guide_id)
                    if full_template:
                        enriched_candidates.append({
                            'guide_id': guide_id,
                            'template_name': full_template.get('template_name', ''),
                            'report_guide': full_template.get('report_guide', {}),
                            'es_score': candidate.get('es_score', 0)
                        })
            
            if not enriched_candidates:
                logger.warning("âš ï¸ æ— æ³•è·å–å€™é€‰æ¨¡æ¿çš„å®Œæ•´æ•°æ®")
                return None
            
            # æ„å»ºå€™é€‰æ¨¡æ¿æ–‡æœ¬ï¼ˆåªåŒ…å«æ ¸å¿ƒä¸‰ä¸ªå­—æ®µï¼‰
            candidates_text = ""
            for i, candidate in enumerate(enriched_candidates, 1):
                # æ ¼å¼åŒ–report_guideå†…å®¹ï¼Œæˆªå–åˆç†é•¿åº¦
                report_guide_str = str(candidate.get('report_guide', {}))
                if len(report_guide_str) > 500:
                    report_guide_preview = report_guide_str[:500] + "..."
                else:
                    report_guide_preview = report_guide_str
                
                candidates_text += f"{i}. æ¨¡æ¿ID: {candidate.get('guide_id', '')}\n"
                candidates_text += f"   æ¨¡æ¿åç§°: {candidate.get('template_name', '')}\n"
                candidates_text += f"   æŠ¥å‘ŠæŒ‡å—å†…å®¹: {report_guide_preview}\n\n"
            
            # ä½¿ç”¨ä»yamlåŠ è½½çš„promptæ¨¡æ¿
            rerank_prompt = self.rerank_prompt_template.format(
                query=query,
                candidates_text=candidates_text
            )
            
            # è°ƒç”¨LLM
            response = self.llm_client.chat(
                messages=[{"role": "user", "content": rerank_prompt}]
            )
            
            # è§£æLLMå“åº”ï¼Œè·å–é€‰ä¸­çš„æ¨¡æ¿
            llm_choice = response.strip()
            try:
                choice_idx = int(llm_choice) - 1
                if 0 <= choice_idx < len(enriched_candidates):
                    # è¿”å›LLMé€‰æ‹©çš„æ¨¡æ¿çš„report_guideå†…å®¹
                    selected = enriched_candidates[choice_idx]
                    logger.info(f"ğŸ¤– LLMé€‰æ‹©æ¨¡æ¿: {selected.get('template_name')}")
                    
                    # æ›´æ–°ä½¿ç”¨é¢‘ç‡ç»Ÿè®¡
                    try:
                        self._mysql_update_report_guide_usage(selected.get('guide_id'))
                    except:
                        pass  # å¿½ç•¥ç»Ÿè®¡æ›´æ–°é”™è¯¯
                    
                    return selected.get('report_guide')
                else:
                    logger.warning(f"âš ï¸ LLMè¿”å›æ— æ•ˆé€‰æ‹©: {llm_choice}")
                    # è¿”å›ç¬¬ä¸€ä¸ªå€™é€‰çš„report_guide
                    return enriched_candidates[0].get('report_guide') if enriched_candidates else None
            except ValueError:
                logger.warning(f"âš ï¸ LLMè¿”å›æ ¼å¼é”™è¯¯: {llm_choice}")
                # è¿”å›ç¬¬ä¸€ä¸ªå€™é€‰çš„report_guide
                return enriched_candidates[0].get('report_guide') if enriched_candidates else None
            
        except Exception as e:
            logger.error(f"âŒ LLMé‡æ’åºå¤±è´¥: {e}")
            # å›é€€ï¼šè¿”å›ç¬¬ä¸€ä¸ªå€™é€‰çš„report_guide
            try:
                if candidates:
                    guide_id = candidates[0].get('guide_id')
                    if guide_id:
                        full_template = self._mysql_get_report_guide_by_id(guide_id)
                        return full_template.get('report_guide') if full_template else None
            except:
                pass
            return None
    
    def _execute_template_search(self, params: Dict[str, Any]) -> str:
        """
        æ‰§è¡Œæ¨¡ç‰ˆæœç´¢å·¥å…· - ElasticSearchå¬å› + LLMè¯­ä¹‰é‡æ’åº
        
        Args:
            params: åŒ…å«queries(æŸ¥è¯¢åˆ—è¡¨)
            
        Returns:
            æœç´¢ç»“æœå­—ç¬¦ä¸²
        """
        try:
            queries = params.get("queries", [])
            
            logger.info(f"ğŸ” æ¨¡ç‰ˆæœç´¢å·¥å…·å¼€å§‹æ‰§è¡Œ - ElasticSearch + LLMé‡æ’åº")
            logger.info(f"ğŸ“ æŸ¥è¯¢åˆ—è¡¨: {queries}")
            
            # åˆå¹¶æ‰€æœ‰æŸ¥è¯¢ä¸ºä¸€ä¸ªç»¼åˆæŸ¥è¯¢
            combined_query = " ".join(queries) if isinstance(queries, list) else str(queries)
            logger.info(f"ğŸ”— åˆå¹¶æŸ¥è¯¢: {combined_query}")
            
            # å°è¯•ä½¿ç”¨ElasticSearch + LLMé‡æ’åº
            if self.es_client:
                logger.info("ğŸš€ ä½¿ç”¨ElasticSearch + LLMé‡æ’åºæ¨¡å¼")
                
                # ç¬¬ä¸€é˜¶æ®µï¼šElasticSearchå¬å›top3å€™é€‰
                es_candidates = self._search_templates_with_es(combined_query, size=3)
                
                if es_candidates:
                    # ç¬¬äºŒé˜¶æ®µï¼šLLMè¯­ä¹‰é‡æ’åºï¼Œç›´æ¥è¿”å›æœ€ä½³åŒ¹é…çš„report_guideå†…å®¹
                    best_report_guide = self._llm_rerank_templates(combined_query, es_candidates)
                    
                    if best_report_guide:
                        # æ„å»ºè¿”å›ç»“æœ - åªè¿”å›report_guideå†…å®¹
                        result_text = f"âœ… æ¨¡ç‰ˆæœç´¢æˆåŠŸ (ElasticSearch + LLMé‡æ’åº)ï¼Œå·²æ‰¾åˆ°æœ€ä½³åŒ¹é…çš„æŠ¥å‘ŠæŒ‡å—ï¼š\n\n"
                        result_text += f"ğŸ“‹ **æŠ¥å‘ŠæŒ‡å—å†…å®¹**ï¼š\n{best_report_guide}\n"
                        
                        logger.info(f"âœ… ElasticSearch + LLMæ¨¡å¼æˆåŠŸæ‰¾åˆ°æœ€ä½³æŠ¥å‘ŠæŒ‡å—")
                        return result_text
                    else:
                        logger.warning("âš ï¸ LLMé‡æ’åºæœªè¿”å›ç»“æœ")
                else:
                    logger.info("ğŸ“­ ElasticSearchæœªæ‰¾åˆ°å€™é€‰æ¨¡æ¿")
                
                # ElasticSearchæ¨¡å¼æœªæ‰¾åˆ°ç»“æœæ—¶çš„æç¤º
                return f"âŒ æ¨¡ç‰ˆæœç´¢ (ElasticSearch + LLMé‡æ’åº): æœªæ‰¾åˆ°åŒ¹é…æ¨¡æ¿ï¼Œå»ºè®®å°è¯•ä¸åŒçš„æŸ¥è¯¢è¯"
            
            else:
                # ElasticSearchä¸å¯ç”¨
                logger.error("âŒ ElasticSearchä¸å¯ç”¨")
                return f"âŒ æ¨¡ç‰ˆæœç´¢å¤±è´¥: ElasticSearchæœåŠ¡ä¸å¯ç”¨"
                
        except Exception as e:
            logger.error(f"âŒ æ¨¡ç‰ˆæœç´¢æ‰§è¡Œå¤±è´¥: {e}")
            return f"âŒ æ¨¡ç‰ˆæœç´¢å¤±è´¥: {str(e)}"
    

    

    

    

    

    
    def _deduplicate_template_results(self, results: List[Dict]) -> List[Dict]:
        """å»é‡å’Œæ’åºæ¨¡æ¿ç»“æœ"""
        seen = set()
        unique_results = []
        
        for result in results:
            template_name = result.get('template_name', '')
            if template_name and template_name not in seen:
                seen.add(template_name)
                unique_results.append(result)
        
        # æŒ‰åŒ¹é…åº¦å’Œä½¿ç”¨é¢‘ç‡æ’åº
        return sorted(unique_results, 
                     key=lambda x: (x.get('matched_score', 0), x.get('usage_frequency', 0)), 
                     reverse=True)
    
    def _unified_content_search(self, project_name: str, query: str, top_k: int = 5, chunk_type: str = "text_chunk") -> List[Dict]:
        """
        ç»Ÿä¸€çš„æœç´¢å‡½æ•° - æ”¯æŒæ–‡æœ¬ã€å›¾ç‰‡ã€è¡¨æ ¼çš„ç»Ÿä¸€æœç´¢é€»è¾‘
        
        Args:
            project_name: é¡¹ç›®åç§°
            query: è‡ªç„¶è¯­è¨€æŸ¥è¯¢
            top_k: è¿”å›ç»“æœæ•°é‡
            chunk_type: å†…å®¹ç±»å‹ ("text_chunk", "image_chunk", "table_chunk")
            
        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        logger.info(f"ğŸ” æ‰§è¡Œç»Ÿä¸€æœç´¢: project={project_name}, query='{query}', type={chunk_type}, top_k={top_k}")
        
        try:
            # 1. æ„å»ºå…ƒæ•°æ®è¿‡æ»¤æ¡ä»¶
            metadata_filter = {
                "type": chunk_type  # ä¿®å¤ï¼šä½¿ç”¨æ­£ç¡®çš„å­—æ®µå"type"è€Œä¸æ˜¯"chunk_type"
            }
            
            # å¦‚æœæœ‰é¡¹ç›®åç§°ï¼Œæ·»åŠ åˆ°è¿‡æ»¤æ¡ä»¶
            if project_name and project_name != "all":
                metadata_filter["project_name"] = project_name
            
                        # 2. ä½¿ç”¨æ··åˆæœç´¢å¼•æ“è¿›è¡Œæœç´¢
            search_results = self.hybrid_searcher.search(
                query=query,
                top_k=top_k,
                filters=metadata_filter,
                search_strategy="hybrid"
            )
            
            # 3. è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
            results = []
            for result in search_results:
                # åŸºç¡€å­—æ®µ
                formatted_result = {
                    "content": result.content,
                    "metadata": result.metadata,
                    "similarity_score": result.vector_score,  # ä¿®å¤ï¼šä½¿ç”¨similarity_scoreè€Œä¸æ˜¯vector_score
                    "bm25_score": result.bm25_score,
                    "final_score": result.final_score
                }
                
                # æ ¹æ®chunk_typeæ·»åŠ ç‰¹å®šå­—æ®µ
                if chunk_type == "text_chunk":
                    formatted_result["content_type"] = "text"
                elif chunk_type == "image_chunk":
                    formatted_result["content_type"] = "image"
                    formatted_result["image_path"] = result.metadata.get("image_path", "")
                    formatted_result["caption"] = result.metadata.get("caption", "")
                    formatted_result["page_context"] = result.metadata.get("page_context", "")
                    formatted_result["detailed_description"] = result.metadata.get("detailed_description", "")
                elif chunk_type == "table_chunk":
                    formatted_result["content_type"] = "table"
                    formatted_result["table_path"] = result.metadata.get("table_path", "")
                    formatted_result["caption"] = result.metadata.get("caption", "")
                    formatted_result["page_context"] = result.metadata.get("page_context", "")
                    formatted_result["detailed_description"] = result.metadata.get("detailed_description", "")
                
                results.append(formatted_result)
            
            logger.info(f"âœ… {chunk_type}æœç´¢å®Œæˆï¼Œæ‰¾åˆ°{len(results)}ä¸ªç»“æœ")
            return results
            
        except Exception as e:
            logger.error(f"âŒ {chunk_type}æœç´¢å¤±è´¥: {e}")
            return []

    def _execute_chapter_content_search(self, params: Dict[str, Any]) -> str:
        """
        æ‰§è¡Œç« èŠ‚å†…å®¹æœç´¢ - é‡æ„åçš„ç»Ÿä¸€æœç´¢é€»è¾‘
        
        Args:
            params: åŒ…å«ä»¥ä¸‹å‚æ•°:
                - query_text æˆ– query: æŸ¥è¯¢æ–‡æœ¬
                - project_name: é¡¹ç›®åç§° (é»˜è®¤"all")
                - top_k: è¿”å›ç»“æœæ•°é‡ (é»˜è®¤5)
                - content_type: å†…å®¹ç±»å‹ (é»˜è®¤"all")
                
        Returns:
            æ ‡å‡†åŒ–çš„JSONå“åº”
        """
        try:
            # æå–å‚æ•° - æ”¯æŒå¤šç§å‚æ•°æ ¼å¼
            query_text = params.get("query_text", "") or params.get("query", "")
            
            # å¦‚æœæ²¡æœ‰query_textï¼Œå°è¯•ä»querieså‚æ•°ä¸­æå–
            if not query_text and "queries" in params:
                queries = params["queries"]
                if isinstance(queries, list) and queries:
                    query_text = " ".join(queries)
                elif isinstance(queries, str):
                    query_text = queries
                logger.info(f"âœ… ä»querieså‚æ•°è½¬æ¢å¾—åˆ°query_text: '{query_text}'")
            
            project_name = params.get("project_name", "all")
            top_k = params.get("top_k", 5)
            content_type = params.get("content_type", "all")
            
            # è°ƒè¯•æ—¥å¿—
            logger.info(f"ğŸ” å‚æ•°æå–ç»“æœ:")
            logger.info(f"   ğŸ“ åŸå§‹å‚æ•°: {params}")
            logger.info(f"   ğŸ” æå–çš„query_text: '{query_text}'")
            logger.info(f"   ğŸ“Š æå–çš„project_name: '{project_name}'")
            logger.info(f"   ğŸ“Š æå–çš„top_k: {top_k}")
            logger.info(f"   ğŸ¯ æå–çš„content_type: '{content_type}'")
            
            if not query_text:
                error_msg = f"æŸ¥è¯¢æ–‡æœ¬ä¸èƒ½ä¸ºç©ºã€‚åŸå§‹å‚æ•°: {params}"
                logger.error(f"âŒ {error_msg}")
                return json.dumps({
                    "status": "error",
                    "message": error_msg,
                    "retrieved_text": [],
                    "retrieved_image": [],
                    "retrieved_table": []
                }, ensure_ascii=False, indent=2)
            
            logger.info(f"ğŸ” å¼€å§‹ç« èŠ‚å†…å®¹æœç´¢:")
            logger.info(f"   ğŸ“ é¡¹ç›®: {project_name}")
            logger.info(f"   ğŸ” æŸ¥è¯¢: {query_text}")
            logger.info(f"   ğŸ“Š æ•°é‡: {top_k}")
            logger.info(f"   ğŸ¯ ç±»å‹: {content_type}")
            
            # æ ¹æ®content_typeå†³å®šæœç´¢ç­–ç•¥
            if content_type == "text":
                # åªæœç´¢æ–‡æœ¬
                text_results = self._unified_content_search(project_name, query_text, top_k, "text_chunk")
                image_results = []
                table_results = []
                # æ ¼å¼åŒ–ç»“æœ
                formatted_text = [self._format_text_chunk(result) for result in text_results[:3]]  # å–top3
                formatted_image = []
                formatted_table = []
                
            elif content_type == "image":
                # åªæœç´¢å›¾ç‰‡
                text_results = []
                image_results = self._unified_content_search(project_name, query_text, top_k, "image_chunk")
                table_results = []
                # æ ¼å¼åŒ–ç»“æœ
                formatted_text = []
                formatted_image = [self._format_image_chunk(result) for result in image_results[:3]]  # å–top3
                formatted_table = []
                
            elif content_type == "table":
                # åªæœç´¢è¡¨æ ¼
                text_results = []
                image_results = []
                table_results = self._unified_content_search(project_name, query_text, top_k, "table_chunk")
                # æ ¼å¼åŒ–ç»“æœ
                formatted_text = []
                formatted_image = []
                formatted_table = [self._format_table_chunk(result) for result in table_results[:3]]  # å–top3
                
            else:
                # content_type="all": æœç´¢æ‰€æœ‰ç±»å‹ï¼Œæ¯ç§ç±»å‹è¿”å›top3
                logger.info("ğŸ”„ æ‰§è¡Œç»Ÿä¸€æ··åˆæœç´¢ - æ‰€æœ‰å†…å®¹ç±»å‹")
                
                # 1. æœç´¢æ‰€æœ‰ç±»å‹çš„å†…å®¹ï¼ˆæ¯ç§ç±»å‹å–top_kï¼Œç¡®ä¿æœ‰è¶³å¤Ÿçš„å€™é€‰ï¼‰
                # æœç´¢æ–‡æœ¬å†…å®¹
                text_candidates = self._unified_content_search(project_name, query_text, top_k, "text_chunk")
                
                # æœç´¢å›¾ç‰‡å†…å®¹  
                image_candidates = self._unified_content_search(project_name, query_text, top_k, "image_chunk")
                
                # æœç´¢è¡¨æ ¼å†…å®¹
                table_candidates = self._unified_content_search(project_name, query_text, top_k, "table_chunk") 
                
                logger.info(f"ğŸ“Š ç»Ÿä¸€æœç´¢å€™é€‰ç»“æœ: text({len(text_candidates)}) + image({len(image_candidates)}) + table({len(table_candidates)})")
                
                # 2. æ¯ç§ç±»å‹å–top3æœ€ä½³ç»“æœï¼ˆè€Œä¸æ˜¯å…¨å±€top3ï¼‰
                top_text_results = text_candidates[:3]  # æ–‡æœ¬å–top3
                top_image_results = image_candidates[:3]  # å›¾ç‰‡å–top3
                top_table_results = table_candidates[:3]  # è¡¨æ ¼å–top3
                
                # 3. æŒ‰ç±»å‹æ ¼å¼åŒ–ç»“æœ
                formatted_text = [self._format_text_chunk(result) for result in top_text_results]
                formatted_image = [self._format_image_chunk(result) for result in top_image_results]
                formatted_table = [self._format_table_chunk(result) for result in top_table_results]
                
                logger.info(f"ğŸ¯ æœ€ç»ˆç»“æœåˆ†å¸ƒ: text({len(formatted_text)}) + image({len(formatted_image)}) + table({len(formatted_table)})")
                
                # è®¡ç®—å®é™…ç»“æœæ•°é‡ç”¨äºåç»­ç»Ÿè®¡
                text_results = top_text_results
                image_results = top_image_results
                table_results = top_table_results
            
            # ç”Ÿæˆå“åº”
            response = {
                "status": "success",
                "message": f"search_documentæ‰§è¡Œå®Œæˆ",
                "query_text": query_text,
                "project_name": project_name,
                "content_type": content_type,
                "total_results": len(text_results) + len(image_results) + len(table_results),
                "retrieved_text": formatted_text,
                "retrieved_image": formatted_image,
                "retrieved_table": formatted_table,
                "search_metadata": {
                    "search_timestamp": datetime.now().isoformat(),
                    "search_strategy": "ç»Ÿä¸€æ··åˆæœç´¢ (embedding + BM25)",
                    "top_k": top_k,
                    "project_filter": project_name != "all"
                }
            }
            
            logger.info(f"ğŸ“Š æœç´¢å®Œæˆ:")
            logger.info(f"   ğŸ“ æ–‡æœ¬ç‰‡æ®µ: {len(formatted_text)}ä¸ª")
            logger.info(f"   ğŸ–¼ï¸ å›¾ç‰‡ç‰‡æ®µ: {len(formatted_image)}ä¸ª")
            logger.info(f"   ğŸ“Š è¡¨æ ¼ç‰‡æ®µ: {len(formatted_table)}ä¸ª")
            
            return json.dumps(response, ensure_ascii=False, indent=2)
            
        except Exception as e:
            logger.error(f"âŒ ç« èŠ‚å†…å®¹æœç´¢å¤±è´¥: {e}")
            return json.dumps({
                "status": "error",
                "message": f"æœç´¢å¤±è´¥: {str(e)}",
                "retrieved_text": [],
                "retrieved_image": [],
                "retrieved_table": []
            }, ensure_ascii=False, indent=2)
    
    def _format_text_chunk(self, result: Dict) -> Dict[str, Any]:
        """æ ¼å¼åŒ–æ–‡æœ¬å—æ•°æ®"""
        return {
            "content_id": result.get("content_id", ""),
            "content": result.get("content", ""),
            "chunk_type": result.get("chunk_type", "paragraph"),
            "document_id": result.get("document_id", ""),
            "chapter_id": result.get("chapter_id", ""),
            "chapter_title": result.get("chapter_title", ""),
            "paragraph_index": result.get("paragraph_index", 0),
            "position_in_chapter": result.get("position_in_chapter", 0),
            "word_count": result.get("word_count", len(result.get("content", ""))),
            "similarity_score": result.get("similarity_score", 0.0),
            "bm25_score": result.get("bm25_score", 0.0),
            "final_score": result.get("final_score", 0.0)  # æ·»åŠ final_scoreå­—æ®µ
        }
    
    def _format_image_chunk(self, result: Dict) -> Dict[str, Any]:
        """æ ¼å¼åŒ–å›¾ç‰‡å—æ•°æ®"""
        image_path = result.get("image_path", "")
        return {
            "content_id": result.get("content_id", ""),
            "image_url": self._generate_minio_url(image_path),
            "image_path": image_path,
            "caption": result.get("caption", ""),
            "ai_description": result.get("ai_description", ""),
            "detailed_description": result.get("detailed_description", ""),
            "page_number": result.get("page_number", 0),
            "page_context": result.get("page_context", ""),
            "document_id": result.get("document_id", ""),
            "chapter_id": result.get("chapter_id", ""),
            "chapter_title": result.get("chapter_title", ""),
            "width": result.get("width", 0),
            "height": result.get("height", 0),
            "aspect_ratio": result.get("aspect_ratio", 0.0),
            "similarity_score": result.get("similarity_score", 0.0),
            "bm25_score": result.get("bm25_score", 0.0),  # æ·»åŠ bm25_scoreå­—æ®µ
            "final_score": result.get("final_score", 0.0)  # æ·»åŠ final_scoreå­—æ®µ
        }
    
    def _format_table_chunk(self, result: Dict) -> Dict[str, Any]:
        """æ ¼å¼åŒ–è¡¨æ ¼å—æ•°æ®"""
        table_path = result.get("table_path", "")
        return {
            "content_id": result.get("content_id", ""),
            "table_url": self._generate_minio_url(table_path),
            "table_path": table_path,
            "caption": result.get("caption", ""),
            "ai_description": result.get("ai_description", ""),
            "detailed_description": result.get("detailed_description", ""),
            "page_number": result.get("page_number", 0),
            "page_context": result.get("page_context", ""),
            "document_id": result.get("document_id", ""),
            "chapter_id": result.get("chapter_id", ""),
            "chapter_title": result.get("chapter_title", ""),
            "similarity_score": result.get("similarity_score", 0.0),
            "bm25_score": result.get("bm25_score", 0.0),  # æ·»åŠ bm25_scoreå­—æ®µ
            "final_score": result.get("final_score", 0.0)  # æ·»åŠ final_scoreå­—æ®µ
        }
    
    def _generate_minio_url(self, file_path: str) -> str:
        """
        ç”ŸæˆMinIOè®¿é—®URL
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            å®Œæ•´çš„MinIOè®¿é—®URL
        """
        if not file_path:
            return ""
            
        # ä»ç¯å¢ƒå˜é‡è·å–MinIOé…ç½®
        minio_endpoint = os.getenv("MINIO_ENDPOINT", "http://localhost:9000")
        minio_bucket = os.getenv("MINIO_BUCKET", "document-storage")
        
        # ç¡®ä¿è·¯å¾„æ ¼å¼æ­£ç¡®
        clean_path = file_path.lstrip("/")
        
        return f"{minio_endpoint}/{minio_bucket}/{clean_path}"
    

    

    

    
    def _format_structured_response_for_display(self, structured_response: Dict[str, Any]) -> str:
        """
        å°†ç»“æ„åŒ–å“åº”è½¬æ¢ä¸ºç”¨æˆ·å‹å¥½çš„å±•ç¤ºæ ¼å¼
        
        Args:
            structured_response: æ ‡å‡†åŒ–çš„JSONå“åº”
            
        Returns:
            ç”¨æˆ·å‹å¥½çš„å±•ç¤ºæ–‡æœ¬ï¼ŒåŒ…å«JSONæ•°æ®
        """
        try:
            status = structured_response.get("status", "unknown")
            message = structured_response.get("message", "")
            
            if status == "error":
                return f"âŒ {message}\n```json\n{json.dumps(structured_response, ensure_ascii=False, indent=2)}\n```"
            
            elif status == "no_results":
                display_message = "æœªæ‰¾åˆ°ç›¸å…³å†…å®¹ï¼Œå»ºè®®å°è¯•ä¸åŒçš„æŸ¥è¯¢è¯æˆ–ä½¿ç”¨æ¨¡ç‰ˆæœç´¢"
                
                return f"âŒ {display_message}\n```json\n{json.dumps(structured_response, ensure_ascii=False, indent=2)}\n```"
            
            else:  # success
                # ç”Ÿæˆæ‘˜è¦
                text_count = len(structured_response.get("retrieved_text", []))
                image_count = len(structured_response.get("retrieved_image", []))
                table_count = len(structured_response.get("retrieved_table", []))
                
                summary = f"âœ… ç« èŠ‚å†…å®¹æœç´¢æˆåŠŸ\n"
                summary += f"ğŸ“Š æ‰¾åˆ°å†…å®¹: æ–‡æœ¬{text_count}ä¸ª, å›¾ç‰‡{image_count}ä¸ª, è¡¨æ ¼{table_count}ä¸ª\n\n"
                
                # æ˜¾ç¤ºéƒ¨åˆ†æ–‡æœ¬å†…å®¹é¢„è§ˆ
                if text_count > 0:
                    summary += "ğŸ“ æ–‡æœ¬å†…å®¹é¢„è§ˆ:\n"
                    for i, text_item in enumerate(structured_response["retrieved_text"][:3], 1):
                        content_preview = text_item.get("content", "")[:150]
                        if len(text_item.get("content", "")) > 150:
                            content_preview += "..."
                        summary += f"   {i}. {content_preview}\n"
                    
                    if text_count > 3:
                        summary += f"   ... è¿˜æœ‰{text_count - 3}ä¸ªæ–‡æœ¬ç‰‡æ®µ\n"
                    summary += "\n"
                
                # æ˜¾ç¤ºå›¾ç‰‡ä¿¡æ¯
                if image_count > 0:
                    summary += f"ğŸ–¼ï¸ å›¾ç‰‡å†…å®¹: {image_count}ä¸ªç›¸å…³å›¾ç‰‡\n\n"
                
                # æ˜¾ç¤ºè¡¨æ ¼ä¿¡æ¯ 
                if table_count > 0:
                    summary += f"ğŸ“Š è¡¨æ ¼å†…å®¹: {table_count}ä¸ªç›¸å…³è¡¨æ ¼\n\n"
                
                summary += "ğŸ“‹ å®Œæ•´ç»“æ„åŒ–æ•°æ®:\n"
                summary += f"```json\n{json.dumps(structured_response, ensure_ascii=False, indent=2)}\n```"
                
                return summary
                
        except Exception as e:
            logger.error(f"âŒ æ ¼å¼åŒ–å±•ç¤ºå¤±è´¥: {e}")
            return f"âŒ æ ¼å¼åŒ–å¤±è´¥: {str(e)}\n```json\n{json.dumps(structured_response, ensure_ascii=False, indent=2)}\n```"
    

    
    def _should_finish(self, thought: str, action: str, observation: str, step_num: int) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥ç»“æŸReactå¾ªç¯"""
        # å¦‚æœæ”¶åˆ°ç»“æŸæŒ‡ä»¤
        if action == "FINISH":
            return True
        
        # å¦‚æœè¾¾åˆ°æœ€å¤§æ­¥éª¤æ•°
        if step_num >= self.max_steps:
            return True
        
        return False
    
    def _generate_final_answer(self, user_query: str, react_steps: List[ReactStep]) -> str:
        """ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ - æ ¹æ®å·¥å…·ç±»å‹è¿”å›å¯¹åº”æ ¼å¼"""
        try:
            if not react_steps:
                logger.warning("âš ï¸ æ²¡æœ‰Reactæ­¥éª¤ï¼Œè¿”å›ç©ºç»“æœ")
                return json.dumps({
                    "retrieved_text": [],
                    "retrieved_image": [],
                    "retrieved_table": []
                }, ensure_ascii=False, indent=2)
            
            # æ£€æµ‹ä½¿ç”¨çš„å·¥å…·ç±»å‹ï¼ˆåŸºäºç¬¬ä¸€æ­¥çš„actionï¼‰
            first_tool = react_steps[0].action
            logger.info(f"ğŸ” æ£€æµ‹åˆ°ä½¿ç”¨çš„å·¥å…·: {first_tool}")
            
            if first_tool == SimplifiedSearchTool.TEMPLATE_SEARCH.value:
                # template_search_tool: è¿”å›æ¨¡æ¿æ–‡æœ¬å†…å®¹
                return self._extract_template_content(react_steps)
                
            elif first_tool == SimplifiedSearchTool.SEARCH_DOCUMENT.value:
                # search_document: åˆå¹¶æ‰€æœ‰æ­¥éª¤çš„JSONç»“æœ
                return self._merge_document_search_results(react_steps)
                
            else:
                logger.warning(f"âš ï¸ æœªçŸ¥å·¥å…·ç±»å‹: {first_tool}")
                return json.dumps({
                    "retrieved_text": [],
                    "retrieved_image": [],
                    "retrieved_table": []
                }, ensure_ascii=False, indent=2)
            
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆå¤±è´¥: {e}")
            # è¿”å›ç©ºçš„ç»“æ„åŒ–ç»“æœ
            empty_result = {
                "retrieved_text": [],
                "retrieved_image": [],
                "retrieved_table": []
            }
            return json.dumps(empty_result, ensure_ascii=False, indent=2)
    
    def _deduplicate_results(self, results: List[Dict], key_field: str) -> List[Dict]:
        """æ ¹æ®æŒ‡å®šå­—æ®µå»é‡ç»“æœ"""
        seen = set()
        unique_results = []
        
        for result in results:
            identifier = result.get(key_field, "") or result.get("content_id", "") 
            if identifier and identifier not in seen:
                seen.add(identifier)
                # ç§»é™¤æŠ€æœ¯ç»†èŠ‚å­—æ®µï¼Œåªä¿ç•™ç”¨æˆ·éœ€è¦çš„ä¿¡æ¯
                cleaned_result = self._clean_result_for_user(result)
                unique_results.append(cleaned_result)
                
        return unique_results[:10]  # é™åˆ¶æœ€å¤š10ä¸ªç»“æœ
    
    def _clean_result_for_user(self, result: Dict) -> Dict:
        """æ¸…æ´—ç»“æœï¼Œç§»é™¤æŠ€æœ¯ç»†èŠ‚ï¼Œåªä¿ç•™ç”¨æˆ·å…³å¿ƒçš„ä¿¡æ¯"""
        # å®šä¹‰éœ€è¦ä¿ç•™çš„å­—æ®µ
        if "image_path" in result or "image_url" in result:
            # å›¾ç‰‡ç»“æœ
            return {
                "content_id": result.get("content_id", ""),
                "image_url": result.get("image_url", ""),
                "caption": result.get("caption", ""),
                "ai_description": result.get("ai_description", ""),
                "chapter_title": result.get("chapter_title", ""),
                "page_number": result.get("page_number", 0)
            }
        elif "table_path" in result or "table_url" in result:
            # è¡¨æ ¼ç»“æœ
            return {
                "content_id": result.get("content_id", ""),
                "table_url": result.get("table_url", ""),
                "caption": result.get("caption", ""),
                "ai_description": result.get("ai_description", ""),
                "chapter_title": result.get("chapter_title", ""),
                "page_number": result.get("page_number", 0)
            }
        else:
            # æ–‡æœ¬ç»“æœ
            return {
                "content_id": result.get("content_id", ""),
                "content": result.get("content", ""),
                "chapter_title": result.get("chapter_title", ""),
                "word_count": result.get("word_count", 0)
            }
    
    def _extract_intelligent_query(self, user_query: str, input_text: str) -> List[str]:
        """
        æ™ºèƒ½æå–æŸ¥è¯¢å†…å®¹ï¼Œæ”¯æŒå¤šç§è¾“å…¥æ ¼å¼ï¼ˆç”¨äºtemplate_search_toolï¼‰
        
        Args:
            user_query: åŸå§‹ç”¨æˆ·æŸ¥è¯¢
            input_text: Action Inputä¸­çš„æ–‡æœ¬
            
        Returns:
            ä¼˜åŒ–åçš„æŸ¥è¯¢åˆ—è¡¨
        """
        try:
            # 1. ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·åŸå§‹æŸ¥è¯¢
            if user_query and user_query.strip():
                primary_query = user_query.strip()
            else:
                primary_query = None
            
            # 2. ä»input_textä¸­æå–æœ‰æ•ˆæŸ¥è¯¢
            if input_text:
                # ç§»é™¤å¸¸è§çš„JSONåŒ…è£…
                clean_input = input_text.strip()
                
                # ç§»é™¤å¼•å·åŒ…è£…
                if clean_input.startswith('"') and clean_input.endswith('"'):
                    clean_input = clean_input[1:-1]
                elif clean_input.startswith("'") and clean_input.endswith("'"):
                    clean_input = clean_input[1:-1]
                
                # æå–ç¬¬ä¸€è¡Œä½œä¸ºä¸»è¦æŸ¥è¯¢
                lines = clean_input.split('\n')
                if lines and lines[0].strip():
                    secondary_query = lines[0].strip()
                else:
                    secondary_query = None
            else:
                secondary_query = None
            
            # 3. æ™ºèƒ½ç»„åˆæŸ¥è¯¢
            queries = []
            
            if primary_query:
                queries.append(primary_query)
            
            if secondary_query and secondary_query != primary_query:
                queries.append(secondary_query)
            
            # 4. ç¡®ä¿æœ‰æŸ¥è¯¢å†…å®¹
            if not queries:
                queries = ["æ™ºèƒ½æœç´¢æŸ¥è¯¢"]
            
            logger.info(f"ğŸ¯ æ™ºèƒ½æŸ¥è¯¢æå–ç»“æœ: {queries}")
            return queries
            
        except Exception as e:
            logger.error(f"âŒ æ™ºèƒ½æŸ¥è¯¢æå–å¤±è´¥: {e}")
            return [user_query if user_query else "é»˜è®¤æŸ¥è¯¢"]
    
    def _extract_intelligent_query_text(self, user_query: str, input_text: str) -> str:
        """
        æ™ºèƒ½æå–æŸ¥è¯¢æ–‡æœ¬ï¼Œæ”¯æŒå¤šç§è¾“å…¥æ ¼å¼ï¼ˆç”¨äºsearch_documentï¼‰
        
        Args:
            user_query: åŸå§‹ç”¨æˆ·æŸ¥è¯¢
            input_text: Action Inputä¸­çš„æ–‡æœ¬
            
        Returns:
            ä¼˜åŒ–åçš„æŸ¥è¯¢æ–‡æœ¬
        """
        try:
            # 1. ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·åŸå§‹æŸ¥è¯¢
            if user_query and user_query.strip():
                return user_query.strip()
            
            # 2. ä»input_textä¸­æå–æœ‰æ•ˆæŸ¥è¯¢
            if input_text:
                # ç§»é™¤å¸¸è§çš„JSONåŒ…è£…
                clean_input = input_text.strip()
                
                # ç§»é™¤å¼•å·åŒ…è£…
                if clean_input.startswith('"') and clean_input.endswith('"'):
                    clean_input = clean_input[1:-1]
                elif clean_input.startswith("'") and clean_input.endswith("'"):
                    clean_input = clean_input[1:-1]
                
                # æå–ç¬¬ä¸€è¡Œä½œä¸ºä¸»è¦æŸ¥è¯¢
                lines = clean_input.split('\n')
                if lines and lines[0].strip():
                    return lines[0].strip()
            
            # 3. é»˜è®¤å€¼
            return "æ™ºèƒ½æ–‡æ¡£æœç´¢"
            
        except Exception as e:
            logger.error(f"âŒ æ™ºèƒ½æŸ¥è¯¢æ–‡æœ¬æå–å¤±è´¥: {e}")
            return user_query if user_query else "é»˜è®¤æŸ¥è¯¢"
    

    
    def _extract_template_content(self, react_steps: List[ReactStep]) -> str:
        """æå–template_search_toolçš„æ¨¡æ¿å†…å®¹"""
        try:
            # æŸ¥æ‰¾æœ€åä¸€ä¸ªåŒ…å«æ¨¡æ¿å†…å®¹çš„æ­¥éª¤
            template_content = ""
            
            for step in react_steps:
                if step.action == SimplifiedSearchTool.TEMPLATE_SEARCH.value:
                    # æŸ¥æ‰¾åŒ…å«æ¨¡æ¿å†…å®¹çš„observation
                    if "âœ…" in step.observation and ("æ¨¡ç‰ˆæœç´¢æˆåŠŸ" in step.observation or "æœ€ä½³åŒ¹é…" in step.observation):
                        # æå–æŠ¥å‘ŠæŒ‡å—å†…å®¹
                        if "ğŸ“‹ **æŠ¥å‘ŠæŒ‡å—å†…å®¹**ï¼š" in step.observation:
                            content_start = step.observation.find("ğŸ“‹ **æŠ¥å‘ŠæŒ‡å—å†…å®¹**ï¼š") + len("ğŸ“‹ **æŠ¥å‘ŠæŒ‡å—å†…å®¹**ï¼š")
                            content = step.observation[content_start:].strip()
                            if content:
                                template_content = content
                                logger.info(f"âœ… æå–åˆ°æ¨¡æ¿å†…å®¹ï¼Œé•¿åº¦: {len(template_content)}å­—ç¬¦")
                                break
            
            if template_content:
                return template_content
            else:
                logger.warning("âš ï¸ æœªæ‰¾åˆ°æ¨¡æ¿å†…å®¹ï¼Œè¿”å›æœªæ‰¾åˆ°ä¿¡æ¯")
                return "æœªæ‰¾åˆ°åŒ¹é…çš„æ¨¡æ¿å†…å®¹"
                
        except Exception as e:
            logger.error(f"âŒ æå–æ¨¡æ¿å†…å®¹å¤±è´¥: {e}")
            return "æ¨¡æ¿å†…å®¹æå–å¤±è´¥"
    
    def _merge_document_search_results(self, react_steps: List[ReactStep]) -> str:
        """åˆå¹¶search_documentçš„JSONç»“æœ"""
        try:
            all_text_results = []
            all_image_results = []
            all_table_results = []
            
            for step in react_steps:
                if step.action == SimplifiedSearchTool.SEARCH_DOCUMENT.value:
                    try:
                        # ç›´æ¥è§£æobservationä¸­çš„JSONï¼ˆç°åœ¨æ˜¯çº¯JSONæ ¼å¼ï¼‰
                        step_data = json.loads(step.observation)
                        
                        logger.info(f"ğŸ“Š æˆåŠŸè§£ææ­¥éª¤{step.step_number}çš„JSONæ•°æ®")
                        
                        # åˆå¹¶æœç´¢ç»“æœ
                        if "retrieved_text" in step_data:
                            all_text_results.extend(step_data["retrieved_text"])
                            logger.info(f"ğŸ”¤ æ·»åŠ {len(step_data['retrieved_text'])}ä¸ªæ–‡æœ¬ç»“æœ")
                        if "retrieved_image" in step_data:
                            all_image_results.extend(step_data["retrieved_image"])
                            logger.info(f"ğŸ–¼ï¸ æ·»åŠ {len(step_data['retrieved_image'])}ä¸ªå›¾ç‰‡ç»“æœ")
                        if "retrieved_table" in step_data:
                            all_table_results.extend(step_data["retrieved_table"])
                            logger.info(f"ğŸ“Š æ·»åŠ {len(step_data['retrieved_table'])}ä¸ªè¡¨æ ¼ç»“æœ")
                            
                    except json.JSONDecodeError as e:
                        logger.warning(f"æ­¥éª¤{step.step_number}çš„JSONè§£æå¤±è´¥: {e}")
                        logger.debug(f"è§‚å¯Ÿå†…å®¹é¢„è§ˆ: {step.observation[:200]}...")
                        continue
            
            # å»é‡å’Œæ¸…æ´—ç»“æœ
            unique_text_results = self._deduplicate_results(all_text_results, "content")
            unique_image_results = self._deduplicate_results(all_image_results, "image_path")
            unique_table_results = self._deduplicate_results(all_table_results, "table_path")
            
            # ç”Ÿæˆæœ€ç»ˆçš„ç®€æ´JSONç­”æ¡ˆ
            final_json = {
                "retrieved_text": unique_text_results,
                "retrieved_image": unique_image_results,
                "retrieved_table": unique_table_results
            }
            
            logger.info(f"ğŸ“Š æœ€ç»ˆç­”æ¡ˆç»Ÿè®¡: æ–‡æœ¬{len(unique_text_results)}ä¸ª, "
                       f"å›¾ç‰‡{len(unique_image_results)}ä¸ª, è¡¨æ ¼{len(unique_table_results)}ä¸ª")
            
            return json.dumps(final_json, ensure_ascii=False, indent=2)
            
        except Exception as e:
            logger.error(f"âŒ åˆå¹¶æ–‡æ¡£æœç´¢ç»“æœå¤±è´¥: {e}")
            return json.dumps({
                "retrieved_text": [],
                "retrieved_image": [],
                "retrieved_table": []
            }, ensure_ascii=False, indent=2)

    def _init_mysql_connection(self):
        """åˆå§‹åŒ–å†…ç½®MySQLè¿æ¥"""
        try:
            self.mysql_connection = None
            self.mysql_config = {
                'host': os.getenv('MYSQL_HOST', 'localhost'),
                'port': int(os.getenv('MYSQL_PORT', 3306)),
                'user': os.getenv('MYSQL_USER', 'root'),
                'password': os.getenv('MYSQL_PASSWORD', ''),
                'database': os.getenv('MYSQL_DATABASE', 'mysql_templates'),
                'charset': os.getenv('MYSQL_CHARSET', 'utf8mb4'),
                'autocommit': True,
                'connect_timeout': 60,  # å¢åŠ è¿æ¥è¶…æ—¶
                'read_timeout': 60,     # å¢åŠ è¯»å–è¶…æ—¶
                'write_timeout': 60     # å¢åŠ å†™å…¥è¶…æ—¶
            }
            
            # å°è¯•è¿æ¥MySQL
            self._create_mysql_connection()
            
        except Exception as e:
            logger.error(f"âŒ MySQLè¿æ¥åˆå§‹åŒ–å¤±è´¥: {e}")
            self.mysql_connection = None

    def _create_mysql_connection(self):
        """åˆ›å»ºMySQLè¿æ¥"""
        try:
            self.mysql_connection = pymysql.connect(**self.mysql_config)
            logger.info(f"âœ… MySQLè¿æ¥æˆåŠŸ: {self.mysql_config['database']}")
        except Exception as e:
            logger.error(f"âŒ MySQLè¿æ¥å¤±è´¥: {e}")
            self.mysql_connection = None
            raise

    def _ensure_mysql_connection(self):
        """ç¡®ä¿MySQLè¿æ¥å¯ç”¨ï¼Œå¦‚æœæ–­å¼€åˆ™é‡è¿"""
        try:
            if self.mysql_connection is None:
                logger.info("ğŸ”„ MySQLè¿æ¥ä¸ºç©ºï¼Œå°è¯•é‡æ–°è¿æ¥...")
                self._create_mysql_connection()
                return
            
            # æ£€æŸ¥è¿æ¥æ˜¯å¦ä»ç„¶æ´»è·ƒ
            self.mysql_connection.ping(reconnect=False)
            
        except Exception as e:
            logger.warning(f"âš ï¸ MySQLè¿æ¥æ£€æŸ¥å¤±è´¥: {e}")
            logger.info("ğŸ”„ å°è¯•é‡æ–°å»ºç«‹MySQLè¿æ¥...")
            try:
                self._create_mysql_connection()
                logger.info("âœ… MySQLé‡è¿æˆåŠŸ")
            except Exception as reconnect_error:
                logger.error(f"âŒ MySQLé‡è¿å¤±è´¥: {reconnect_error}")
                self.mysql_connection = None
                raise

    def _mysql_search_report_guides(self, query: str = "", limit: int = 1000) -> List[Dict[str, Any]]:
        """å†…ç½®æ–¹æ³•ï¼šä»MySQLæœç´¢æŠ¥å‘ŠæŒ‡å—æ¨¡æ¿"""
        try:
            # ä½¿ç”¨è¿æ¥ç®¡ç†å™¨çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨
            with mysql_manager.get_cursor() as cursor:
                # æ„å»ºæœç´¢SQLï¼ˆåŒ…å«guide_summaryå­—æ®µï¼‰
                base_sql = """
                SELECT rgt.guide_id, rgt.document_type_id, rgt.template_name, rgt.project_category,
                       rgt.target_objects, rgt.report_guide, rgt.guide_summary, rgt.usage_frequency, rgt.created_at,
                       dt.type_name, dt.category
                FROM report_guide_templates rgt
                LEFT JOIN document_types dt ON rgt.document_type_id = dt.type_id
                WHERE 1=1
                """
                
                params = []
                
                # åŸºç¡€æŸ¥è¯¢è¿‡æ»¤
                if query:
                    base_sql += " AND (rgt.template_name LIKE %s OR rgt.project_category LIKE %s OR dt.type_name LIKE %s)"
                    search_pattern = f"%{query}%"
                    params.extend([search_pattern, search_pattern, search_pattern])
                
                base_sql += " ORDER BY rgt.usage_frequency DESC, rgt.created_at DESC LIMIT %s"
                params.append(limit)
                
                cursor.execute(base_sql, params)
                results = cursor.fetchall()
                
                report_guides = []
                for result in results:
                    guide = {
                        'guide_id': result[0],
                        'document_type_id': result[1],
                        'template_name': result[2],
                        'project_category': result[3],
                        'target_objects': json.loads(result[4]) if result[4] else [],
                        'report_guide': json.loads(result[5]) if result[5] else {},
                        'guide_summary': result[6] if result[6] else "",
                        'usage_frequency': result[7],
                        'created_at': result[8].isoformat() if result[8] else "",
                        'document_type_name': result[9],
                        'document_category': result[10]
                    }
                    report_guides.append(guide)
                
                logger.info(f"ä»MySQLæœç´¢åˆ° {len(report_guides)} ä¸ªæŠ¥å‘ŠæŒ‡å—")
                return report_guides
            
        except Exception as e:
            logger.error(f"MySQLæœç´¢æŠ¥å‘ŠæŒ‡å—å¤±è´¥: {e}")
            return []

    def _mysql_get_report_guide_by_id(self, guide_id: str) -> Optional[Dict[str, Any]]:
        """å†…ç½®æ–¹æ³•ï¼šæ ¹æ®IDè·å–æŠ¥å‘ŠæŒ‡å—"""
        try:
            # ä½¿ç”¨è¿æ¥ç®¡ç†å™¨çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨
            with mysql_manager.get_cursor() as cursor:
                sql = """
                SELECT rgt.guide_id, rgt.document_type_id, rgt.template_name, rgt.project_category,
                       rgt.target_objects, rgt.report_guide, rgt.guide_summary, rgt.usage_frequency, rgt.created_at,
                       dt.type_name, dt.category
                FROM report_guide_templates rgt
                LEFT JOIN document_types dt ON rgt.document_type_id = dt.type_id
                WHERE rgt.guide_id = %s
                """
                
                cursor.execute(sql, (guide_id,))
                result = cursor.fetchone()
                
                if result:
                    return {
                        'guide_id': result[0],
                        'document_type_id': result[1],
                        'template_name': result[2],
                        'project_category': result[3],
                        'target_objects': json.loads(result[4]) if result[4] else [],
                        'report_guide': json.loads(result[5]) if result[5] else {},
                        'guide_summary': result[6] if result[6] else "",
                        'usage_frequency': result[7],
                        'created_at': result[8].isoformat() if result[8] else "",
                        'document_type_name': result[9],
                        'document_category': result[10]
                    }
                
                return None
            
        except Exception as e:
            logger.error(f"æ ¹æ®IDè·å–æŠ¥å‘ŠæŒ‡å—å¤±è´¥: {e}")
            return None

    def _mysql_update_report_guide_usage(self, guide_id: str) -> bool:
        """å†…ç½®æ–¹æ³•ï¼šæ›´æ–°æŠ¥å‘ŠæŒ‡å—ä½¿ç”¨é¢‘ç‡"""
        try:
            # ä½¿ç”¨è¿æ¥ç®¡ç†å™¨çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨
            with mysql_manager.get_cursor() as cursor:
                sql = """
                UPDATE report_guide_templates 
                SET usage_frequency = usage_frequency + 1, last_updated = NOW()
                WHERE guide_id = %s
                """
                
                cursor.execute(sql, (guide_id,))
                
                if cursor.rowcount > 0:
                    logger.info(f"æˆåŠŸæ›´æ–°æŠ¥å‘ŠæŒ‡å— {guide_id} çš„ä½¿ç”¨é¢‘ç‡")
                    return True
                else:
                    logger.warning(f"æŠ¥å‘ŠæŒ‡å— {guide_id} ä¸å­˜åœ¨")
                    return False
            
        except Exception as e:
            logger.error(f"æ›´æ–°æŠ¥å‘ŠæŒ‡å—ä½¿ç”¨é¢‘ç‡å¤±è´¥: {e}")
            return False

    def close(self):
        """å…³é—­æ‰€æœ‰è¿æ¥"""
        try:
            if hasattr(self, 'mysql_connection') and self.mysql_connection:
                self.mysql_connection.close()
                logger.info("MySQLè¿æ¥å·²å…³é—­")
        except Exception as e:
            logger.error(f"å…³é—­MySQLè¿æ¥å¤±è´¥: {e}")

    def __del__(self):
        """ææ„å‡½æ•°ï¼Œç¡®ä¿è¿æ¥è¢«å…³é—­"""
        self.close()

# ä¸ºäº†å‘åå…¼å®¹ï¼Œä¿ç•™åŸæ¥å£
class ReactRAGAgent(SimplifiedReactAgent):
    """å‘åå…¼å®¹çš„React RAG Agent"""
    
    def __init__(self, storage_dir: str = None, templates_db: str = None):
        super().__init__(storage_dir)
    
    def process_input(self, user_query: str) -> str:
        """å¤„ç†è¾“å…¥ï¼ˆå‘åå…¼å®¹ï¼‰"""
        return self.process_query(user_query)
    
    def query(self, user_query: str, context: Optional[Dict[str, Any]] = None) -> AgentResponse:
        """æŸ¥è¯¢æ–¹æ³•ï¼ˆå‘åå…¼å®¹ï¼‰"""
        result_json = self.process_query(user_query)
        result_data = json.loads(result_json)
        
        # è½¬æ¢ä¸ºAgentResponseæ ¼å¼
        react_steps = []
        if "react_process" in result_data and "steps" in result_data["react_process"]:
            for step_data in result_data["react_process"]["steps"]:
                react_step = ReactStep(
                    step_number=step_data["step_number"],
                    thought=step_data["thought"],
                    action=step_data["action"],
                    action_input=step_data["action_input"],
                    observation=step_data["observation"],
                    timestamp=step_data["timestamp"]
                )
                react_steps.append(react_step)
        
        return AgentResponse(
            success=result_data.get("status") == "success",
            final_answer=result_data.get("final_answer", ""),
            react_steps=react_steps,
            total_steps=result_data.get("react_process", {}).get("total_steps", 0),
            execution_time=result_data.get("execution_time", 0.0),
            metadata=result_data.get("metadata", {})
        )