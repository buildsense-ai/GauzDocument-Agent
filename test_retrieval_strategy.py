#!/usr/bin/env python3
"""
æµ‹è¯•æ£€ç´¢ç­–ç•¥
éªŒè¯"å°å—æ£€ç´¢ï¼Œå¤§å—å–‚å…»"åŠŸèƒ½
"""

import json
import os
import sys
from pathlib import Path

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent / "src"))

from src.pdf_processing.text_chunker import TextChunker
from src.pdf_processing.retrieval_strategy import RetrievalStrategy, RetrievalQuery

def test_retrieval_strategy():
    """æµ‹è¯•æ£€ç´¢ç­–ç•¥"""
    print("ğŸ§ª å¼€å§‹æµ‹è¯•æ£€ç´¢ç­–ç•¥...")
    
    # 1. åŠ è½½åˆ†å—ç»“æœ
    chunking_output_dir = "chunking_test_output"
    chapters_file = os.path.join(chunking_output_dir, "first_level_chapters.json")
    chunks_file = os.path.join(chunking_output_dir, "minimal_chunks.json")
    
    if not os.path.exists(chapters_file) or not os.path.exists(chunks_file):
        print("âŒ è¯·å…ˆè¿è¡Œ test_text_chunker.py ç”Ÿæˆåˆ†å—ç»“æœ")
        return
    
    # ä»JSONæ–‡ä»¶é‡å»ºåˆ†å—ç»“æœ
    print("ğŸ“– åŠ è½½åˆ†å—ç»“æœ...")
    chunking_result = load_chunking_result(chapters_file, chunks_file)
    
    # 2. åˆ›å»ºæ£€ç´¢ç­–ç•¥
    strategy = RetrievalStrategy(chunking_result)
    
    # 3. æµ‹è¯•ä¸åŒçš„æŸ¥è¯¢
    test_queries = [
        "æ–‡ç‰©ä¿æŠ¤",
        "åŒ»çµå¤åº™",
        "å»ºç­‘è®¾è®¡",
        "å®‰å…¨ç›‘æµ‹",
        "é¡¹ç›®æ¦‚å†µ",
        "åŸºç¡€æªæ–½",
        "å½±å“åˆ†æ",
        "æŠ€æœ¯å¯è¡Œæ€§"
    ]
    
    for query_text in test_queries:
        print(f"\n{'='*60}")
        print(f"ğŸ” æµ‹è¯•æŸ¥è¯¢: '{query_text}'")
        print('='*60)
        
        # åˆ›å»ºæŸ¥è¯¢
        query = RetrievalQuery(query_text=query_text, top_k=3)
        
        # æ‰§è¡Œæ£€ç´¢
        result = strategy.search(query)
        
        # æ˜¾ç¤ºç»“æœ
        formatted_result = strategy.format_retrieval_result(result)
        print(formatted_result)
        
        # ä¿å­˜ç»“æœ
        output_file = f"retrieval_test_output_{query_text.replace(' ', '_')}.json"
        strategy.save_retrieval_result(result, output_file)
    
    # 4. æµ‹è¯•é«˜çº§æŸ¥è¯¢
    print(f"\n{'='*60}")
    print("ğŸ§ª æµ‹è¯•é«˜çº§æŸ¥è¯¢åŠŸèƒ½")
    print('='*60)
    
    # åªæ£€ç´¢æ ‡é¢˜å—
    query = RetrievalQuery(
        query_text="å»ºç­‘",
        top_k=2,
        chunk_types=["title"]
    )
    result = strategy.search(query)
    print("ğŸ¯ åªæ£€ç´¢æ ‡é¢˜å—:")
    print(strategy.format_retrieval_result(result))
    
    # åªæ£€ç´¢ç‰¹å®šç« èŠ‚
    query = RetrievalQuery(
        query_text="å®‰å…¨",
        top_k=3,
        chapter_filter=["8", "16", "17"]  # æ–‡ä¿å•ä½ã€å½±å“åˆ†æã€é¢„é˜²æªæ–½
    )
    result = strategy.search(query)
    print("\nğŸ¯ åªæ£€ç´¢ç‰¹å®šç« èŠ‚:")
    print(strategy.format_retrieval_result(result))
    
    print("\nğŸ‰ æ£€ç´¢ç­–ç•¥æµ‹è¯•å®Œæˆ!")

def load_chunking_result(chapters_file, chunks_file):
    """ä»JSONæ–‡ä»¶åŠ è½½åˆ†å—ç»“æœ"""
    # è¿™é‡Œéœ€è¦é‡æ–°æ„å»ºChunkingResultå¯¹è±¡
    # ç”±äºå¯¼å…¥é—®é¢˜ï¼Œæˆ‘ä»¬ç›´æ¥ä½¿ç”¨å­—å…¸å½¢å¼è¿›è¡Œæµ‹è¯•
    with open(chapters_file, 'r', encoding='utf-8') as f:
        chapters_data = json.load(f)
    
    with open(chunks_file, 'r', encoding='utf-8') as f:
        chunks_data = json.load(f)
    
    # é‡æ–°æ„å»ºå¯¹è±¡
    from src.pdf_processing.text_chunker import ChapterContent, MinimalChunk, ChunkingResult
    
    # é‡å»ºç« èŠ‚å¯¹è±¡
    chapters = []
    for ch_data in chapters_data['chapters']:
        chapter = ChapterContent(
            chapter_id=ch_data['chapter_id'],
            title=ch_data['title'],
            content=ch_data['content'],
            start_pos=ch_data['start_pos'],
            end_pos=ch_data['end_pos'],
            word_count=ch_data['word_count'],
            has_images=ch_data['has_images'],
            has_tables=ch_data['has_tables']
        )
        chapters.append(chapter)
    
    # é‡å»ºå—å¯¹è±¡
    chunks = []
    for chunk_data in chunks_data['chunks']:
        chunk = MinimalChunk(
            chunk_id=chunk_data['chunk_id'],
            content=chunk_data['content'],
            chunk_type=chunk_data['chunk_type'],
            belongs_to_chapter=chunk_data['belongs_to_chapter'],
            chapter_title=chunk_data['chapter_title'],
            start_pos=chunk_data['start_pos'],
            end_pos=chunk_data['end_pos'],
            word_count=chunk_data['word_count']
        )
        chunks.append(chunk)
    
    # é‡å»ºåˆ†å—ç»“æœ
    result = ChunkingResult(
        first_level_chapters=chapters,
        minimal_chunks=chunks,
        total_chapters=len(chapters),
        total_chunks=len(chunks),
        processing_metadata=chunks_data['processing_metadata']
    )
    
    return result

if __name__ == "__main__":
    test_retrieval_strategy() 