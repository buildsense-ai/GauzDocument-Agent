"""
Qwen (é€šä¹‰åƒé—®) API Client
æ”¯æŒé˜¿é‡Œäº‘é€šä¹‰åƒé—®æ¨¡å‹ï¼ŒåŒ…æ‹¬æ‰¹å¤„ç†æ¨¡å¼
"""

import os
import json
import time
from typing import List, Dict, Any, Optional, Union
from openai import OpenAI
from dotenv import load_dotenv
import asyncio
from concurrent.futures import ThreadPoolExecutor, as_completed

# Load environment variables
load_dotenv()

class QwenClient:
    """é˜¿é‡Œäº‘é€šä¹‰åƒé—®APIå®¢æˆ·ç«¯ï¼Œå…¼å®¹OpenAI APIæ¥å£"""
    
    def __init__(
        self,
        api_key: Optional[str] = None,
        base_url: Optional[str] = None,
        model: str = "qwen-turbo-latest",
        max_tokens: int = 4000,
        temperature: float = 0.1,
        timeout: int = 60,
        max_retries: int = 3,
        enable_batch_mode: bool = False
    ):
        """
        åˆå§‹åŒ–Qwenå®¢æˆ·ç«¯
        
        Args:
            api_key: APIå¯†é’¥
            base_url: APIåŸºç¡€URL
            model: æ¨¡å‹åç§°
            max_tokens: æœ€å¤§tokensæ•°
            temperature: æ¸©åº¦å‚æ•°
            timeout: è¯·æ±‚è¶…æ—¶æ—¶é—´
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            enable_batch_mode: æ˜¯å¦å¯ç”¨æ‰¹å¤„ç†æ¨¡å¼
        """
        self.api_key = api_key or os.getenv("QWEN_API_KEY")
        self.base_url = base_url or os.getenv("QWEN_BASE_URL", "https://dashscope.aliyuncs.com/compatible-mode/v1")
        self.model = model
        self.max_tokens = max_tokens
        self.temperature = temperature
        self.timeout = timeout
        self.max_retries = max_retries
        self.enable_batch_mode = enable_batch_mode
        
        # è¯·æ±‚ç»Ÿè®¡
        self.request_stats = {
            "total_requests": 0,
            "successful_requests": 0,
            "failed_requests": 0,
            "total_tokens": 0,
            "timeout_errors": 0,
            "api_errors": 0
        }
        
        if not self.api_key:
            raise ValueError("Qwen API key is required. Set QWEN_API_KEY environment variable.")
        
        # åˆå§‹åŒ–OpenAIå…¼å®¹å®¢æˆ·ç«¯
        self.client = OpenAI(
            api_key=self.api_key,
            base_url=self.base_url,
            timeout=self.timeout
        )
        
        print(f"âœ… Qwenå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        print(f"ğŸ¯ æ¨¡å‹: {self.model}")
        print(f"ğŸ”— åŸºç¡€URL: {self.base_url}")
        print(f"âš¡ æ‰¹å¤„ç†æ¨¡å¼: {'å¯ç”¨' if self.enable_batch_mode else 'ç¦ç”¨'}")
    
    def generate_response(self, prompt: str, system_prompt: Optional[str] = None) -> str:
        """
        ç”Ÿæˆå•ä¸ªå“åº”
        
        Args:
            prompt: ç”¨æˆ·æç¤º
            system_prompt: ç³»ç»Ÿæç¤ºï¼ˆå¯é€‰ï¼‰
            
        Returns:
            str: æ¨¡å‹å“åº”
        """
        messages = []
        
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
        
        messages.append({"role": "user", "content": prompt})
        
        return self._call_api(messages)
    
    def call_api(self, prompt: str, system_prompt: Optional[str] = None) -> str:
        """
        è°ƒç”¨APIçš„é€šç”¨æ–¹æ³•ï¼ˆå…¼å®¹ç°æœ‰æ¥å£ï¼‰
        
        Args:
            prompt: ç”¨æˆ·æç¤º
            system_prompt: ç³»ç»Ÿæç¤ºï¼ˆå¯é€‰ï¼‰
            
        Returns:
            str: æ¨¡å‹å“åº”
        """
        return self.generate_response(prompt, system_prompt)
    
    def batch_generate_responses(self, prompts: List[str], system_prompt: Optional[str] = None, max_workers: int = 10) -> List[str]:
        """
        æ‰¹é‡ç”Ÿæˆå“åº”ï¼ˆå¹¶è¡Œå¤„ç†ï¼‰
        
        Args:
            prompts: æç¤ºåˆ—è¡¨
            system_prompt: ç³»ç»Ÿæç¤ºï¼ˆå¯é€‰ï¼‰
            max_workers: æœ€å¤§å¹¶è¡Œå·¥ä½œæ•°
            
        Returns:
            List[str]: å“åº”åˆ—è¡¨
        """
        if not prompts:
            return []
        
        print(f"ğŸš€ å¯åŠ¨æ‰¹é‡å¤„ç†ï¼š{len(prompts)} ä¸ªè¯·æ±‚ï¼Œæœ€å¤§å¹¶è¡Œæ•°: {max_workers}")
        
        results = [None] * len(prompts)
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_index = {
                executor.submit(self.generate_response, prompt, system_prompt): i
                for i, prompt in enumerate(prompts)
            }
            
            # æ”¶é›†ç»“æœ
            completed_count = 0
            for future in as_completed(future_to_index):
                index = future_to_index[future]
                try:
                    result = future.result()
                    results[index] = result
                    completed_count += 1
                    print(f"âœ… æ‰¹é‡å¤„ç†è¿›åº¦: {completed_count}/{len(prompts)}")
                except Exception as e:
                    print(f"âŒ æ‰¹é‡å¤„ç†å¤±è´¥ (ç´¢å¼• {index}): {e}")
                    results[index] = f"å¤„ç†å¤±è´¥: {e}"
        
        print(f"ğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆ: {completed_count}/{len(prompts)} æˆåŠŸ")
        return results
    
    def _call_api(self, messages: List[Dict[str, str]]) -> str:
        """
        è°ƒç”¨APIçš„æ ¸å¿ƒæ–¹æ³•
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            
        Returns:
            str: æ¨¡å‹å“åº”
        """
        for attempt in range(self.max_retries):
            try:
                self.request_stats["total_requests"] += 1
                
                # è°ƒç”¨API
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=messages,
                    max_tokens=self.max_tokens,
                    temperature=self.temperature
                )
                
                # æå–å“åº”å†…å®¹
                content = response.choices[0].message.content
                
                # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                self.request_stats["successful_requests"] += 1
                if hasattr(response, 'usage') and response.usage:
                    self.request_stats["total_tokens"] += response.usage.total_tokens
                
                return content
                
            except Exception as e:
                self.request_stats["failed_requests"] += 1
                error_msg = str(e)
                
                # åˆ†ç±»é”™è¯¯ç±»å‹
                if "timeout" in error_msg.lower():
                    self.request_stats["timeout_errors"] += 1
                    print(f"â±ï¸ è¯·æ±‚è¶…æ—¶ (å°è¯• {attempt + 1}/{self.max_retries}): {error_msg}")
                else:
                    self.request_stats["api_errors"] += 1
                    print(f"âŒ APIé”™è¯¯ (å°è¯• {attempt + 1}/{self.max_retries}): {error_msg}")
                
                # å¦‚æœä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œç­‰å¾…åé‡è¯•
                if attempt < self.max_retries - 1:
                    wait_time = (attempt + 1) * 2  # æŒ‡æ•°é€€é¿
                    print(f"â³ ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    time.sleep(wait_time)
                else:
                    # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸
                    raise Exception(f"APIè°ƒç”¨å¤±è´¥ï¼Œå·²é‡è¯• {self.max_retries} æ¬¡: {error_msg}")
        
        return ""
    
    def get_stats(self) -> Dict[str, Any]:
        """
        è·å–è¯·æ±‚ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            Dict[str, Any]: ç»Ÿè®¡ä¿¡æ¯
        """
        return {
            **self.request_stats,
            "success_rate": (
                self.request_stats["successful_requests"] / max(1, self.request_stats["total_requests"])
            ) * 100,
            "timeout_rate": (
                self.request_stats["timeout_errors"] / max(1, self.request_stats["total_requests"])
            ) * 100,
            "api_error_rate": (
                self.request_stats["api_errors"] / max(1, self.request_stats["total_requests"])
            ) * 100
        }
    
    def print_stats(self):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.get_stats()
        print("\nğŸ“Š Qwenå®¢æˆ·ç«¯ç»Ÿè®¡ä¿¡æ¯:")
        print(f"æ€»è¯·æ±‚æ•°: {stats['total_requests']}")
        print(f"æˆåŠŸè¯·æ±‚: {stats['successful_requests']}")
        print(f"å¤±è´¥è¯·æ±‚: {stats['failed_requests']}")
        print(f"æˆåŠŸç‡: {stats['success_rate']:.1f}%")
        print(f"è¶…æ—¶ç‡: {stats['timeout_rate']:.1f}%")
        print(f"APIé”™è¯¯ç‡: {stats['api_error_rate']:.1f}%")
        print(f"æ€»tokens: {stats['total_tokens']}") 