"""
æ€»ç›‘Agent (Orchestrator Agent)

è´Ÿè´£æœ€é«˜å±‚çš„è§„åˆ’ï¼Œç‰¹åˆ«æ˜¯ç”Ÿæˆç›®æ ‡æ–‡æ¡£çš„å¤§çº²ã€‚
"""

import json
from typing import List, Dict, Any

from .mock_retrieval_tool import MockKnowledgeSearchTool
# from ..deepseek_client import DeepSeekClient # å‡è®¾ä½ æœ‰ä¸€ä¸ªLLMå®¢æˆ·ç«¯

class OrchestratorAgent:
    """
    è§„åˆ’å’Œç¼–æ’æ•´ä¸ªé•¿æ–‡ç”Ÿæˆæµç¨‹çš„Agentã€‚
    """
    def __init__(self):
        # åœ¨çœŸå®åœºæ™¯ä¸­ï¼Œè¿™é‡Œä¼šæ³¨å…¥ä¸€ä¸ªçœŸæ­£çš„LLMå®¢æˆ·ç«¯
        # self.llm_client = DeepSeekClient()
        self.retrieval_tool = MockKnowledgeSearchTool()
        self.system_prompt = """
ä½ æ˜¯ä¸€ä½é¡¶çº§çš„é¡¹ç›®æ€»ç›‘å’Œè§„åˆ’å¸ˆï¼Œæ“…é•¿é«˜å±‹å»ºç“´åœ°è¿›è¡Œç»“æ„è®¾è®¡ã€‚
ä½ çš„ä»»åŠ¡æ˜¯åŸºäºæºæ–‡æ¡£çš„æ ¸å¿ƒç»“æ„ï¼Œä¸ºä¸€ä»½æ–°çš„ã€ä¸»é¢˜ç›¸å…³çš„æ–‡æ¡£è®¾è®¡ä¸€ä¸ªä¸“ä¸šã€è¯¦ç»†ã€é€»è¾‘æ¸…æ™°çš„ç« èŠ‚å¤§çº²ã€‚
ä½ å¿…é¡»ä¸¥æ ¼æŒ‰ç…§æŒ‡å®šçš„JSONæ ¼å¼è¾“å‡ºã€‚
"""
        print("ğŸ‘¨â€ğŸ’¼ [OrchestratorAgent] åˆå§‹åŒ–æˆåŠŸã€‚")

    def generate_outline(self, source_document_id: str, target_document_description: str) -> List[Dict[str, Any]]:
        """
        ç”Ÿæˆç›®æ ‡æ–‡æ¡£çš„å¤§çº²ã€‚

        Args:
            source_document_id: æºæ–‡æ¡£çš„IDï¼Œç”¨äºæ£€ç´¢ã€‚
            target_document_description: å¯¹ç›®æ ‡æ–‡æ¡£çš„ç®€å•æè¿°ï¼Œå¦‚â€œä¸€ä»½å…³äºåŒ»çµå¤åº™çš„æ–‡ç‰©è¯„ä¼°æ–¹æ¡ˆâ€ã€‚

        Returns:
            ä¸€ä¸ªä»£è¡¨å¤§çº²çš„å­—å…¸åˆ—è¡¨ï¼Œä¾‹å¦‚ [{'chapter': '1.0', 'title': '...'}, ...]ã€‚
        """
        print(f"ğŸ‘¨â€ğŸ’¼ [OrchestratorAgent] å¼€å§‹ä¸º '{target_document_description}' ç”Ÿæˆå¤§çº²...")

        # 1. è°ƒç”¨æ£€ç´¢å·¥å…·ï¼Œè·å–æºæ–‡æ¡£çš„æ•´ä½“ç»“æ„
        print("ğŸ‘¨â€ğŸ’¼ [OrchestratorAgent] æ­¥éª¤1: æ£€ç´¢æºæ–‡æ¡£çš„æ ¸å¿ƒç»“æ„...")
        retrieval_result_json = self.retrieval_tool.execute(
            queries=["æ–‡æ¡£ç›®å½•", "æ–‡æ¡£ç»“æ„"],
            filters={"document_id": source_document_id}
        )
        retrieval_result = json.loads(retrieval_result_json)
        source_structure = retrieval_result.get("retrieved_items", [])

        if not source_structure:
            print("ğŸ‘¨â€ğŸ’¼ [OrchestratorAgent] è­¦å‘Š: æœªèƒ½ä»æºæ–‡æ¡£æ£€ç´¢åˆ°ç»“æ„ä¿¡æ¯ã€‚å°†å°è¯•ç”Ÿæˆé€šç”¨å¤§çº²ã€‚")

        # 2. æ„å»ºPromptï¼Œè¯·æ±‚LLMç”Ÿæˆå¤§çº²
        print("ğŸ‘¨â€ğŸ’¼ [OrchestratorAgent] æ­¥éª¤2: è¯·æ±‚LLMè®¾è®¡æ–°å¤§çº²...")
        generation_prompt = f"""
æºæ–‡æ¡£çš„æ ¸å¿ƒç« èŠ‚ç»“æ„å¦‚ä¸‹:
{json.dumps(source_structure, indent=2, ensure_ascii=False)}

è¯·åŸºäºä»¥ä¸Šæºæ–‡æ¡£ç»“æ„ï¼Œä¸ºä¸€ä»½æ–°çš„æ–‡æ¡£ã€Š{target_document_description}ã€‹è®¾è®¡ä¸€ä¸ªä¸“ä¸šã€è¯¦ç»†çš„å¤§çº²ã€‚

è¯·ä»¥JSONæ ¼å¼è¿”å›ä¸€ä¸ªåŒ…å«ç« èŠ‚å·å’Œæ ‡é¢˜çš„åˆ—è¡¨ã€‚ä¾‹å¦‚:
[
  {{"chapter": "1.0", "title": "å¼•è¨€"}},
  {{"chapter": "2.0", "title": "æ–‡ç‰©ä»·å€¼è¯„ä¼°"}},
  {{"chapter": "2.1", "title": "å†å²ä»·å€¼"}}
]
"""
        
        # --- çœŸå®LLMè°ƒç”¨å‘ç”Ÿåœ¨è¿™é‡Œ ---
        # response = self.llm_client.generate(self.system_prompt, generation_prompt)
        # return json.loads(response)
        
        # --- ä½¿ç”¨ç¡¬ç¼–ç çš„æ¨¡æ‹Ÿè¾“å‡ºæ¥è¿›è¡Œå¼€å‘ ---
        print("ğŸ‘¨â€ğŸ’¼ [OrchestratorAgent] (æ¨¡æ‹ŸLLM) ç”Ÿæˆå¤§çº²...")
        mock_outline = [
            {"chapter": "1.0", "title": "é¡¹ç›®æ¦‚å†µä¸è¯„ä¼°ä¾æ®"},
            {"chapter": "2.0", "title": "æ–‡ç‰©æœ¬ä½“ç°çŠ¶è¯„ä¼°"},
            {"chapter": "3.0", "title": "æ ¸å¿ƒä»·å€¼è¯„ä¼°"},
            {"chapter": "3.1", "title": "å†å²ä¸è‰ºæœ¯ä»·å€¼è¯„ä¼°"},
            {"chapter": "3.2", "title": "ç»“æ„å®‰å…¨æ€§è¯„ä¼°"},
            {"chapter": "4.0", "title": "ä¿æŠ¤å»ºè®®ä¸ç»“è®º"}
        ]
        print(f"ğŸ‘¨â€ğŸ’¼ [OrchestratorAgent] å¤§çº²ç”ŸæˆæˆåŠŸï¼ŒåŒ…å« {len(mock_outline)} ä¸ªç« èŠ‚ã€‚")
        return mock_outline

