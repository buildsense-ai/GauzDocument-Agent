#!/usr/bin/env python3
"""
Metadata Bug Fix Script

ä¿®å¤ç°æœ‰metadataæ–‡ä»¶ä¸­çš„å‡ ä¸ªé—®é¢˜ï¼š
1. å›¾ç‰‡chunksä¸­çš„detailed_descriptionå­—æ®µåŒ…å«JSONå­—ç¬¦ä¸²è€Œéçº¯æ–‡æœ¬
2. ç§»é™¤å·²åºŸå¼ƒçš„å­—æ®µï¼ˆpage_number, page_rangeï¼‰
3. ç¡®ä¿æ‰€æœ‰å­—æ®µéƒ½æ­£ç¡®æ ¼å¼åŒ–

Usage:
    python fix_metadata_bug.py <metadata_file_path>
"""

import json
import re
import argparse
from pathlib import Path
from typing import Dict, Any, Optional


def extract_json_from_markdown(text: str) -> Optional[Dict[str, Any]]:
    """ä»markdownæ ¼å¼çš„JSONå­—ç¬¦ä¸²ä¸­æå–å®é™…çš„JSONå¯¹è±¡"""
    if not text:
        return None
    
    try:
        # ç›´æ¥å°è¯•è§£æ
        return json.loads(text)
    except json.JSONDecodeError:
        pass
    
    # æŸ¥æ‰¾ ```json ... ``` æˆ– ``` ... ``` æ ¼å¼
    json_match = re.search(r'```(?:json)?\s*\n?(.*?)\n?```', text, re.DOTALL)
    if json_match:
        json_str = json_match.group(1).strip()
        try:
            return json.loads(json_str)
        except json.JSONDecodeError:
            pass
    
    # æŸ¥æ‰¾ç¬¬ä¸€ä¸ª { åˆ°æœ€åä¸€ä¸ª } ä¹‹é—´çš„å†…å®¹
    brace_match = re.search(r'\{.*\}', text, re.DOTALL)
    if brace_match:
        json_str = brace_match.group(0)
        try:
            return json.loads(json_str)
        except json.JSONDecodeError:
            pass
    
    return None


def fix_image_chunk(image_chunk: Dict[str, Any]) -> bool:
    """ä¿®å¤å•ä¸ªå›¾ç‰‡chunkçš„æè¿°å­—æ®µ"""
    fixed = False
    
    # æ£€æŸ¥detailed_descriptionå­—æ®µæ˜¯å¦åŒ…å«JSONå­—ç¬¦ä¸²
    detailed_desc = image_chunk.get('detailed_description')
    if detailed_desc and isinstance(detailed_desc, str):
        extracted_json = extract_json_from_markdown(detailed_desc)
        if extracted_json:
            # æå–å„ä¸ªå­—æ®µ
            search_summary = extracted_json.get('search_summary')
            detailed_description = extracted_json.get('detailed_description')
            engineering_details = extracted_json.get('engineering_details')
            
            # æ›´æ–°å­—æ®µ
            if search_summary and search_summary != "AIç”Ÿæˆçš„å›¾ç‰‡æè¿°":
                image_chunk['search_summary'] = search_summary
                fixed = True
            
            if detailed_description:
                image_chunk['detailed_description'] = detailed_description
                fixed = True
            
            if engineering_details is not None:
                image_chunk['engineering_details'] = engineering_details
                fixed = True
            
            if fixed:
                print(f"âœ… ä¿®å¤å›¾ç‰‡ {image_chunk.get('content_id', 'unknown')}")
    
    return fixed


def remove_deprecated_fields(data: Dict[str, Any]) -> int:
    """ç§»é™¤å·²åºŸå¼ƒçš„å­—æ®µ"""
    removed_count = 0
    
    # ç§»é™¤text_chunksä¸­çš„page_numberå­—æ®µ
    text_chunks = data.get('text_chunks', [])
    for chunk in text_chunks:
        if 'page_number' in chunk:
            del chunk['page_number']
            removed_count += 1
    
    # ç§»é™¤chapter_summariesä¸­çš„page_rangeå­—æ®µ
    chapter_summaries = data.get('chapter_summaries', [])
    for chapter in chapter_summaries:
        if 'page_range' in chapter:
            del chapter['page_range']
            removed_count += 1
    
    return removed_count


def fix_metadata_file(file_path: str, output_path: Optional[str] = None) -> None:
    """ä¿®å¤metadataæ–‡ä»¶"""
    file_path_obj = Path(file_path)
    
    if not file_path_obj.exists():
        raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path_obj}")
    
    print(f"ğŸ“– è¯»å–metadataæ–‡ä»¶: {file_path_obj}")
    
    # è¯»å–åŸæ–‡ä»¶
    with open(file_path_obj, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    # ç»Ÿè®¡ä¿®å¤æƒ…å†µ
    fixed_images = 0
    
    # ä¿®å¤å›¾ç‰‡chunks
    image_chunks = data.get('image_chunks', [])
    for image_chunk in image_chunks:
        if fix_image_chunk(image_chunk):
            fixed_images += 1
    
    # ç§»é™¤åºŸå¼ƒå­—æ®µ
    removed_fields = remove_deprecated_fields(data)
    
    # ç§»é™¤document_summaryä¸­çš„metadataå­—æ®µï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    doc_summary = data.get('document_summary', {})
    if 'metadata' in doc_summary:
        del doc_summary['metadata']
        removed_fields += 1
        print("âœ… ç§»é™¤document_summary.metadataå­—æ®µ")
    
    # ç¡®å®šè¾“å‡ºè·¯å¾„
    if output_path is None:
        output_path_obj = file_path_obj.parent / f"{file_path_obj.stem}_fixed{file_path_obj.suffix}"
    else:
        output_path_obj = Path(output_path)
    
    # å†™å…¥ä¿®å¤åçš„æ–‡ä»¶
    with open(output_path_obj, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ’¾ ä¿®å¤åçš„æ–‡ä»¶å·²ä¿å­˜åˆ°: {output_path_obj}")
    print(f"ğŸ“Š ä¿®å¤ç»Ÿè®¡:")
    print(f"  - ä¿®å¤çš„å›¾ç‰‡: {fixed_images}")
    print(f"  - ç§»é™¤çš„åºŸå¼ƒå­—æ®µ: {removed_fields}")
    
    if fixed_images > 0 or removed_fields > 0:
        print("âœ… ä¿®å¤å®Œæˆ!")
    else:
        print("â„¹ï¸  æ²¡æœ‰å‘ç°éœ€è¦ä¿®å¤çš„é—®é¢˜")


def main():
    parser = argparse.ArgumentParser(description="ä¿®å¤PDFå¤„ç†metadataæ–‡ä»¶ä¸­çš„bug")
    parser.add_argument("metadata_file", help="è¦ä¿®å¤çš„metadataæ–‡ä»¶è·¯å¾„")
    parser.add_argument("-o", "--output", help="è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ä¸ºåŸæ–‡ä»¶ååŠ _fixedåç¼€ï¼‰")
    
    args = parser.parse_args()
    
    try:
        fix_metadata_file(args.metadata_file, args.output)
    except Exception as e:
        print(f"âŒ ä¿®å¤å¤±è´¥: {e}")
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main()) 