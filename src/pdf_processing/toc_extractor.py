#!/usr/bin/env python3
"""
TOCæå–å™¨ - ç”Ÿäº§ç‰ˆæœ¬
ä½¿ç”¨ç»Ÿä¸€çš„QwenClientè¿›è¡ŒAPIè°ƒç”¨
åŸºäºAIæ¨ç†æ¨¡å¼æå–æ–‡æ¡£ç›®å½•ç»“æ„
"""

import json
import os
import sys
import time
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))

from src.qwen_client import QwenClient

@dataclass
class TOCItem:
    """TOCæ¡ç›®æ•°æ®ç»“æ„"""
    title: str
    level: int
    start_text: str  # ç”¨äºåŒ¹é…çš„å¼€å¤´æ–‡æœ¬
    id: str
    parent_id: Optional[str] = None

class TOCExtractor:
    """TOCæå–å™¨ - ä½¿ç”¨ç»Ÿä¸€çš„QwenClient"""
    
    def __init__(self, model: str = "qwen-plus"):
        """
        åˆå§‹åŒ–TOCæå–å™¨
        
        Args:
            model: ä½¿ç”¨çš„æ¨¡å‹åç§°
        """
        self.client = QwenClient(
            model=model,
            temperature=0.1,
            max_retries=3
        )
        self.model = model
    
    def stitch_full_text(self, basic_result_path: str) -> str:
        """
        æ‹¼æ¥å®Œæ•´æ–‡æœ¬ï¼Œä¿æŒé¡µé¢é¡ºåº
        
        Args:
            basic_result_path: åŸºç¡€è§£æç»“æœæ–‡ä»¶è·¯å¾„
            
        Returns:
            str: æ‹¼æ¥åçš„å®Œæ•´æ–‡æœ¬
        """
        if not os.path.exists(basic_result_path):
            raise FileNotFoundError(f"åŸºç¡€è§£æç»“æœæ–‡ä»¶ä¸å­˜åœ¨: {basic_result_path}")
        
        with open(basic_result_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        pages = data.get('pages', [])
        full_text_parts = []
        
        # å…¨å±€è®¡æ•°å™¨ï¼Œç”¨äºç”Ÿæˆå”¯ä¸€ID
        global_image_counter = 0
        global_table_counter = 0
        
        for page in pages:
            cleaned_text = page.get('cleaned_text', '') or ''
            images = page.get('images', [])
            tables = page.get('tables', [])
            
            # æ·»åŠ é¡µé¢æ–‡æœ¬
            if cleaned_text and cleaned_text.strip():
                full_text_parts.append(cleaned_text.strip())
            
            # æ·»åŠ å›¾ç‰‡æè¿°ï¼ˆåŒ…å«å”¯ä¸€æ ‡è¯†ç¬¦ï¼‰
            for image in images:
                global_image_counter += 1
                description = image.get('ai_description', 'å›¾ç‰‡æè¿°') or 'å›¾ç‰‡æè¿°'
                image_path = image.get('image_path', '')
                # æ ¼å¼ï¼š[å›¾ç‰‡|ID:xxx|PATH:xxx: æè¿°]
                full_text_parts.append(f"[å›¾ç‰‡|ID:{global_image_counter}|PATH:{image_path}: {description}]")
            
            # æ·»åŠ è¡¨æ ¼æè¿°ï¼ˆåŒ…å«å”¯ä¸€æ ‡è¯†ç¬¦ï¼‰
            for table in tables:
                global_table_counter += 1
                description = table.get('ai_description', 'è¡¨æ ¼æè¿°') or 'è¡¨æ ¼æè¿°'
                table_path = table.get('table_path', '')
                # æ ¼å¼ï¼š[è¡¨æ ¼|ID:xxx|PATH:xxx: æè¿°]
                full_text_parts.append(f"[è¡¨æ ¼|ID:{global_table_counter}|PATH:{table_path}: {description}]")
        
        # ç”¨åŒæ¢è¡Œè¿æ¥ï¼Œä¿æŒæ®µè½åˆ†éš”
        full_text = "\n\n".join(full_text_parts)
        
        print(f"âœ… æ–‡æœ¬ç¼åˆå®Œæˆï¼Œæ€»é•¿åº¦: {len(full_text)} å­—ç¬¦")
        print(f"ğŸ“„ æ€»é¡µæ•°: {len(pages)}")
        print(f"ğŸ–¼ï¸ åŒ…å«å›¾ç‰‡: {global_image_counter} ä¸ª")
        print(f"ğŸ“Š åŒ…å«è¡¨æ ¼: {global_table_counter} ä¸ª")
        
        return full_text
    
    def extract_toc_with_reasoning(self, full_text: str) -> Tuple[List[TOCItem], str]:
        """
        ä½¿ç”¨AIæ¨ç†æ¨¡å¼æå–TOC
        
        Args:
            full_text: å®Œæ•´æ–‡æ¡£æ–‡æœ¬
            
        Returns:
            Tuple[List[TOCItem], str]: TOCé¡¹ç›®åˆ—è¡¨å’Œæ¨ç†å†…å®¹
        """
        print("ğŸ§  å¼€å§‹ä½¿ç”¨AIæ¨ç†æ¨¡å¼æå–TOC...")
        
        # ç³»ç»Ÿæç¤º
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æ¡£ç»“æ„åˆ†æå¸ˆã€‚è¯·åˆ†ææ–‡æ¡£æ–‡æœ¬ï¼Œæå–å®Œæ•´çš„ç›®å½•ç»“æ„(TOC)ã€‚

è¦æ±‚ï¼š
1. è¯†åˆ«æ‰€æœ‰å±‚çº§çš„ç« èŠ‚æ ‡é¢˜ï¼ˆä¸€çº§ã€äºŒçº§ã€ä¸‰çº§ç­‰ï¼‰
2. ä¸ºæ¯ä¸ªç« èŠ‚æä¾›ç”¨äºåŒ¹é…çš„å¼€å¤´æ–‡æœ¬ç‰‡æ®µï¼ˆ20-40ä¸ªå­—ç¬¦ï¼‰
3. åˆ†æç« èŠ‚çš„å±‚çº§å…³ç³»ï¼Œæ­£ç¡®è®¾ç½®parent_id
4. ä½¿ç”¨æ•°å­—IDæ ¼å¼ï¼ˆ1, 2, 3ç­‰ï¼‰

è¿”å›JSONæ ¼å¼ï¼š
{
  "toc": [
    {
      "title": "ç« èŠ‚æ ‡é¢˜",
      "level": 1,
      "start_text": "ç« èŠ‚å¼€å¤´çš„æ–‡æœ¬ç‰‡æ®µï¼Œç”¨äºç²¾ç¡®åŒ¹é…",
      "id": "1",
      "parent_id": null
    },
    {
      "title": "å­ç« èŠ‚æ ‡é¢˜",
      "level": 2,
      "start_text": "å­ç« èŠ‚å¼€å¤´çš„æ–‡æœ¬ç‰‡æ®µ",
      "id": "2",
      "parent_id": "1"
    }
  ]
}

æ³¨æ„ï¼š
- levelä»1å¼€å§‹ï¼ˆ1=ä¸€çº§æ ‡é¢˜ï¼Œ2=äºŒçº§æ ‡é¢˜ï¼Œä»¥æ­¤ç±»æ¨ï¼‰
- start_textåº”è¯¥æ˜¯ç« èŠ‚æ ‡é¢˜åç´§æ¥ç€çš„æ–‡æœ¬ï¼Œç”¨äºç²¾ç¡®åŒ¹é…
- idä½¿ç”¨ç®€å•çš„æ•°å­—æ ¼å¼ï¼š1, 2, 3, 4ç­‰
- parent_idæŒ‡å‘ä¸Šçº§ç« èŠ‚çš„idï¼Œä¸€çº§ç« èŠ‚çš„parent_idä¸ºnull
- ç¡®ä¿å±‚çº§å…³ç³»æ­£ç¡®ï¼ŒäºŒçº§ç« èŠ‚çš„parent_idåº”è¯¥æŒ‡å‘å…¶æ‰€å±çš„ä¸€çº§ç« èŠ‚
"""
        
        # ç”¨æˆ·æç¤º
        user_prompt = f"""è¯·ä»”ç»†åˆ†æä»¥ä¸‹æ–‡æ¡£æ–‡æœ¬ï¼Œæå–å®Œæ•´çš„ç›®å½•ç»“æ„ã€‚

è¯·ä½¿ç”¨æ¨ç†æ¨¡å¼åˆ†ææ–‡æ¡£ç»“æ„ï¼Œè¯†åˆ«æ‰€æœ‰ç« èŠ‚æ ‡é¢˜å’Œå±‚çº§å…³ç³»ï¼š

{full_text}

è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¿”å›ç»“æœï¼Œç¡®ä¿æ‰€æœ‰å­—æ®µéƒ½æ­£ç¡®å¡«å†™ã€‚
"""
        
        try:
            print("ğŸ”„ æ­£åœ¨è°ƒç”¨AIæ¨ç†æ¨¡å¼...")
            
            # ä½¿ç”¨ç»Ÿä¸€çš„å®¢æˆ·ç«¯è¿›è¡ŒAPIè°ƒç”¨
            content, reasoning_content = self.client.generate_response_with_reasoning(
                prompt=user_prompt,
                system_prompt=system_prompt,
                enable_thinking=True,
                stream=True
            )
            
            print(f"\nâœ… æ¨ç†å†…å®¹æ”¶é›†å®Œæˆï¼Œå…± {len(reasoning_content)} å­—ç¬¦")
            print(f"ğŸ“ ä¸»è¦å“åº”å†…å®¹ï¼Œå…± {len(content)} å­—ç¬¦")
            
            # å¤„ç†JSONå“åº”
            if content.startswith('```json'):
                json_start = content.find('{')
                json_end = content.rfind('}') + 1
                if json_start != -1 and json_end != -1:
                    content = content[json_start:json_end]
            
            # è§£æJSON
            try:
                result = json.loads(content)
                toc_data = result.get('toc', [])
                
                # è½¬æ¢ä¸ºTOCItemå¯¹è±¡
                toc_items = []
                for item in toc_data:
                    toc_item = TOCItem(
                        title=item.get('title', ''),
                        level=item.get('level', 1),
                        start_text=item.get('start_text', ''),
                        id=str(item.get('id', '')),
                        parent_id=item.get('parent_id')
                    )
                    toc_items.append(toc_item)
                
                print(f"âœ… TOCæå–æˆåŠŸï¼Œå…±è¯†åˆ« {len(toc_items)} ä¸ªç« èŠ‚")
                
                # æ˜¾ç¤ºæå–ç»“æœ
                for item in toc_items:
                    indent = "  " * (item.level - 1)
                    parent_info = f" (çˆ¶çº§: {item.parent_id})" if item.parent_id else ""
                    print(f"{indent}{item.level}. {item.title}{parent_info}")
                
                return toc_items, reasoning_content
                
            except json.JSONDecodeError as e:
                print(f"âŒ JSONè§£æå¤±è´¥: {e}")
                print(f"ğŸ” åŸå§‹å“åº”: {content}")
                return [], reasoning_content
                
        except Exception as e:
            print(f"âŒ APIè°ƒç”¨å¤±è´¥: {e}")
            return [], ""
    
    def save_toc_result(self, toc_items: List[TOCItem], reasoning_content: str, output_path: str):
        """
        ä¿å­˜TOCæå–ç»“æœ
        
        Args:
            toc_items: TOCé¡¹ç›®åˆ—è¡¨
            reasoning_content: æ¨ç†å†…å®¹
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        toc_dict = {
            "toc": [
                {
                    "title": item.title,
                    "level": item.level,
                    "start_text": item.start_text,
                    "id": item.id,
                    "parent_id": item.parent_id
                }
                for item in toc_items
            ],
            "extraction_time": time.time(),
            "total_chapters": len(toc_items),
            "reasoning_content": reasoning_content,
            "model_used": self.model
        }
        
        # ä¿å­˜ç»“æœ
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(toc_dict, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“ TOCç»“æœå·²ä¿å­˜åˆ°: {output_path}")
    
    def save_full_text_debug(self, full_text: str, output_path: str):
        """
        ä¿å­˜å®Œæ•´æ–‡æœ¬ç”¨äºè°ƒè¯•
        
        Args:
            full_text: å®Œæ•´æ–‡æœ¬
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(full_text)
        
        print(f"ğŸ“ å®Œæ•´æ–‡æœ¬å·²ä¿å­˜åˆ°: {output_path}")
    
    def print_client_stats(self):
        """æ‰“å°å®¢æˆ·ç«¯ç»Ÿè®¡ä¿¡æ¯"""
        print("\nğŸ“Š APIè°ƒç”¨ç»Ÿè®¡:")
        self.client.print_stats()

def main():
    """ä¸»å‡½æ•°"""
    # è¾“å…¥æ–‡ä»¶è·¯å¾„
    input_file = "parser_output/20250714_232720_vvmpc0/basic_processing_result.json"
    
    if not os.path.exists(input_file):
        print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
        return
    
    # åˆ›å»ºæå–å™¨
    extractor = TOCExtractor()
    
    # ç¼åˆå®Œæ•´æ–‡æœ¬
    full_text = extractor.stitch_full_text(input_file)
    
    # ä¿å­˜å®Œæ•´æ–‡æœ¬ç”¨äºè°ƒè¯•
    output_dir = os.path.dirname(input_file)
    full_text_path = os.path.join(output_dir, "full_text.txt")
    extractor.save_full_text_debug(full_text, full_text_path)
    
    # æå–TOC
    toc_items, reasoning_content = extractor.extract_toc_with_reasoning(full_text)
    
    # è¾“å‡ºæ¨ç†å†…å®¹
    if reasoning_content:
        print("\n" + "="*50)
        print("ğŸ§  AIæ¨ç†å†…å®¹:")
        print("="*50)
        print(reasoning_content)
        print("="*50)
    
    # ä¿å­˜ç»“æœ
    if toc_items:
        result_path = os.path.join(output_dir, "toc_extraction_result.json")
        extractor.save_toc_result(toc_items, reasoning_content, result_path)
        print(f"\nğŸ‰ TOCæå–å®Œæˆ! ç»“æœä¿å­˜åœ¨: {result_path}")
    else:
        print("âŒ TOCæå–å¤±è´¥")
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    extractor.print_client_stats()

if __name__ == "__main__":
    main() 