#!/usr/bin/env python3
"""
AIæ™ºèƒ½åˆ†å—å™¨
ä½¿ç”¨è½»é‡æ¨¡å‹(qwen turbo)å¯¹ç« èŠ‚å†…å®¹è¿›è¡Œæ™ºèƒ½åˆ†å—
æ›¿ä»£æ­£åˆ™è¡¨è¾¾å¼çš„æ®µè½åˆ‡å‰²
"""

import json
import logging
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
import asyncio
import concurrent.futures
from pathlib import Path
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))

from src.qwen_client import QwenClient

logger = logging.getLogger(__name__)

@dataclass
class MinimalChunk:
    """æœ€å°åˆ†å—ä¿¡æ¯"""
    chunk_id: str
    content: str
    chunk_type: str  # paragraph, list_item, heading, image_desc, table_desc
    belongs_to_chapter: str  # ç« èŠ‚ID
    chapter_title: str
    start_pos: int  # åœ¨ç« èŠ‚ä¸­çš„ä½ç½®
    end_pos: int
    word_count: int

class AIChunker:
    """AIæ™ºèƒ½åˆ†å—å™¨"""
    
    def __init__(self, model: str = "qwen-turbo"):
        """
        åˆå§‹åŒ–AIåˆ†å—å™¨
        
        Args:
            model: ä½¿ç”¨çš„è½»é‡æ¨¡å‹ï¼Œé»˜è®¤qwen-turbo
        """
        self.client = QwenClient(
            model=model,
            temperature=0.1,
            max_retries=2
        )
        self.model = model
        print(f"âœ… AIåˆ†å—å™¨åˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨æ¨¡å‹: {model}")
    
    async def chunk_chapter_async(self, 
                                chapter_id: str, 
                                chapter_title: str, 
                                chapter_content: str,
                                start_chunk_id: int) -> List[MinimalChunk]:
        """
        å¼‚æ­¥å¯¹å•ä¸ªç« èŠ‚è¿›è¡Œæ™ºèƒ½åˆ†å—
        
        Args:
            chapter_id: ç« èŠ‚ID
            chapter_title: ç« èŠ‚æ ‡é¢˜
            chapter_content: ç« èŠ‚å†…å®¹
            start_chunk_id: èµ·å§‹åˆ†å—ID
            
        Returns:
            List[MinimalChunk]: åˆ†å—ç»“æœåˆ—è¡¨
        """
        return await asyncio.get_event_loop().run_in_executor(
            None, 
            self.chunk_chapter_sync,
            chapter_id, chapter_title, chapter_content, start_chunk_id
        )
    
    def chunk_chapter_sync(self, 
                          chapter_id: str, 
                          chapter_title: str, 
                          chapter_content: str,
                          start_chunk_id: int) -> List[MinimalChunk]:
        """
        åŒæ­¥å¯¹å•ä¸ªç« èŠ‚è¿›è¡Œæ™ºèƒ½åˆ†å—
        
        Args:
            chapter_id: ç« èŠ‚ID
            chapter_title: ç« èŠ‚æ ‡é¢˜
            chapter_content: ç« èŠ‚å†…å®¹
            start_chunk_id: èµ·å§‹åˆ†å—ID
            
        Returns:
            List[MinimalChunk]: åˆ†å—ç»“æœåˆ—è¡¨
        """
        print(f"ğŸ”ª å¼€å§‹AIæ™ºèƒ½åˆ†å—ç« èŠ‚: {chapter_title}")
        
        # å¦‚æœå†…å®¹å¤ªçŸ­ï¼Œç›´æ¥è¿”å›å•ä¸ªåˆ†å—
        if len(chapter_content.strip()) < 100:
            return [MinimalChunk(
                chunk_id=f"{chapter_id}_{start_chunk_id}",
                content=chapter_content.strip(),
                chunk_type="paragraph",
                belongs_to_chapter=chapter_id,
                chapter_title=chapter_title,
                start_pos=0,
                end_pos=len(chapter_content),
                word_count=len(chapter_content.strip())
            )]
        
        # æ„å»ºæç¤ºè¯
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æ¡£åˆ†å—åŠ©æ‰‹ã€‚è¯·å°†ç»™å®šçš„ç« èŠ‚å†…å®¹æ™ºèƒ½åˆ†å‰²æˆåˆç†çš„åˆ†å—ï¼Œæ¯ä¸ªåˆ†å—åº”è¯¥æ˜¯ä¸€ä¸ªå®Œæ•´çš„è¯­ä¹‰å•å…ƒã€‚

åˆ†å—åŸåˆ™ï¼š
1. ä¿æŒè¯­ä¹‰å®Œæ•´æ€§ - æ¯ä¸ªåˆ†å—åº”è¯¥æ˜¯ä¸€ä¸ªå®Œæ•´çš„æ€æƒ³æˆ–æ¦‚å¿µ
2. é€‚å½“çš„é•¿åº¦ - æ¯ä¸ªåˆ†å—100-500å­—ç¬¦ä¸ºå®œ
3. å°Šé‡åŸæ–‡ç»“æ„ - ä¿æŒæ®µè½ã€åˆ—è¡¨ã€è¡¨æ ¼çš„å®Œæ•´æ€§
4. å›¾ç‰‡è¡¨æ ¼ä½ç½® - [å›¾ç‰‡:...] å’Œ [è¡¨æ ¼:...] åº”è¯¥ä¸ç›¸å…³æ–‡æœ¬åœ¨åŒä¸€åˆ†å—ä¸­

è¯·è¿”å›JSONæ ¼å¼ï¼š
{
  "chunks": [
    {
      "content": "åˆ†å—å†…å®¹",
      "type": "paragraph|list_item|heading|mixed",
      "reason": "åˆ†å—åŸå› è¯´æ˜"
    }
  ]
}

æ³¨æ„ï¼š
- ä¸è¦ä¿®æ”¹åŸæ–‡å†…å®¹ï¼Œåªè¿›è¡Œåˆ†å—
- ä¿æŒ[å›¾ç‰‡:...]å’Œ[è¡¨æ ¼:...]æ ‡è®°ä¸å˜
- å¦‚æœå›¾ç‰‡/è¡¨æ ¼åœ¨æ®µè½ä¸­é—´ï¼Œå°†å…¶ä¸ç›¸å…³æ–‡æœ¬æ”¾åœ¨åŒä¸€åˆ†å—ä¸­"""

        user_prompt = f"""è¯·å¯¹ä»¥ä¸‹ç« èŠ‚å†…å®¹è¿›è¡Œæ™ºèƒ½åˆ†å—ï¼š

ç« èŠ‚æ ‡é¢˜ï¼š{chapter_title}

ç« èŠ‚å†…å®¹ï¼š
{chapter_content}

è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¿”å›åˆ†å—ç»“æœã€‚"""
        
        try:
            # è°ƒç”¨AIæ¨¡å‹è¿›è¡Œåˆ†å—
            response = self.client.generate_response(
                prompt=user_prompt,
                system_prompt=system_prompt
            )
            
            # è§£æå“åº”
            chunks_data = self._parse_chunking_response(response)
            
            # è½¬æ¢ä¸ºMinimalChunkå¯¹è±¡
            chunks = self._convert_to_minimal_chunks(
                chunks_data, chapter_id, chapter_title, 
                chapter_content, start_chunk_id
            )
            
            print(f"âœ… ç« èŠ‚ {chapter_title} åˆ†å—å®Œæˆ: {len(chunks)} ä¸ªåˆ†å—")
            return chunks
            
        except Exception as e:
            print(f"âŒ AIåˆ†å—å¤±è´¥ï¼Œä½¿ç”¨å›é€€æ–¹æ¡ˆ: {e}")
            # å›é€€åˆ°ç®€å•åˆ†å‰²
            return self._fallback_chunking(
                chapter_id, chapter_title, chapter_content, start_chunk_id
            )
    
    def _parse_chunking_response(self, response: str) -> List[Dict[str, Any]]:
        """è§£æAIåˆ†å—å“åº”"""
        try:
            # æå–JSONéƒ¨åˆ†
            if '```json' in response:
                json_start = response.find('{')
                json_end = response.rfind('}') + 1
                if json_start != -1 and json_end > json_start:
                    response = response[json_start:json_end]
            
            # è§£æJSON
            result = json.loads(response)
            return result.get('chunks', [])
            
        except json.JSONDecodeError as e:
            print(f"âŒ JSONè§£æå¤±è´¥: {e}")
            print(f"å°è¯•ä¿®å¤JSON...")
            
            # å°è¯•ä¿®å¤å¸¸è§çš„JSONæ ¼å¼é—®é¢˜
            fixed_response = self._fix_json_response(response)
            if fixed_response:
                try:
                    result = json.loads(fixed_response)
                    return result.get('chunks', [])
                except json.JSONDecodeError:
                    print("âŒ JSONä¿®å¤å¤±è´¥")
            
            print(f"åŸå§‹å“åº”å‰500å­—ç¬¦: {response[:500]}")
            return []
    
    def _fix_json_response(self, response: str) -> Optional[str]:
        """å°è¯•ä¿®å¤JSONå“åº”ä¸­çš„å¸¸è§é—®é¢˜"""
        try:
            # 1. ç§»é™¤å¯èƒ½çš„éJSONå‰ç¼€å’Œåç¼€
            response = response.strip()
            
            # 2. æŸ¥æ‰¾JSONçš„å¼€å§‹å’Œç»“æŸä½ç½®
            json_start = response.find('{')
            json_end = response.rfind('}')
            
            if json_start == -1 or json_end == -1 or json_end <= json_start:
                return None
            
            json_content = response[json_start:json_end + 1]
            
            # 3. ä¿®å¤å­—ç¬¦ä¸²ä¸­çš„æœªè½¬ä¹‰å­—ç¬¦
            import re
            
            # æ–¹æ³•1ï¼šä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ä¿®å¤å­—ç¬¦ä¸²å€¼
            def fix_string_value(match):
                """ä¿®å¤å­—ç¬¦ä¸²å€¼ä¸­çš„æœªè½¬ä¹‰å­—ç¬¦"""
                full_match = match.group(0)
                key = match.group(1)
                value = match.group(2)
                
                # è½¬ä¹‰å­—ç¬¦ä¸²å€¼ä¸­çš„ç‰¹æ®Šå­—ç¬¦
                value = value.replace('\\', '\\\\')  # è½¬ä¹‰åæ–œæ 
                value = value.replace('"', '\\"')    # è½¬ä¹‰å¼•å·
                value = value.replace('\n', '\\n')   # è½¬ä¹‰æ¢è¡Œç¬¦
                value = value.replace('\r', '\\r')   # è½¬ä¹‰å›è½¦ç¬¦
                value = value.replace('\t', '\\t')   # è½¬ä¹‰åˆ¶è¡¨ç¬¦
                
                return f'"{key}": "{value}"'
            
            # åŒ¹é… "key": "value" æ ¼å¼ï¼Œå…¶ä¸­valueå¯èƒ½åŒ…å«æœªè½¬ä¹‰çš„å­—ç¬¦
            pattern = r'"([^"]+)":\s*"([^"]*(?:[^"\\]|\\.)*)(?!["])'
            
            # é€æ­¥ä¿®å¤
            lines = json_content.split('\n')
            fixed_lines = []
            
            for i, line in enumerate(lines):
                try:
                    # å°è¯•è§£æå½“å‰è¡Œï¼Œçœ‹æ˜¯å¦æœ‰è¯­æ³•é”™è¯¯
                    if '"' in line and ':' in line:
                        # æ£€æŸ¥æ˜¯å¦æ˜¯é”®å€¼å¯¹è¡Œ
                        if line.strip().startswith('"') and '":' in line:
                            # æŸ¥æ‰¾å€¼çš„å¼€å§‹ä½ç½®
                            colon_pos = line.find('":')
                            if colon_pos != -1:
                                value_start = colon_pos + 2
                                # è·³è¿‡ç©ºç™½å­—ç¬¦
                                while value_start < len(line) and line[value_start] in ' \t':
                                    value_start += 1
                                
                                if value_start < len(line) and line[value_start] == '"':
                                    # æ‰¾åˆ°å€¼çš„ç»“æŸä½ç½®
                                    value_end = len(line)
                                    for j in range(value_start + 1, len(line)):
                                        if line[j] == '"' and line[j-1] != '\\':
                                            value_end = j
                                            break
                                    
                                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç»“æŸå¼•å·ï¼Œæˆ–è€…åœ¨ç»“æŸå¼•å·åé¢è¿˜æœ‰å†…å®¹
                                    if value_end == len(line) or (value_end < len(line) - 1 and line[value_end + 1:].strip() not in [',', '']):
                                        # æˆªå–åˆ°é€—å·æˆ–è¡Œå°¾
                                        actual_end = len(line)
                                        for j in range(value_start + 1, len(line)):
                                            if line[j] == ',' and line[j-1] != '\\':
                                                actual_end = j
                                                break
                                        
                                        # æå–å¹¶æ¸…ç†å€¼
                                        value_content = line[value_start + 1:actual_end]
                                        if value_content.endswith('"'):
                                            value_content = value_content[:-1]
                                        
                                        # è½¬ä¹‰ç‰¹æ®Šå­—ç¬¦
                                        value_content = value_content.replace('\\', '\\\\')
                                        value_content = value_content.replace('"', '\\"')
                                        value_content = value_content.replace('\n', '\\n')
                                        value_content = value_content.replace('\r', '\\r')
                                        value_content = value_content.replace('\t', '\\t')
                                        
                                        # é‡æ„è¡Œ
                                        key_part = line[:value_start]
                                        remaining = line[actual_end:]
                                        fixed_line = f'{key_part}"{value_content}"{remaining}'
                                        fixed_lines.append(fixed_line)
                                        continue
                    
                    # å¦‚æœä¸éœ€è¦ä¿®å¤ï¼Œç›´æ¥æ·»åŠ 
                    fixed_lines.append(line)
                    
                except Exception as e:
                    # å¦‚æœä¿®å¤å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹è¡Œ
                    fixed_lines.append(line)
            
            # é‡æ–°ç»„è£…
            json_content = '\n'.join(fixed_lines)
            
            # 4. ç¡®ä¿JSONæ­£ç¡®ç»“æŸ
            if not json_content.rstrip().endswith('}'):
                json_content = json_content.rstrip() + '}'
            
            return json_content
            
        except Exception as e:
            print(f"âŒ å¤æ‚JSONä¿®å¤å¤±è´¥: {e}")
            
            # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨æ›´ç®€å•çš„ä¿®å¤ç­–ç•¥
            try:
                return self._simple_json_fix(response)
            except Exception as e2:
                print(f"âŒ ç®€å•JSONä¿®å¤ä¹Ÿå¤±è´¥: {e2}")
                return None
    
    def _simple_json_fix(self, response: str) -> Optional[str]:
        """ç®€å•çš„JSONä¿®å¤ç­–ç•¥"""
        try:
            # 1. æŸ¥æ‰¾JSONè¾¹ç•Œ
            json_start = response.find('{')
            json_end = response.rfind('}')
            
            if json_start == -1 or json_end == -1:
                return None
            
            json_content = response[json_start:json_end + 1]
            
            # 2. ç®€å•ç²—æš´çš„ä¿®å¤ï¼šç§»é™¤æ‰€æœ‰æ¢è¡Œç¬¦å’Œå¤šä½™çš„å¼•å·
            # æŒ‰è¡Œå¤„ç†ï¼Œä¿®å¤å­—ç¬¦ä¸²å€¼
            lines = json_content.split('\n')
            fixed_lines = []
            
            for line in lines:
                # è·³è¿‡ç©ºè¡Œ
                if not line.strip():
                    continue
                
                # å¤„ç†åŒ…å«å­—ç¬¦ä¸²å€¼çš„è¡Œ
                if '":' in line and '"' in line:
                    # æ‰¾åˆ°å†’å·ä½ç½®
                    colon_pos = line.find('":')
                    if colon_pos != -1:
                        key_part = line[:colon_pos + 2]
                        value_part = line[colon_pos + 2:].strip()
                        
                        # å¦‚æœå€¼éƒ¨åˆ†ä»¥å¼•å·å¼€å§‹ï¼Œè¿™æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²å€¼
                        if value_part.startswith('"'):
                            # ç§»é™¤å¼€å¤´çš„å¼•å·
                            value_content = value_part[1:]
                            
                            # æŸ¥æ‰¾ç»“æŸä½ç½®ï¼ˆé€—å·æˆ–è¡Œå°¾ï¼‰
                            end_pos = len(value_content)
                            if ',' in value_content:
                                end_pos = value_content.rfind(',')
                            
                            actual_value = value_content[:end_pos].strip()
                            remaining = value_content[end_pos:] if end_pos < len(value_content) else ""
                            
                            # ç§»é™¤å¯èƒ½çš„å°¾éƒ¨å¼•å·
                            if actual_value.endswith('"'):
                                actual_value = actual_value[:-1]
                            
                            # æ¸…ç†å€¼ï¼šè½¬ä¹‰ç‰¹æ®Šå­—ç¬¦
                            actual_value = actual_value.replace('\\', '\\\\')  # å…ˆè½¬ä¹‰åæ–œæ 
                            actual_value = actual_value.replace('"', '\\"')    # è½¬ä¹‰å¼•å·
                            actual_value = actual_value.replace('\n', '\\n')   # è½¬ä¹‰æ¢è¡Œ
                            actual_value = actual_value.replace('\r', '\\r')   # è½¬ä¹‰å›è½¦
                            actual_value = actual_value.replace('\t', '\\t')   # è½¬ä¹‰åˆ¶è¡¨ç¬¦
                            
                            # é‡æ–°æ„é€ è¡Œ
                            fixed_line = f'{key_part} "{actual_value}"{remaining}'
                            fixed_lines.append(fixed_line)
                            continue
                
                # å¯¹äºå…¶ä»–è¡Œï¼Œç›´æ¥æ·»åŠ 
                fixed_lines.append(line)
            
            # 3. é‡æ–°ç»„è£…
            result = '\n'.join(fixed_lines)
            
            # 4. ç¡®ä¿JSONæ­£ç¡®ç»“æŸ
            if not result.rstrip().endswith('}'):
                result = result.rstrip() + '}'
            
            return result
            
        except Exception as e:
            print(f"âŒ ç®€å•JSONä¿®å¤å¤±è´¥: {e}")
            return None
    
    def _convert_to_minimal_chunks(self,
                                  chunks_data: List[Dict[str, Any]],
                                  chapter_id: str,
                                  chapter_title: str,
                                  chapter_content: str,
                                  start_chunk_id: int) -> List[MinimalChunk]:
        """è½¬æ¢ä¸ºMinimalChunkå¯¹è±¡"""
        chunks = []
        current_pos = 0
        
        for i, chunk_data in enumerate(chunks_data):
            content = chunk_data.get('content', '').strip()
            chunk_type = chunk_data.get('type', 'paragraph')
            
            if not content:
                continue
            
            # åœ¨ç« èŠ‚å†…å®¹ä¸­æŸ¥æ‰¾è¿™ä¸ªåˆ†å—çš„ä½ç½®
            start_pos = chapter_content.find(content, current_pos)
            if start_pos == -1:
                start_pos = current_pos
            
            end_pos = start_pos + len(content)
            current_pos = end_pos
            
            chunk = MinimalChunk(
                chunk_id=f"{chapter_id}_{start_chunk_id + i}",
                content=content,
                chunk_type=chunk_type,
                belongs_to_chapter=chapter_id,
                chapter_title=chapter_title,
                start_pos=start_pos,
                end_pos=end_pos,
                word_count=len(content)
            )
            
            chunks.append(chunk)
        
        return chunks
    
    def _fallback_chunking(self,
                          chapter_id: str,
                          chapter_title: str,
                          chapter_content: str,
                          start_chunk_id: int) -> List[MinimalChunk]:
        """å›é€€åˆ†å—æ–¹æ¡ˆ - åŸºäºç®€å•è§„åˆ™"""
        print(f"ğŸ”„ ä½¿ç”¨å›é€€åˆ†å—æ–¹æ¡ˆ")
        
        chunks = []
        
        # ç®€å•çš„æ®µè½åˆ†å‰²
        paragraphs = chapter_content.split('\n\n')
        
        for i, paragraph in enumerate(paragraphs):
            paragraph = paragraph.strip()
            if not paragraph:
                continue
            
            # åˆ¤æ–­ç±»å‹
            chunk_type = "paragraph"
            if paragraph.startswith('#'):
                chunk_type = "heading"
            elif paragraph.startswith('-') or paragraph.startswith('â€¢'):
                chunk_type = "list_item"
            elif '[å›¾ç‰‡:' in paragraph:
                chunk_type = "mixed"
            elif '[è¡¨æ ¼:' in paragraph:
                chunk_type = "mixed"
            
            chunk = MinimalChunk(
                chunk_id=f"{chapter_id}_{start_chunk_id + i}",
                content=paragraph,
                chunk_type=chunk_type,
                belongs_to_chapter=chapter_id,
                chapter_title=chapter_title,
                start_pos=0,
                end_pos=len(paragraph),
                word_count=len(paragraph)
            )
            
            chunks.append(chunk)
        
        return chunks
    
    async def chunk_chapters_batch(self, 
                                 chapters: List[Dict[str, Any]],
                                 max_workers: int = 3) -> List[MinimalChunk]:
        """
        æ‰¹é‡å¼‚æ­¥å¤„ç†ç« èŠ‚åˆ†å—
        
        Args:
            chapters: ç« èŠ‚åˆ—è¡¨ï¼Œæ¯ä¸ªåŒ…å«chapter_id, title, content
            max_workers: æœ€å¤§å¹¶å‘æ•°
            
        Returns:
            List[MinimalChunk]: æ‰€æœ‰åˆ†å—ç»“æœ
        """
        print(f"ğŸš€ å¼€å§‹æ‰¹é‡å¼‚æ­¥åˆ†å—ï¼Œå…± {len(chapters)} ä¸ªç« èŠ‚")
        
        all_chunks = []
        chunk_counter = 0
        
        # åˆ›å»ºå¼‚æ­¥ä»»åŠ¡
        tasks = []
        for chapter in chapters:
            task = self.chunk_chapter_async(
                chapter['chapter_id'],
                chapter['title'],
                chapter['content'],
                chunk_counter
            )
            tasks.append(task)
            
            # ä¼°ç®—åˆ†å—æ•°é‡ï¼ˆç”¨äºIDè®¡ç®—ï¼‰
            estimated_chunks = max(1, len(chapter['content']) // 200)
            chunk_counter += estimated_chunks
        
        # æ§åˆ¶å¹¶å‘æ•°
        semaphore = asyncio.Semaphore(max_workers)
        
        async def process_with_semaphore(task):
            async with semaphore:
                return await task
        
        # æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
        results = await asyncio.gather(*[process_with_semaphore(task) for task in tasks])
        
        # åˆå¹¶ç»“æœ
        for chapter_chunks in results:
            all_chunks.extend(chapter_chunks)
        
        print(f"âœ… æ‰¹é‡åˆ†å—å®Œæˆï¼Œå…±ç”Ÿæˆ {len(all_chunks)} ä¸ªåˆ†å—")
        return all_chunks

# ä¾¿æ·å‡½æ•°
def chunk_chapters_with_ai(chapters: List[Dict[str, Any]], 
                          model: str = "qwen-turbo",
                          max_workers: int = 3) -> List[MinimalChunk]:
    """
    ä½¿ç”¨AIå¯¹ç« èŠ‚è¿›è¡Œæ™ºèƒ½åˆ†å—çš„ä¾¿æ·å‡½æ•°
    
    Args:
        chapters: ç« èŠ‚åˆ—è¡¨
        model: ä½¿ç”¨çš„æ¨¡å‹
        max_workers: æœ€å¤§å¹¶å‘æ•°
        
    Returns:
        List[MinimalChunk]: åˆ†å—ç»“æœ
    """
    chunker = AIChunker(model=model)
    
    # è¿è¡Œå¼‚æ­¥ä»»åŠ¡
    return asyncio.run(chunker.chunk_chapters_batch(chapters, max_workers))

# æµ‹è¯•å‡½æ•°
async def test_ai_chunker():
    """æµ‹è¯•AIåˆ†å—å™¨"""
    chunker = AIChunker()
    
    # æµ‹è¯•ç« èŠ‚
    test_chapter = {
        'chapter_id': '1',
        'title': 'è®¾è®¡ä¾æ®',
        'content': '''## è®¾ è®¡ ä¾ æ®

- 2.å åœ°åŸºå»ºé¢ç§¯ï¼š125.9å¹³æ–¹ç±³ï¼Œé—¨å‰èŠ±å›­å åœ°é¢ç§¯ï¼š65å¹³æ–¹ç±³ï¼Œæ€»å»ºç­‘é¢ç§¯ï¼š473.6å¹³æ–¹ç±³
- 3.å»ºç­‘ç‰©å±‚æ•°ä¸ºï¼š2å±‚
- 4.æœ¬å·¥ç¨‹ä¸ºå¤šå±‚å»ºç­‘ï¼Œè€ç«ç­‰çº§ä¸ºäºŒçº§ï¼ŒæŠ—éœ‡è®¾é˜²ä¸ºä¸ƒåº¦ï¼Œé˜²æ°´ç­‰çº§ä¸ºäºŒçº§ã€‚

1. ã€Šä¸­åäººæ°‘å…±å’Œå›½æ–‡ç‰©ä¿æŠ¤æ³•ã€‹ï¼ˆ2024 å¹´ä¿®è®¢ï¼‰
2. ã€Šä¸­åäººæ°‘å…±å’Œå›½æ–‡ç‰©ä¿æŠ¤æ³•å®æ–½æ¡ä¾‹ã€‹ï¼ˆ2015å¹´ï¼‰

[å›¾ç‰‡: Error: An unexpected error occurred while fetching the image description.]

[å›¾ç‰‡: Error: An unexpected error occurred while fetching the image description.]

3. ã€Šæ°‘ç”¨å»ºç­‘è®¾è®¡é€šåˆ™ã€‹ï¼»GB50352-2015ï¼½
4. ã€Šä½å®…å»ºç­‘è®¾è®¡è§„èŒƒã€‹ï¼»GB 50096-2011ï¼½
5. ã€Šå»ºç­‘è®¾è®¡é˜²ç«è§„èŒƒã€‹[GB50016-2014]
6. ã€Šå»ºç­‘æŠ—éœ‡è®¾è®¡è§„èŒƒã€‹[GB50011-2010]
7. ã€Šå»ºç­‘å†…éƒ¨è£…ä¿®è®¾è®¡é˜²ç«è§„èŒƒã€‹[GB50222-2015]
8. ã€Šä½å®…å»ºç­‘è§„èŒƒã€‹[GB50368-2005]
9. ã€Šä½å®…è®¾è®¡è§„èŒƒã€‹[GB50096-2011]
- 10.ã€ŠåŸå¸‚é“è·¯å’Œå»ºç­‘ç‰©æ— éšœç¢è®¾è®¡è§„èŒƒã€‹[JGJ50-2013]
- 11.ã€Šå»ºç­‘é˜²æ°´å·¥ç¨‹æŠ€æœ¯è§„ç¨‹ã€‹[DBJ15-19-2016]'''
    }
    
    chunks = await chunker.chunk_chapter_async(
        test_chapter['chapter_id'],
        test_chapter['title'],
        test_chapter['content'],
        0
    )
    
    print(f"\nğŸ¯ æµ‹è¯•ç»“æœ: {len(chunks)} ä¸ªåˆ†å—")
    for i, chunk in enumerate(chunks):
        print(f"\n--- åˆ†å— {i+1} ---")
        print(f"ID: {chunk.chunk_id}")
        print(f"ç±»å‹: {chunk.chunk_type}")
        print(f"å†…å®¹: {chunk.content[:100]}...")

if __name__ == "__main__":
    asyncio.run(test_ai_chunker()) 