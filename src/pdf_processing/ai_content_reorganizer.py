"""
AI Content Reorganizer

è´Ÿè´£ä½¿ç”¨AIæ¨¡åž‹å¯¹PDFè§£æžå†…å®¹è¿›è¡Œé‡ç»„å’Œå¢žå¼ºå¤„ç†
"""

import os
import asyncio
from typing import Dict, List, Optional, Any, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed
import base64
from pathlib import Path
import time

from .config import PDFProcessingConfig
from .data_models import PageData, ImageWithContext, TableWithContext

# å°è¯•å¯¼å…¥AIå®¢æˆ·ç«¯
try:
    # å¯¼å…¥é¡¹ç›®ä¸­çš„AIå®¢æˆ·ç«¯
    import sys
    sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))
    from src.deepseek_client import DeepSeekClient
    from src.openrouter_client import OpenRouterClient
    from src.qwen_client import QwenClient
    
    AI_CLIENTS_AVAILABLE = True
    print("âœ… AIå®¢æˆ·ç«¯å¯ç”¨")
except ImportError as e:
    AI_CLIENTS_AVAILABLE = False
    print(f"âš ï¸ AIå®¢æˆ·ç«¯ä¸å¯ç”¨: {e}")
    
    # åˆ›å»ºå ä½ç¬¦ç±»åž‹
    class DeepSeekClient:
        pass
    
    class OpenRouterClient:
        pass
    
    class QwenClient:
        pass


class AIContentReorganizer:
    """
    AIå†…å®¹é‡ç»„å™¨
    
    è´Ÿè´£ä½¿ç”¨AIæ¨¡åž‹å¯¹PDFè§£æžçš„å†…å®¹è¿›è¡Œæ¸…æ´—ã€é‡ç»„å’Œå¢žå¼ºï¼š
    1. é€é¡µæ–‡æœ¬æ¸…æ´—å’Œé‡ç»„
    2. å›¾ç‰‡æè¿°ç”Ÿæˆ
    3. è¡¨æ ¼æè¿°ç”Ÿæˆ
    4. æ”¯æŒå¤šç§AIæ¨¡åž‹å’Œå¹¶è¡Œå¤„ç†
    """
    
    def __init__(self, config: Optional[PDFProcessingConfig] = None):
        """
        åˆå§‹åŒ–AIå†…å®¹é‡ç»„å™¨
        
        Args:
            config: PDFå¤„ç†é…ç½®
        """
        self.config = config or PDFProcessingConfig()
        self.ai_clients = {}
        self.supported_models = {}
        
        # åˆå§‹åŒ–AIå®¢æˆ·ç«¯
        self._init_ai_clients()
        
        # æ–‡æœ¬æ¸…æ´—æç¤ºè¯æ¨¡æ¿ - ä¸“æ³¨äºŽOCRé”™è¯¯ä¿®å¤å’Œæ ¼å¼æ•´ç†
        self.text_cleaning_prompt = """
# ä»»åŠ¡
ä¿®å¤OCRè¯†åˆ«é”™è¯¯å’Œæ ¼å¼é—®é¢˜ï¼Œè¿˜åŽŸå¹²å‡€å¯è¯»çš„åŽŸæ–‡ã€‚

# è¾“å…¥æ–‡æœ¬
{raw_text}

# ä¿®å¤è§„åˆ™
1. **ä¿®æ­£OCRè¯†åˆ«é”™è¯¯**ï¼šä¿®å¤å­—ç¬¦è¯†åˆ«é”™è¯¯ã€ä¹±ç ã€é”™è¯¯çš„å­—ç¬¦ç»„åˆ
2. **æ•´ç†æ ¼å¼é—®é¢˜**ï¼š
   - åˆ é™¤å¤šä½™çš„ç©ºè¡Œå’Œæ¢è¡Œç¬¦
   - ä¿®æ­£ä¸å½“çš„ç©ºæ ¼åˆ†å¸ƒ
   - æ•´ç†æ®µè½é—´è·
   - ä¿®æ­£æ ‡ç‚¹ç¬¦å·çš„ä½ç½®å’Œæ ¼å¼
3. **ä¿æŒåŽŸæ–‡å®Œæ•´æ€§**ï¼š
   - ä¸åˆ é™¤ä»»ä½•å†…å®¹
   - ä¸æ”¹å˜åŽŸæ–‡è¡¨è¾¾
   - ä¸è¿›è¡Œæ„æ€è§£é‡Šæˆ–é‡ç»„
   - ä¿æŒæ‰€æœ‰æ•°å­—ã€å¼•ç”¨ã€å…¬å¼ç­‰åŽŸæ ·
4. **è¾“å‡ºè¦æ±‚**ï¼š
   - çº¯æ–‡æœ¬æ ¼å¼ï¼Œæ— markdownæ ‡è®°
   - ä¿æŒåŽŸæ–‡çš„å®Œæ•´ç»“æž„å’Œå±‚æ¬¡
   - ç¡®ä¿æ–‡æœ¬è¿žè´¯å¯è¯»

# ä¿®å¤åŽçš„æ–‡æœ¬
"""
        
        # å›¾ç‰‡æè¿°æç¤ºè¯æ¨¡æ¿ - åŸºäºŽimage_analysis.yamlä¼˜åŒ–
        self.image_description_prompt = """
# è§’è‰²
ä½ æ˜¯ä¸€ä¸ªç²¾ç‚¼çš„å›¾åƒåˆ†æžå¼•æ“Žã€‚

# ä»»åŠ¡
ä¸ºç»™å®šçš„å›¾ç‰‡ç”Ÿæˆä¸€æ®µæžå…¶ç²¾ç®€çš„æ ¸å¿ƒæè¿°ï¼Œè¯¥æè¿°å°†ç”¨äºŽè¯­ä¹‰æœç´¢ã€‚ä½ çš„ç›®æ ‡æ˜¯"ç´¢å¼•"å›¾ç‰‡å†…å®¹ï¼Œè€Œä¸æ˜¯"è§£è¯´"å›¾ç‰‡ã€‚

# é¡µé¢ä¸Šä¸‹æ–‡ï¼ˆå‚è€ƒæ–‡å­—ï¼‰
{page_context}

# æ ¸å¿ƒè§„åˆ™
1. **ä¸“æ³¨äºŽå…³é”®å…ƒç´ **ï¼šåªè¯†åˆ«å’Œæè¿°å›¾ç‰‡ä¸­æœ€æ ¸å¿ƒçš„1-3ä¸ªä¸»ä½“ã€çŠ¶æ€æˆ–æ¦‚å¿µã€‚
2. **æå–å…³é”®è¯ï¼Œè€Œéžå®Œæ•´å™è¿°**ï¼šç”Ÿæˆèƒ½å¤Ÿä»£è¡¨å›¾ç‰‡å†…å®¹çš„å…³é”®è¯ç»„åˆæˆ–çŸ­è¯­ï¼Œè€Œä¸æ˜¯ä¸€ä¸ªæ•…äº‹æ€§çš„æ®µè½ã€‚å¤šä½¿ç”¨åè¯å’Œå…³é”®åŠ¨è¯ã€‚
3. **ç»“æž„å»ºè®®**ï¼šå°½é‡ä½¿ç”¨"ä¸»ä½“ + çŠ¶æ€/è¡Œä¸º + å…³é”®å¯¹è±¡"çš„ç»“æž„ã€‚ä¾‹å¦‚ï¼Œ"ä¸€å¼ å…³äºŽ[ä¸»é¢˜]çš„[å›¾è¡¨ç±»åž‹]"æˆ–"[ä¸»ä½“]çš„[æŸç§çŠ¶æ€]ç‰¹å†™"ã€‚
4. **ç»å¯¹ç®€æ´**ï¼šæè¿°é€šå¸¸åº”åœ¨15åˆ°30å­—ä¹‹é—´ã€‚å‰”é™¤æ‰€æœ‰ä¸å¿…è¦çš„ä¿®é¥°è¯å’Œå¼•å¯¼è¯­ï¼ˆä¾‹å¦‚ä¸è¦ç”¨"è¿™å¼ å›¾ç‰‡æ˜¾ç¤ºäº†â€¦"ï¼‰ã€‚
5. **å¿½ç•¥æ— å…³ä¸Šä¸‹æ–‡**ï¼šå¦‚æžœå›¾ç‰‡é™„å¸¦çš„å‚è€ƒæ–‡å­—ä¸Žå›¾ç‰‡å†…å®¹ä¸ç¬¦ï¼Œå¿…é¡»å®Œå…¨å¿½ç•¥è¯¥æ–‡å­—ã€‚

# ç¤ºä¾‹
- **è¾“å…¥å›¾ç‰‡**: ä¸€å¼ ç®¡é“æŽ¥å£å¤„ä¸¥é‡ç”Ÿé”ˆçš„ç…§ç‰‡ã€‚
- **åˆæ ¼è¾“å‡º**: "ç®¡é“æŽ¥å£å¤„çš„ä¸¥é‡è…èš€ä¸Žé‡‘å±žé”ˆè¿¹ç‰¹å†™ã€‚"
- **ä¸åˆæ ¼è¾“å‡º**: "è¿™å¼ å›¾ç‰‡å‘æˆ‘ä»¬å±•ç¤ºäº†ä¸€ä¸ªçœ‹èµ·æ¥å¾ˆæ—§çš„é‡‘å±žç®¡é“ï¼Œå®ƒè¿žæŽ¥ç€å¦ä¸€ä¸ªéƒ¨åˆ†ï¼Œè¿žæŽ¥å¤„æœ‰å¾ˆå¤šæ£•è‰²çš„é”ˆè¿¹ï¼Œå¯èƒ½æ˜¯å› ä¸ºé•¿æ—¶é—´æš´éœ²åœ¨æ½®æ¹¿çŽ¯å¢ƒä¸­å¯¼è‡´çš„ã€‚"

# å›¾ç‰‡æè¿°
"""
        
        # è¡¨æ ¼æè¿°æç¤ºè¯æ¨¡æ¿ - ä¸“æ³¨äºŽè¡¨æ ¼æ•°æ®å’Œç»“æž„
        self.table_description_prompt = """
# è§’è‰²
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è¡¨æ ¼æ•°æ®åˆ†æžå¼•æ“Žã€‚

# ä»»åŠ¡
ä¸ºç»™å®šçš„è¡¨æ ¼ç”Ÿæˆä¸€æ®µç²¾ç®€çš„æ ¸å¿ƒæè¿°ï¼Œè¯¥æè¿°å°†ç”¨äºŽè¯­ä¹‰æœç´¢ã€‚ä½ çš„ç›®æ ‡æ˜¯"ç´¢å¼•"è¡¨æ ¼çš„æ•°æ®ç»“æž„å’Œå…³é”®ä¿¡æ¯ï¼Œè€Œä¸æ˜¯è¯¦ç»†è§£è¯»æ¯ä¸ªæ•°æ®ç‚¹ã€‚

# é¡µé¢ä¸Šä¸‹æ–‡ï¼ˆå‚è€ƒæ–‡å­—ï¼‰
{page_context}

# æ ¸å¿ƒè§„åˆ™
1. **ä¸“æ³¨äºŽè¡¨æ ¼ç»“æž„**ï¼šè¯†åˆ«è¡¨æ ¼çš„ä¸»è¦ç»´åº¦ï¼ˆè¡Œåˆ—æ ‡é¢˜ã€æ•°æ®ç±»åž‹ã€ä¸»è¦åˆ†ç±»ï¼‰ã€‚
2. **æå–å…³é”®æ•°æ®ç‰¹å¾**ï¼šå…³æ³¨æ•°æ®èŒƒå›´ã€è¶‹åŠ¿ã€å…³é”®æ•°å€¼ï¼Œè€Œä¸æ˜¯åˆ—ä¸¾æ‰€æœ‰æ•°æ®ã€‚
3. **ç»“æž„å»ºè®®**ï¼šä½¿ç”¨"[ä¸»é¢˜]çš„[æ•°æ®ç±»åž‹]è¡¨æ ¼"æˆ–"[ç»´åº¦1] vs [ç»´åº¦2]çš„[æ•°æ®ç‰¹å¾]å¯¹æ¯”"çš„ç»“æž„ã€‚
4. **ç»å¯¹ç®€æ´**ï¼šæè¿°é€šå¸¸åº”åœ¨20åˆ°40å­—ä¹‹é—´ã€‚å‰”é™¤æ‰€æœ‰ä¸å¿…è¦çš„ä¿®é¥°è¯ã€‚
5. **å¿½ç•¥æ— å…³ä¸Šä¸‹æ–‡**ï¼šå¦‚æžœè¡¨æ ¼é™„å¸¦çš„å‚è€ƒæ–‡å­—ä¸Žè¡¨æ ¼å†…å®¹ä¸ç¬¦ï¼Œå¿…é¡»å®Œå…¨å¿½ç•¥è¯¥æ–‡å­—ã€‚

# ç¤ºä¾‹
- **è¾“å…¥è¡¨æ ¼**: ä¸€ä¸ªæ˜¾ç¤ºä¸åŒå¹´ä»½é”€å”®æ•°æ®çš„è¡¨æ ¼ï¼ŒåŒ…å«äº§å“ç±»åˆ«å’Œé”€å”®é¢ã€‚
- **åˆæ ¼è¾“å‡º**: "2020-2023å¹´å„äº§å“ç±»åˆ«é”€å”®é¢ç»Ÿè®¡è¡¨æ ¼ã€‚"
- **ä¸åˆæ ¼è¾“å‡º**: "è¿™ä¸ªè¡¨æ ¼è¯¦ç»†å±•ç¤ºäº†ä»Ž2020å¹´åˆ°2023å¹´æœŸé—´ï¼Œå…¬å¸å„ä¸ªäº§å“ç±»åˆ«çš„é”€å”®é¢æ•°æ®ï¼Œå¯ä»¥çœ‹å‡ºç”µå­äº§å“çš„é”€å”®é¢æœ€é«˜ï¼Œè€Œæœè£…ç±»äº§å“çš„é”€å”®é¢ç›¸å¯¹è¾ƒä½Žã€‚"

# è¡¨æ ¼æè¿°
"""
    
    def _init_ai_clients(self) -> None:
        """åˆå§‹åŒ–AIå®¢æˆ·ç«¯"""
        if not AI_CLIENTS_AVAILABLE:
            print("âš ï¸ AIå®¢æˆ·ç«¯ä¸å¯ç”¨ï¼Œè·³è¿‡åˆå§‹åŒ–")
            return
        
        try:
            # åˆå§‹åŒ–Qwenå®¢æˆ·ç«¯ï¼ˆä¸“ç”¨äºŽæ–‡æœ¬å¤„ç†ï¼Œé«˜rate limitï¼‰
            self.ai_clients['qwen'] = QwenClient(
                model=self.config.ai_content.default_llm_model,
                max_tokens=self.config.ai_content.max_context_length // 10,  # åˆç†çš„tokené™åˆ¶
                max_retries=self.config.ai_content.max_retries,
                enable_batch_mode=True  # å¯ç”¨æ‰¹å¤„ç†æ¨¡å¼
            )
            self.supported_models['qwen'] = ['qwen-turbo-latest', 'qwen-plus-latest', 'qwen-max-latest']
            print("âœ… Qwenå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸï¼ˆç”¨äºŽæ–‡æœ¬æ¸…æ´—ï¼Œé«˜rate limitï¼‰")
        except Exception as e:
            print(f"âš ï¸ Qwenå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
        

        try:
            # åˆå§‹åŒ–DeepSeekå®¢æˆ·ç«¯ï¼ˆå¤‡ç”¨æ–‡æœ¬å¤„ç†ï¼‰
            self.ai_clients['deepseek'] = DeepSeekClient()
            self.supported_models['deepseek'] = ['deepseek-chat', 'deepseek-reasoner']
            print("âœ… DeepSeekå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸï¼ˆå¤‡ç”¨æ–‡æœ¬æ¸…æ´—ï¼‰")
        except Exception as e:
            print(f"âš ï¸ DeepSeekå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
        
        try:
            # åˆå§‹åŒ–OpenRouterå®¢æˆ·ç«¯ï¼ˆä¸“ç”¨äºŽå¤šæ¨¡æ€å¤„ç†ï¼‰
            self.ai_clients['openrouter'] = OpenRouterClient()
            self.supported_models['openrouter'] = [
                'google/gemini-2.5-flash',  # ä¸»è¦ç”¨äºŽå›¾ç‰‡å’Œè¡¨æ ¼æè¿°
                'google/gemini-pro'         # å¤‡ç”¨å¤šæ¨¡æ€æ¨¡åž‹
            ]
            print("âœ… OpenRouterå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸï¼ˆç”¨äºŽå¤šæ¨¡æ€å¤„ç†ï¼‰")
        except Exception as e:
            print(f"âš ï¸ OpenRouterå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
    
    def process_pages(self, pages: List[PageData], 
                     parallel_processing: bool = True) -> List[PageData]:
        """
        å¤„ç†é¡µé¢æ•°æ®ï¼Œè¿›è¡Œæ–‡æœ¬æ¸…æ´—å’Œåª’ä½“æè¿°ç”Ÿæˆ
        
        Args:
            pages: é¡µé¢æ•°æ®åˆ—è¡¨
            parallel_processing: æ˜¯å¦ä½¿ç”¨å¹¶è¡Œå¤„ç†
            
        Returns:
            List[PageData]: å¤„ç†åŽçš„é¡µé¢æ•°æ®åˆ—è¡¨
        """
        if not pages:
            print("âš ï¸ æ²¡æœ‰é¡µé¢æ•°æ®éœ€è¦å¤„ç†")
            return []
        
        print(f"ðŸš€ å¼€å§‹AIå†…å®¹é‡ç»„å¤„ç†...")
        print(f"ðŸ“„ æ€»é¡µæ•°: {len(pages)}")
        print(f"âš¡ å¹¶è¡Œå¤„ç†: {'å¯ç”¨' if parallel_processing else 'ç¦ç”¨'}")
        
        start_time = time.time()
        
        if parallel_processing and len(pages) > 1:
            processed_pages = self._process_pages_parallel(pages)
        else:
            processed_pages = self._process_pages_sequential(pages)
        
        end_time = time.time()
        processing_time = end_time - start_time
        
        print(f"âœ… AIå¤„ç†å®Œæˆï¼Œè€—æ—¶: {processing_time:.2f} ç§’")
        return processed_pages
    
    def _process_pages_parallel(self, pages: List[PageData]) -> List[PageData]:
        """å¹¶è¡Œå¤„ç†é¡µé¢ - ä½¿ç”¨ä¼ªæ‰¹é‡å¤„ç†ï¼ˆThreadPoolExecutorï¼‰"""
        print("âš¡ ä½¿ç”¨å¹¶è¡Œå¤„ç†æ¨¡å¼...")
        
        # ç›´æŽ¥ä½¿ç”¨ä¼ªæ‰¹é‡å¤„ç†ï¼Œä¸ä½¿ç”¨çœŸæ­£çš„Batch API
        if 'qwen' in self.ai_clients and len(pages) > 1:
            print("ðŸš€ ä½¿ç”¨Qwenä¼ªæ‰¹é‡å¤„ç†æ–‡æœ¬æ¸…æ´—...")
            return self._process_pages_batch(pages)
        
        # å¦åˆ™ä½¿ç”¨ä¼ ç»Ÿçš„å¹¶è¡Œå¤„ç†
        max_workers = min(self.config.ai_content.max_workers if hasattr(self.config.ai_content, 'max_workers') else 4, len(pages))
        processed_pages = [None] * len(pages)
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_index = {
                executor.submit(self._process_single_page, page): i 
                for i, page in enumerate(pages)
            }
            
            # æ”¶é›†ç»“æžœ
            for future in as_completed(future_to_index):
                index = future_to_index[future]
                try:
                    processed_page = future.result()
                    processed_pages[index] = processed_page
                    print(f"âœ… é¡µé¢ {processed_page.page_number} å¤„ç†å®Œæˆ")
                except Exception as e:
                    print(f"âŒ é¡µé¢ {pages[index].page_number} å¤„ç†å¤±è´¥: {e}")
                    # ä¿ç•™åŽŸå§‹é¡µé¢æ•°æ®
                    processed_pages[index] = pages[index]
        
        # è¿‡æ»¤Noneå€¼
        return [page for page in processed_pages if page is not None]
    
    def _process_pages_batch(self, pages: List[PageData]) -> List[PageData]:
        """æ‰¹é‡å¤„ç†é¡µé¢ - åˆ©ç”¨Qwençš„æ‰¹é‡å¤„ç†èƒ½åŠ›"""
        print(f"ðŸš€ æ‰¹é‡å¤„ç† {len(pages)} ä¸ªé¡µé¢...")
        
        # åˆ›å»ºé¡µé¢å‰¯æœ¬
        processed_pages = []
        for page in pages:
            processed_page = PageData(
                page_number=page.page_number,
                raw_text=page.raw_text,
                cleaned_text=page.cleaned_text,
                images=page.images.copy() if page.images else [],
                tables=page.tables.copy() if page.tables else []
            )
            processed_pages.append(processed_page)
        
        # 1. æ‰¹é‡æ–‡æœ¬æ¸…æ´—
        if 'qwen' in self.ai_clients:
            self._batch_clean_texts(processed_pages)
        
        # 2. å¹¶è¡Œå¤„ç†å›¾ç‰‡å’Œè¡¨æ ¼æè¿°ï¼ˆè¿™éƒ¨åˆ†ä»ç„¶éœ€è¦VLMæ¨¡åž‹ï¼‰
        if 'openrouter' in self.ai_clients:
            self._batch_process_media(processed_pages)
        
        return processed_pages
    

    
    def _batch_clean_texts(self, pages: List[PageData]):
        """æ‰¹é‡æ¸…æ´—æ–‡æœ¬ï¼ˆä½¿ç”¨ThreadPoolExecutorä¼ªæ‰¹å¤„ç†ï¼‰"""
        print("ðŸ§¹ æ‰¹é‡æ¸…æ´—æ–‡æœ¬...")
        
        # æ”¶é›†éœ€è¦æ¸…æ´—çš„æ–‡æœ¬
        text_prompts = []
        page_indices = []
        
        for i, page in enumerate(pages):
            if page.raw_text and not page.cleaned_text:
                prompt = self.text_cleaning_prompt.format(raw_text=page.raw_text)
                text_prompts.append(prompt)
                page_indices.append(i)
        
        if not text_prompts:
            print("âš ï¸ æ²¡æœ‰éœ€è¦æ¸…æ´—çš„æ–‡æœ¬")
            return
        
        print(f"ðŸ“ æ‰¹é‡æ¸…æ´— {len(text_prompts)} ä¸ªæ–‡æœ¬...")
        
        try:
            # ä½¿ç”¨Qwenå®¢æˆ·ç«¯æ‰¹é‡å¤„ç†
            client = self.ai_clients['qwen']
            max_workers = min(self.config.ai_content.max_workers, len(text_prompts))
            
            responses = client.batch_generate_responses(
                text_prompts, 
                max_workers=max_workers
            )
            
            # å°†å“åº”åˆ†é…å›žé¡µé¢
            for i, response in enumerate(responses):
                page_index = page_indices[i]
                pages[page_index].cleaned_text = response.strip() if response else pages[page_index].raw_text
                print(f"âœ… é¡µé¢ {pages[page_index].page_number} æ–‡æœ¬æ¸…æ´—å®Œæˆ")
        
        except Exception as e:
            print(f"âŒ æ‰¹é‡æ–‡æœ¬æ¸…æ´—å¤±è´¥: {e}")
            # é™çº§åˆ°é€ä¸ªå¤„ç†
            for i, page_index in enumerate(page_indices):
                try:
                    pages[page_index].cleaned_text = self._clean_page_text(pages[page_index].raw_text)
                except Exception as e2:
                    print(f"âš ï¸ é¡µé¢ {pages[page_index].page_number} æ–‡æœ¬æ¸…æ´—å¤±è´¥: {e2}")
                    pages[page_index].cleaned_text = pages[page_index].raw_text
    
    def _batch_process_media(self, pages: List[PageData]):
        """æ‰¹é‡å¤„ç†å›¾ç‰‡å’Œè¡¨æ ¼æè¿°"""
        print("ðŸ–¼ï¸ æ‰¹é‡å¤„ç†åª’ä½“æè¿°...")
        
        # æ”¶é›†æ‰€æœ‰éœ€è¦å¤„ç†çš„å›¾ç‰‡å’Œè¡¨æ ¼
        all_tasks = []
        
        for page in pages:
            # å›¾ç‰‡ä»»åŠ¡
            for img in page.images:
                if not img.ai_description:
                    all_tasks.append(('image', img, page))
            
            # è¡¨æ ¼ä»»åŠ¡
            for table in page.tables:
                if not table.ai_description:
                    all_tasks.append(('table', table, page))
        
        if not all_tasks:
            print("âš ï¸ æ²¡æœ‰éœ€è¦å¤„ç†çš„åª’ä½“")
            return
        
        print(f"ðŸ“Š æ‰¹é‡å¤„ç† {len(all_tasks)} ä¸ªåª’ä½“é¡¹...")
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†åª’ä½“
        max_workers = min(self.config.ai_content.max_workers, len(all_tasks))
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_task = {
                executor.submit(self._process_single_media_item, task_type, item, page): (task_type, item, page)
                for task_type, item, page in all_tasks
            }
            
            for future in as_completed(future_to_task):
                task_type, item, page = future_to_task[future]
                try:
                    description = future.result()
                    if description:
                        item.ai_description = description
                        print(f"âœ… {task_type} æè¿°ç”Ÿæˆå®Œæˆ (é¡µé¢ {page.page_number})")
                except Exception as e:
                    print(f"âŒ {task_type} æè¿°ç”Ÿæˆå¤±è´¥ (é¡µé¢ {page.page_number}): {e}")
    
    def _process_single_media_item(self, task_type: str, item, page: PageData) -> Optional[str]:
        """å¤„ç†å•ä¸ªåª’ä½“é¡¹"""
        try:
            page_context = page.raw_text or ""
            
            if task_type == 'image':
                return self._generate_image_description(item.image_path, page_context)
            elif task_type == 'table':
                return self._generate_table_description(item.table_path, page_context)
            else:
                return None
        except Exception as e:
            print(f"âš ï¸ å¤„ç† {task_type} å¤±è´¥: {e}")
            return None
    
    def _process_pages_sequential(self, pages: List[PageData]) -> List[PageData]:
        """é¡ºåºå¤„ç†é¡µé¢"""
        print("ðŸ”„ ä½¿ç”¨é¡ºåºå¤„ç†æ¨¡å¼...")
        
        processed_pages = []
        for page in pages:
            try:
                processed_page = self._process_single_page(page)
                processed_pages.append(processed_page)
                print(f"âœ… é¡µé¢ {processed_page.page_number} å¤„ç†å®Œæˆ")
            except Exception as e:
                print(f"âŒ é¡µé¢ {page.page_number} å¤„ç†å¤±è´¥: {e}")
                # ä¿ç•™åŽŸå§‹é¡µé¢æ•°æ®
                processed_pages.append(page)
        
        return processed_pages
    
    def _process_single_page(self, page: PageData) -> PageData:
        """
        å¤„ç†å•ä¸ªé¡µé¢
        
        Args:
            page: é¡µé¢æ•°æ®
            
        Returns:
            PageData: å¤„ç†åŽçš„é¡µé¢æ•°æ®
        """
        # åˆ›å»ºé¡µé¢å‰¯æœ¬ï¼Œé¿å…ä¿®æ”¹åŽŸå§‹æ•°æ®
        processed_page = PageData(
            page_number=page.page_number,
            raw_text=page.raw_text,
            cleaned_text=page.cleaned_text,
            images=page.images.copy() if page.images else [],
            tables=page.tables.copy() if page.tables else []
        )
        
        try:
            # 1. æ–‡æœ¬æ¸…æ´—
            if processed_page.raw_text and not processed_page.cleaned_text:
                processed_page.cleaned_text = self._clean_page_text(processed_page.raw_text)
            
            # 2. å›¾ç‰‡æè¿°ç”Ÿæˆ
            for img in processed_page.images:
                if not img.ai_description:
                    img.ai_description = self._generate_image_description(
                        img.image_path, 
                        img.page_context or processed_page.raw_text
                    )
            
            # 3. è¡¨æ ¼æè¿°ç”Ÿæˆ
            for table in processed_page.tables:
                if not table.ai_description:
                    table.ai_description = self._generate_table_description(
                        table.table_path, 
                        table.page_context or processed_page.raw_text
                    )
        
        except Exception as e:
            print(f"âš ï¸ é¡µé¢ {page.page_number} éƒ¨åˆ†å¤„ç†å¤±è´¥: {e}")
        
        return processed_page
    
    def _clean_page_text(self, raw_text: str) -> str:
        """
        æ¸…æ´—é¡µé¢æ–‡æœ¬
        
        Args:
            raw_text: åŽŸå§‹æ–‡æœ¬
            
        Returns:
            str: æ¸…æ´—åŽçš„æ–‡æœ¬
        """
        if not raw_text.strip():
            return raw_text
        
        try:
            # æ£€æŸ¥æ–‡æœ¬é•¿åº¦ï¼Œé¿å…è¶…è¿‡æ¨¡åž‹é™åˆ¶
            if len(raw_text) > self.config.ai_content.max_context_length:
                print(f"âš ï¸ æ–‡æœ¬é•¿åº¦è¶…é™ ({len(raw_text)} > {self.config.ai_content.max_context_length})ï¼Œæˆªæ–­å¤„ç†")
                raw_text = raw_text[:self.config.ai_content.max_context_length]
            
            # ä¼˜å…ˆä½¿ç”¨Qwenè¿›è¡Œæ–‡æœ¬æ¸…æ´—ï¼ˆé«˜rate limitï¼‰
            if 'qwen' in self.ai_clients:
                print("ðŸ§  ä½¿ç”¨Qwenè¿›è¡Œæ–‡æœ¬æ¸…æ´—ï¼ˆé«˜rate limitï¼‰...")
                return self._call_qwen_for_text(raw_text)
            # å¤‡ç”¨DeepSeekè¿›è¡Œæ–‡æœ¬æ¸…æ´—
            elif 'deepseek' in self.ai_clients:
                print("ðŸ§  ä½¿ç”¨DeepSeekè¿›è¡Œæ–‡æœ¬æ¸…æ´—ï¼ˆå¤‡ç”¨ï¼‰...")
                return self._call_deepseek_for_text(raw_text)
            else:
                print("âš ï¸ æ–‡æœ¬æ¸…æ´—å®¢æˆ·ç«¯ä¸å¯ç”¨ï¼Œè·³è¿‡æ–‡æœ¬æ¸…æ´—")
                return raw_text
                
        except Exception as e:
            print(f"âŒ æ–‡æœ¬æ¸…æ´—å¤±è´¥: {e}")
            return raw_text
    
    def _generate_image_description(self, image_path: str, page_context: str) -> str:
        """
        ç”Ÿæˆå›¾ç‰‡æè¿°
        
        Args:
            image_path: å›¾ç‰‡è·¯å¾„
            page_context: é¡µé¢ä¸Šä¸‹æ–‡
            
        Returns:
            str: å›¾ç‰‡æè¿°
        """
        if not os.path.exists(image_path):
            return f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_path}"
        
        try:
            # ä½¿ç”¨Gemini 2.5 Flashè¿›è¡Œå¤šæ¨¡æ€å›¾ç‰‡æè¿°
            if 'openrouter' in self.ai_clients:
                print(f"ðŸ–¼ï¸ ä½¿ç”¨Gemini 2.5 Flashç”Ÿæˆå›¾ç‰‡æè¿°: {os.path.basename(image_path)}")
                vlm_model = self.config.ai_content.default_vlm_model  # google/gemini-2.5-flash
                return self._call_openrouter_for_vision(image_path, page_context, vlm_model)
            else:
                print("âš ï¸ OpenRouterå®¢æˆ·ç«¯ä¸å¯ç”¨ï¼Œè·³è¿‡å›¾ç‰‡æè¿°ç”Ÿæˆ")
                return f"å›¾ç‰‡: {os.path.basename(image_path)}"
                
        except Exception as e:
            print(f"âŒ å›¾ç‰‡æè¿°ç”Ÿæˆå¤±è´¥: {e}")
            return f"å›¾ç‰‡: {os.path.basename(image_path)} (å¤„ç†å¤±è´¥)"
    
    def _generate_table_description(self, table_path: str, page_context: str) -> str:
        """
        ç”Ÿæˆè¡¨æ ¼æè¿°
        
        Args:
            table_path: è¡¨æ ¼è·¯å¾„
            page_context: é¡µé¢ä¸Šä¸‹æ–‡
            
        Returns:
            str: è¡¨æ ¼æè¿°
        """
        if not os.path.exists(table_path):
            return f"è¡¨æ ¼æ–‡ä»¶ä¸å­˜åœ¨: {table_path}"
        
        try:
            # ä½¿ç”¨Gemini 2.5 Flashè¿›è¡Œå¤šæ¨¡æ€è¡¨æ ¼æè¿°
            if 'openrouter' in self.ai_clients:
                print(f"ðŸ“Š ä½¿ç”¨Gemini 2.5 Flashç”Ÿæˆè¡¨æ ¼æè¿°: {os.path.basename(table_path)}")
                vlm_model = self.config.ai_content.default_vlm_model  # google/gemini-2.5-flash
                return self._call_openrouter_for_vision(
                    table_path, page_context, vlm_model, is_table=True
                )
            else:
                print("âš ï¸ OpenRouterå®¢æˆ·ç«¯ä¸å¯ç”¨ï¼Œè·³è¿‡è¡¨æ ¼æè¿°ç”Ÿæˆ")
                return f"è¡¨æ ¼: {os.path.basename(table_path)}"
                
        except Exception as e:
            print(f"âŒ è¡¨æ ¼æè¿°ç”Ÿæˆå¤±è´¥: {e}")
            return f"è¡¨æ ¼: {os.path.basename(table_path)} (å¤„ç†å¤±è´¥)"
    
    def _call_qwen_for_text(self, text: str) -> str:
        """è°ƒç”¨Qwenè¿›è¡Œæ–‡æœ¬æ¸…æ´—"""
        try:
            client = self.ai_clients['qwen']
            prompt = self.text_cleaning_prompt.format(raw_text=text)
            
            # è°ƒç”¨Qwen API
            response = client.generate_response(prompt)
            return response.strip() if response else text
            
        except Exception as e:
            print(f"âŒ Qwenè°ƒç”¨å¤±è´¥: {e}")
            # å¦‚æžœQwenå¤±è´¥ï¼Œå°è¯•é™çº§åˆ°DeepSeek
            if 'deepseek' in self.ai_clients:
                print("ðŸ”„ é™çº§åˆ°DeepSeek...")
                return self._call_deepseek_for_text(text)
            return text
    
    def _call_deepseek_for_text(self, text: str) -> str:
        """è°ƒç”¨DeepSeekè¿›è¡Œæ–‡æœ¬æ¸…æ´—"""
        try:
            client = self.ai_clients['deepseek']
            prompt = self.text_cleaning_prompt.format(raw_text=text)
            
            # è°ƒç”¨DeepSeek API
            response = client.generate_response(prompt)
            return response.strip() if response else text
            
        except Exception as e:
            print(f"âŒ DeepSeekè°ƒç”¨å¤±è´¥: {e}")
            return text
    
    def _call_openrouter_for_vision(self, image_path: str, page_context: str, 
                                  model: str, is_table: bool = False) -> str:
        """è°ƒç”¨OpenRouterè¿›è¡Œè§†è§‰å¤„ç†"""
        try:
            client = self.ai_clients['openrouter']
            
            # é€‰æ‹©åˆé€‚çš„æç¤ºè¯
            if is_table:
                prompt = self.table_description_prompt.format(page_context=page_context)
            else:
                prompt = self.image_description_prompt.format(page_context=page_context)
            
            # è°ƒç”¨OpenRouter Vision APIï¼ˆä½¿ç”¨çŽ°æœ‰çš„get_image_description_geminiæ–¹æ³•ï¼‰
            response = client.get_image_description_gemini(image_path, prompt)
            
            return response.strip() if response else f"{'è¡¨æ ¼' if is_table else 'å›¾ç‰‡'}å¤„ç†å¤±è´¥"
            
        except Exception as e:
            print(f"âŒ OpenRouterè§†è§‰è°ƒç”¨å¤±è´¥: {e}")
            return f"{'è¡¨æ ¼' if is_table else 'å›¾ç‰‡'}: {os.path.basename(image_path)} (å¤„ç†å¤±è´¥)"
    
    def get_processing_stats(self, pages: List[PageData]) -> Dict[str, Any]:
        """
        èŽ·å–å¤„ç†ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            pages: å¤„ç†åŽçš„é¡µé¢æ•°æ®
            
        Returns:
            Dict[str, Any]: ç»Ÿè®¡ä¿¡æ¯
        """
        stats = {
            "total_pages": len(pages),
            "pages_with_cleaned_text": 0,
            "total_images": 0,
            "images_with_ai_description": 0,
            "total_tables": 0,
            "tables_with_ai_description": 0,
            "average_text_length": 0,
            "average_cleaned_text_length": 0
        }
        
        total_text_length = 0
        total_cleaned_text_length = 0
        
        for page in pages:
            # æ–‡æœ¬ç»Ÿè®¡
            if page.raw_text:
                total_text_length += len(page.raw_text)
            if page.cleaned_text:
                stats["pages_with_cleaned_text"] += 1
                total_cleaned_text_length += len(page.cleaned_text)
            
            # å›¾ç‰‡ç»Ÿè®¡
            stats["total_images"] += len(page.images)
            for img in page.images:
                if img.ai_description:
                    stats["images_with_ai_description"] += 1
            
            # è¡¨æ ¼ç»Ÿè®¡
            stats["total_tables"] += len(page.tables)
            for table in page.tables:
                if table.ai_description:
                    stats["tables_with_ai_description"] += 1
        
        # è®¡ç®—å¹³å‡å€¼
        if stats["total_pages"] > 0:
            stats["average_text_length"] = total_text_length / stats["total_pages"]
            
        if stats["pages_with_cleaned_text"] > 0:
            stats["average_cleaned_text_length"] = total_cleaned_text_length / stats["pages_with_cleaned_text"]
        
        return stats 