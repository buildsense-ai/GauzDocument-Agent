"""
PDF Document Parser

ä¸“é—¨è´Ÿè´£PDFæ–‡æ¡£è§£æçš„ç»„ä»¶ï¼Œä½¿ç”¨Doclingè¿›è¡Œè§£æå¹¶æŒ‰é¡µè¾“å‡ºæ–‡æœ¬å†…å®¹
"""

import os
import re
from typing import Dict, Any, Optional, Tuple
from pathlib import Path

from .config import PDFProcessingConfig, DoclingConfig

# å¯¼å…¥doclingç›¸å…³ç»„ä»¶
try:
    from docling.datamodel.base_models import InputFormat
    from docling.datamodel.pipeline_options import PdfPipelineOptions, EasyOcrOptions
    from docling.document_converter import DocumentConverter, PdfFormatOption
    DOCLING_AVAILABLE = True
    print("âœ… Doclingç»„ä»¶å¯ç”¨")
except ImportError as e:
    DOCLING_AVAILABLE = False
    print(f"âŒ Doclingç»„ä»¶ä¸å¯ç”¨: {e}")
    
    # åˆ›å»ºå ä½ç¬¦ç±»å‹ï¼Œé¿å…ç±»å‹é”™è¯¯
    class DocumentConverter:
        pass
    
    class PdfPipelineOptions:
        pass


class PDFDocumentParser:
    """
    PDFæ–‡æ¡£è§£æå™¨ - ä¸“é—¨è´Ÿè´£PDFæ–‡æ¡£çš„è§£æ
    
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. ä½¿ç”¨Doclingè¿›è¡ŒPDFè§£æ
    2. æŒ‰é¡µæå–æ–‡æœ¬å†…å®¹
    3. æ”¯æŒé…ç½®åŒ–çš„è§£æå‚æ•°
    4. è¾“å‡ºåŸå§‹è§£æç»“æœå’ŒæŒ‰é¡µæ–‡æœ¬
    """
    
    def __init__(self, config: Optional[PDFProcessingConfig] = None):
        """
        åˆå§‹åŒ–PDFæ–‡æ¡£è§£æå™¨
        
        Args:
            config: PDFå¤„ç†é…ç½®ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤é…ç½®
        """
        self.config = config or PDFProcessingConfig.from_env()
        self.doc_converter = None
        
        if not DOCLING_AVAILABLE:
            print("âš ï¸ Doclingä¸å¯ç”¨ï¼ŒPDFDocumentParseråŠŸèƒ½å—é™")
            return
            
        self._init_docling_converter()
    
    def _init_docling_converter(self) -> None:
        """åˆå§‹åŒ–Doclingè½¬æ¢å™¨"""
        try:
            # è®¾ç½®æœ¬åœ°æ¨¡å‹è·¯å¾„
            models_cache_dir = Path("models_cache")
            artifacts_path = None
            if models_cache_dir.exists():
                artifacts_path = str(models_cache_dir.absolute())
            elif self.config.docling.artifacts_path:
                artifacts_path = self.config.docling.artifacts_path
            
            # åˆ›å»ºOCRé€‰é¡¹
            ocr_options = EasyOcrOptions() if self.config.docling.ocr_enabled else None
            
            # åˆ›å»ºç®¡é“é€‰é¡¹
            pipeline_options = PdfPipelineOptions(
                ocr_options=ocr_options,
                artifacts_path=artifacts_path
            )
            
            # è®¾ç½®è§£æé€‰é¡¹
            pipeline_options.images_scale = self.config.docling.images_scale
            pipeline_options.generate_page_images = self.config.docling.generate_page_images
            pipeline_options.generate_picture_images = self.config.docling.generate_picture_images
            
            # åˆ›å»ºæ–‡æ¡£è½¬æ¢å™¨
            self.doc_converter = DocumentConverter(
                format_options={
                    InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)
                }
            )
            
            print("âœ… Doclingè½¬æ¢å™¨åˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            print(f"âŒ Doclingè½¬æ¢å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            self.doc_converter = None
    
    def parse_pdf(self, pdf_path: str) -> Tuple[Any, Dict[int, str]]:
        """
        è§£æPDFæ–‡ä»¶
        
        Args:
            pdf_path: PDFæ–‡ä»¶è·¯å¾„
            
        Returns:
            Tuple[Any, Dict[int, str]]: (raw_result, page_texts)
            - raw_result: DoclingåŸå§‹è§£æç»“æœ
            - page_texts: é¡µç åˆ°é¡µé¢æ–‡æœ¬çš„æ˜ å°„
        """
        if not DOCLING_AVAILABLE:
            raise RuntimeError("Doclingä¸å¯ç”¨ï¼Œæ— æ³•è§£æPDF")
        
        if not self.doc_converter:
            raise RuntimeError("Doclingè½¬æ¢å™¨æœªåˆå§‹åŒ–")
        
        if not os.path.exists(pdf_path):
            raise FileNotFoundError(f"PDFæ–‡ä»¶ä¸å­˜åœ¨: {pdf_path}")
        
        print(f"ğŸ”„ å¼€å§‹è§£æPDF: {pdf_path}")
        
        try:
            # ä½¿ç”¨Doclingè§£æPDF
            raw_result = self.doc_converter.convert(Path(pdf_path))
            print("âœ… Doclingè§£æå®Œæˆ")
            
            # æå–æŒ‰é¡µæ–‡æœ¬
            page_texts = self._extract_page_texts(raw_result)
            print(f"ğŸ“„ æå–åˆ° {len(page_texts)} é¡µæ–‡æœ¬")
            
            return raw_result, page_texts
            
        except Exception as e:
            print(f"âŒ PDFè§£æå¤±è´¥: {e}")
            raise RuntimeError(f"PDFè§£æå¤±è´¥: {str(e)}")
    
    def _extract_page_texts(self, raw_result: Any) -> Dict[int, str]:
        """
        ä»Doclingè§£æç»“æœä¸­æå–æŒ‰é¡µæ–‡æœ¬
        
        Args:
            raw_result: Doclingè§£æç»“æœ
            
        Returns:
            Dict[int, str]: é¡µç åˆ°é¡µé¢æ–‡æœ¬çš„æ˜ å°„
        """
        try:
            # å¯¼å‡ºä¸ºmarkdownæ ¼å¼
            raw_markdown = raw_result.document.export_to_markdown()
            
            # æ¸…ç†markdownå†…å®¹ï¼ˆç§»é™¤HTMLæ³¨é‡Šï¼‰
            markdown_clean_pattern = re.compile(r"<!--[\s\S]*?-->")
            cleaned_markdown = markdown_clean_pattern.sub("", raw_markdown)
            
            # æŒ‰é¡µåˆ†å‰²æ–‡æœ¬
            page_texts = self._split_text_by_pages(cleaned_markdown, raw_result)
            
            return page_texts
            
        except Exception as e:
            print(f"âŒ é¡µé¢æ–‡æœ¬æå–å¤±è´¥: {e}")
            return {}
    
    def _split_text_by_pages(self, text_content: str, raw_result: Any) -> Dict[int, str]:
        """
        å°†æ–‡æœ¬æŒ‰é¡µåˆ†å‰²
        
        Args:
            text_content: æ¸…ç†åçš„æ–‡æœ¬å†…å®¹
            raw_result: Doclingè§£æç»“æœ
            
        Returns:
            Dict[int, str]: é¡µç åˆ°é¡µé¢æ–‡æœ¬çš„æ˜ å°„
        """
        try:
            # å°è¯•ä»Doclingç»“æœä¸­è·å–é¡µé¢ä¿¡æ¯
            page_texts = {}
            
            # æ–¹æ³•1ï¼šå°è¯•ä»æ–‡æ¡£ç»“æ„ä¸­æŒ‰é¡µæå– (document.pagesæ˜¯å­—å…¸)
            if hasattr(raw_result, 'document') and hasattr(raw_result.document, 'pages'):
                pages_dict = raw_result.document.pages
                print(f"ğŸ“„ å‘ç° {len(pages_dict)} ä¸ªé¡µé¢")
                
                # pagesæ˜¯å­—å…¸ï¼Œkeyæ˜¯é¡µç 
                for page_num, page in pages_dict.items():
                    page_text = ""
                    
                    # å°è¯•å¤šç§æ–¹å¼æå–é¡µé¢æ–‡æœ¬
                    try:
                        # æ–¹å¼1ï¼šä½¿ç”¨export_to_textæ–¹æ³•ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                        if hasattr(raw_result.document, 'export_to_text'):
                            # è·å–è¯¥é¡µé¢çš„æ–‡æœ¬
                            full_text = raw_result.document.export_to_text()
                            # è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªç®€å•çš„æ–¹æ³•ï¼šå°†å…¨æ–‡æŒ‰é¡µé¢æ•°é‡åˆ†å‰²
                            lines = full_text.split('\n')
                            lines_per_page = len(lines) // len(pages_dict)
                            start_idx = (page_num - 1) * lines_per_page
                            end_idx = start_idx + lines_per_page if page_num < len(pages_dict) else len(lines)
                            page_text = '\n'.join(lines[start_idx:end_idx])
                        
                        # æ–¹å¼2ï¼šå¦‚æœæœ‰elementså±æ€§
                        elif hasattr(page, 'elements'):
                            for element in page.elements:
                                if hasattr(element, 'text') and element.text:
                                    page_text += element.text + "\n"
                        
                        # æ–¹å¼3ï¼šå¦‚æœpageæœ‰textå±æ€§
                        elif hasattr(page, 'text'):
                            page_text = page.text
                        
                        # æ–¹å¼4ï¼šå…¶ä»–å¯èƒ½çš„æ–‡æœ¬å±æ€§
                        else:
                            # å°è¯•ä»pageå¯¹è±¡ä¸­æå–ä»»ä½•å¯èƒ½çš„æ–‡æœ¬
                            for attr in dir(page):
                                if not attr.startswith('_') and 'text' in attr.lower():
                                    try:
                                        attr_value = getattr(page, attr)
                                        if isinstance(attr_value, str) and attr_value.strip():
                                            page_text += attr_value + "\n"
                                    except:
                                        continue
                    
                    except Exception as e:
                        print(f"âš ï¸ é¡µé¢ {page_num} æ–‡æœ¬æå–å¤±è´¥: {e}")
                        continue
                    
                    if page_text.strip():
                        page_texts[page_num] = page_text.strip()
            
            # æ–¹æ³•2ï¼šå¦‚æœæ–¹æ³•1å¤±è´¥ï¼Œå°è¯•ä»raw_result.pagesåˆ—è¡¨ä¸­æå–
            if not page_texts and hasattr(raw_result, 'pages'):
                print("ğŸ”„ å°è¯•ä»raw_result.pagesæå–é¡µé¢æ–‡æœ¬...")
                pages_list = raw_result.pages
                if pages_list:
                    for page_num, page in enumerate(pages_list, 1):
                        page_text = ""
                        
                        # å°è¯•æå–é¡µé¢æ–‡æœ¬
                        if hasattr(page, 'text'):
                            page_text = page.text
                        elif hasattr(page, 'content'):
                            page_text = page.content
                        
                        if page_text.strip():
                            page_texts[page_num] = page_text.strip()
            
            # æ–¹æ³•3ï¼šå¦‚æœä»ç„¶æ²¡æœ‰åˆ†é¡µï¼ŒæŒ‰markdownç»“æ„æ™ºèƒ½åˆ†å‰²
            if not page_texts and text_content.strip():
                print("ğŸ”„ å°è¯•æ™ºèƒ½åˆ†å‰²æ–‡æœ¬...")
                # ä½¿ç”¨æ›´æ™ºèƒ½çš„åˆ†å‰²æ–¹æ³•
                page_texts = self._smart_split_text(text_content)
            
            # æ–¹æ³•4ï¼šå¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼Œå°†æ‰€æœ‰æ–‡æœ¬ä½œä¸ºç¬¬ä¸€é¡µ
            if not page_texts and text_content.strip():
                page_texts[1] = text_content.strip()
                print("âš ï¸ æ— æ³•è¯†åˆ«é¡µé¢åˆ†å‰²ï¼Œå°†æ‰€æœ‰æ–‡æœ¬ä½œä¸ºç¬¬ä¸€é¡µ")
            
            return page_texts
            
        except Exception as e:
            print(f"âŒ æ–‡æœ¬åˆ†é¡µå¤±è´¥: {e}")
            # ä½œä¸ºæœ€åçš„å¤‡é€‰æ–¹æ¡ˆ
            if text_content.strip():
                return {1: text_content.strip()}
            return {}
    
    def _smart_split_text(self, text_content: str) -> Dict[int, str]:
        """
        æ™ºèƒ½åˆ†å‰²æ–‡æœ¬ï¼ŒåŸºäºå†…å®¹ç»“æ„
        
        Args:
            text_content: æ–‡æœ¬å†…å®¹
            
        Returns:
            Dict[int, str]: é¡µç åˆ°é¡µé¢æ–‡æœ¬çš„æ˜ å°„
        """
        # æŒ‰ç…§å­¦æœ¯è®ºæ–‡çš„ç»“æ„ç‰¹å¾è¿›è¡Œåˆ†å‰²
        # å¯»æ‰¾ç« èŠ‚æ ‡é¢˜ã€å›¾è¡¨æ ‡é¢˜ç­‰ä½œä¸ºåˆ†å‰²ç‚¹
        
        lines = text_content.split('\n')
        page_texts = {}
        current_page = 1
        current_page_text = []
        
        # ä¼°ç®—æ¯é¡µçš„è¡Œæ•°ï¼ˆåŸºäºæ€»è¡Œæ•°å’Œé¢„æœŸé¡µé¢æ•°ï¼‰
        estimated_pages = max(1, len(lines) // 100)  # å‡è®¾æ¯é¡µçº¦100è¡Œ
        lines_per_page = len(lines) // estimated_pages
        
        for i, line in enumerate(lines):
            current_page_text.append(line)
            
            # æ¯è¾¾åˆ°é¢„ä¼°è¡Œæ•°ï¼Œæˆ–é‡åˆ°æ˜æ˜¾çš„åˆ†å‰²æ ‡è¯†ï¼Œå°±åˆ†é¡µ
            if (len(current_page_text) >= lines_per_page and 
                (self._is_page_break(line) or self._is_section_start(line))):
                
                if current_page_text:
                    page_texts[current_page] = '\n'.join(current_page_text).strip()
                current_page += 1
                current_page_text = []
        
        # ä¿å­˜æœ€åä¸€é¡µ
        if current_page_text:
            page_texts[current_page] = '\n'.join(current_page_text).strip()
        
        return page_texts
    
    def _is_section_start(self, line: str) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦æ˜¯ç« èŠ‚å¼€å§‹
        
        Args:
            line: æ–‡æœ¬è¡Œ
            
        Returns:
            bool: æ˜¯å¦æ˜¯ç« èŠ‚å¼€å§‹
        """
        # æ£€æŸ¥æ˜¯å¦æ˜¯ç« èŠ‚æ ‡é¢˜
        section_patterns = [
            r'^\s*#+\s+',  # Markdownæ ‡é¢˜
            r'^\s*\d+\.\s+',  # æ•°å­—æ ‡é¢˜
            r'^\s*[A-Z][A-Z\s]+$',  # å…¨å¤§å†™æ ‡é¢˜
            r'^\s*Figure\s+\d+',  # å›¾è¡¨æ ‡é¢˜
            r'^\s*Table\s+\d+',  # è¡¨æ ¼æ ‡é¢˜
        ]
        
        for pattern in section_patterns:
            if re.match(pattern, line):
                return True
        
        return False
    
    def _is_page_break(self, line: str) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦æ˜¯é¡µé¢åˆ†å‰²æ ‡è¯†
        
        Args:
            line: æ–‡æœ¬è¡Œ
            
        Returns:
            bool: æ˜¯å¦æ˜¯é¡µé¢åˆ†å‰²æ ‡è¯†
        """
        # å¸¸è§çš„é¡µé¢åˆ†å‰²æ ‡è¯†
        page_break_patterns = [
            r'^\s*---+\s*$',  # è¿ç»­çš„ç ´æŠ˜å·
            r'^\s*===+\s*$',  # è¿ç»­çš„ç­‰å·
            r'^\s*Page\s+\d+\s*$',  # Page æ•°å­—
            r'^\s*ç¬¬\s*\d+\s*é¡µ\s*$',  # ç¬¬Xé¡µ
            r'^\s*\d+\s*$',  # çº¯æ•°å­—ï¼ˆå¯èƒ½çš„é¡µç ï¼‰
        ]
        
        for pattern in page_break_patterns:
            if re.match(pattern, line, re.IGNORECASE):
                return True
        
        return False
    
    def get_raw_text(self, pdf_path: str) -> str:
        """
        è·å–PDFçš„åŸå§‹æ–‡æœ¬å†…å®¹ï¼ˆä¸åˆ†é¡µï¼‰
        
        Args:
            pdf_path: PDFæ–‡ä»¶è·¯å¾„
            
        Returns:
            str: åŸå§‹æ–‡æœ¬å†…å®¹
        """
        raw_result, _ = self.parse_pdf(pdf_path)
        
        try:
            # å¯¼å‡ºä¸ºmarkdownæ ¼å¼
            raw_markdown = raw_result.document.export_to_markdown()
            
            # æ¸…ç†markdownå†…å®¹
            markdown_clean_pattern = re.compile(r"<!--[\s\S]*?-->")
            cleaned_text = markdown_clean_pattern.sub("", raw_markdown)
            
            return cleaned_text.strip()
            
        except Exception as e:
            print(f"âŒ åŸå§‹æ–‡æœ¬æå–å¤±è´¥: {e}")
            return ""
    
    def get_document_info(self, pdf_path: str) -> Dict[str, Any]:
        """
        è·å–PDFæ–‡æ¡£ä¿¡æ¯
        
        Args:
            pdf_path: PDFæ–‡ä»¶è·¯å¾„
            
        Returns:
            Dict[str, Any]: æ–‡æ¡£ä¿¡æ¯
        """
        if not DOCLING_AVAILABLE or not self.doc_converter:
            return {
                "error": "Doclingä¸å¯ç”¨",
                "file_path": pdf_path,
                "file_size": os.path.getsize(pdf_path) if os.path.exists(pdf_path) else 0
            }
        
        try:
            raw_result, page_texts = self.parse_pdf(pdf_path)
            
            # è®¡ç®—æ–‡æ¡£ç»Ÿè®¡ä¿¡æ¯
            total_text_length = sum(len(text) for text in page_texts.values())
            
            return {
                "file_path": pdf_path,
                "file_name": os.path.basename(pdf_path),
                "file_size": os.path.getsize(pdf_path),
                "total_pages": len(page_texts),
                "total_text_length": total_text_length,
                "average_text_per_page": total_text_length / len(page_texts) if page_texts else 0,
                "config": {
                    "images_scale": self.config.docling.images_scale,
                    "ocr_enabled": self.config.docling.ocr_enabled,
                    "generate_page_images": self.config.docling.generate_page_images,
                    "generate_picture_images": self.config.docling.generate_picture_images
                }
            }
            
        except Exception as e:
            return {
                "error": f"æ–‡æ¡£ä¿¡æ¯è·å–å¤±è´¥: {str(e)}",
                "file_path": pdf_path,
                "file_size": os.path.getsize(pdf_path) if os.path.exists(pdf_path) else 0
            } 