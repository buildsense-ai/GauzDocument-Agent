"""
PDF Document Parser

ä¸“é—¨è´Ÿè´£PDFæ–‡æ¡£è§£æçš„ç»„ä»¶ï¼Œä½¿ç”¨Doclingè¿›è¡Œè§£æå¹¶æŒ‰é¡µè¾“å‡ºæ–‡æœ¬å†…å®¹
"""

import os
import re
from typing import Dict, Any, Optional, Tuple
from pathlib import Path

from .config import PDFProcessingConfig, DoclingConfig

# å¯¼å…¥doclingç›¸å…³ç»„ä»¶
try:
    from docling.datamodel.base_models import InputFormat
    from docling.datamodel.pipeline_options import PdfPipelineOptions, EasyOcrOptions
    from docling.document_converter import DocumentConverter, PdfFormatOption
    DOCLING_AVAILABLE = True
    print("âœ… Doclingç»„ä»¶å¯ç”¨")
except ImportError as e:
    DOCLING_AVAILABLE = False
    print(f"âŒ Doclingç»„ä»¶ä¸å¯ç”¨: {e}")
    
    # åˆ›å»ºå ä½ç¬¦ç±»å‹ï¼Œé¿å…ç±»å‹é”™è¯¯
    class DocumentConverter:
        pass
    
    class PdfPipelineOptions:
        pass

# å¯¼å…¥å¤‡ç”¨PDFå¤„ç†åº“
try:
    import fitz  # PyMuPDF
    PYMUPDF_AVAILABLE = True
    print("âœ… PyMuPDFå¯ç”¨ä½œå¤‡ç”¨è§£æå™¨")
except ImportError:
    PYMUPDF_AVAILABLE = False
    print("âŒ PyMuPDFä¸å¯ç”¨")


class PDFDocumentParser:
    """
    PDFæ–‡æ¡£è§£æå™¨ - ä¸“é—¨è´Ÿè´£PDFæ–‡æ¡£çš„è§£æ
    
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. ä½¿ç”¨Doclingè¿›è¡ŒPDFè§£æ
    2. æŒ‰é¡µæå–æ–‡æœ¬å†…å®¹
    3. æ”¯æŒé…ç½®åŒ–çš„è§£æå‚æ•°
    4. è¾“å‡ºåŸå§‹è§£æç»“æœå’ŒæŒ‰é¡µæ–‡æœ¬
    """
    
    def __init__(self, config: Optional[PDFProcessingConfig] = None):
        """
        åˆå§‹åŒ–PDFæ–‡æ¡£è§£æå™¨
        
        Args:
            config: PDFå¤„ç†é…ç½®ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤é…ç½®
        """
        self.config = config or PDFProcessingConfig.from_env()
        self.doc_converter = None
        
        if not DOCLING_AVAILABLE:
            print("âš ï¸ Doclingä¸å¯ç”¨ï¼ŒPDFDocumentParseråŠŸèƒ½å—é™")
            return
            
        self._init_docling_converter()
    
    def _init_docling_converter(self) -> None:
        """åˆå§‹åŒ–Doclingè½¬æ¢å™¨ï¼ˆæ™ºèƒ½è®¾å¤‡é€‚é…ç‰ˆæœ¬ï¼‰"""
        try:
            import torch
            import os
            import platform
            import multiprocessing
            
            # æ£€æµ‹ç¡¬ä»¶èƒ½åŠ›
            system_info = platform.system()
            cpu_count = multiprocessing.cpu_count()
            
            # è®¾å¤‡æ£€æµ‹å’Œä¼˜åŒ–
            device = "cpu"
            use_gpu = False
            use_mps = False
            
            if torch.cuda.is_available():
                device = "cuda:0"
                use_gpu = True
                # CUDA GPUä¼˜åŒ–è®¾ç½®
                torch.backends.cudnn.benchmark = True
                os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'
                torch.backends.cuda.matmul.allow_tf32 = True
                torch.backends.cudnn.allow_tf32 = True
                print(f"ğŸš€ CUDA GPUæ£€æµ‹æˆåŠŸ - è®¾å¤‡: {torch.cuda.get_device_name(0)}")
            elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                device = "mps"
                use_mps = True
                print("ğŸ Apple Silicon MPSæ£€æµ‹æˆåŠŸ")
            else:
                print(f"ğŸ’» ä½¿ç”¨CPUæ¨¡å¼ - ç³»ç»Ÿ: {system_info}, CPUæ ¸å¿ƒ: {cpu_count}")
            
            # æ ¹æ®ç¡¬ä»¶è®¾ç½®çº¿ç¨‹æ•°
            if use_gpu:
                # GPUæ¨¡å¼ï¼šé€‚ä¸­çš„çº¿ç¨‹æ•°é¿å…CPU-GPUç«äº‰
                optimal_threads = min(16, cpu_count)
            else:
                # CPUæ¨¡å¼ï¼šå……åˆ†åˆ©ç”¨CPUæ ¸å¿ƒ
                optimal_threads = max(1, cpu_count - 1)  # ä¿ç•™ä¸€ä¸ªæ ¸å¿ƒç»™ç³»ç»Ÿ
            
            torch.set_num_threads(optimal_threads)
            
            # è®¾ç½®æœ¬åœ°æ¨¡å‹è·¯å¾„
            models_cache_dir = Path("models_cache")
            artifacts_path = None
            if models_cache_dir.exists():
                artifacts_path = str(models_cache_dir.absolute())
            elif self.config.docling.artifacts_path:
                artifacts_path = self.config.docling.artifacts_path
            
            # æ™ºèƒ½åŠ é€Ÿå™¨é€‰é¡¹
            from docling.datamodel.accelerator_options import AcceleratorOptions
            accelerator_options = AcceleratorOptions(
                device=device,
                num_threads=optimal_threads,
                cuda_use_flash_attention2=use_gpu  # ä»…åœ¨GPUæ¨¡å¼ä¸‹å¯ç”¨
            )
            
            # æ™ºèƒ½OCRé€‰é¡¹
            ocr_options = None
            if self.config.docling.ocr_enabled:
                # æ ¹æ®EasyOCRæ”¯æŒçš„è¯­è¨€åˆ—è¡¨é€‰æ‹©å®‰å…¨çš„è¯­è¨€ç»„åˆ
                supported_langs = ["en"]  # è‹±è¯­æ˜¯æœ€ç¨³å®šæ”¯æŒçš„
                if not use_gpu:  # CPUæ¨¡å¼ä¸‹æ·»åŠ æ›´å¤šè¯­è¨€æ”¯æŒ
                    supported_langs.extend(["fr", "de"])  # æ³•è¯­å’Œå¾·è¯­é€šå¸¸æ”¯æŒè¾ƒå¥½
                
                ocr_options = EasyOcrOptions(
                    confidence_threshold=0.4,
                    lang=supported_langs
                    # æ³¨æ„ï¼šä¸å†ä½¿ç”¨å·²å¼ƒç”¨çš„use_gpuå‚æ•°ï¼Œè®¾å¤‡é€‰æ‹©ç”±accelerator_optionsæ§åˆ¶
                )
            
            # æ™ºèƒ½è¡¨æ ¼ç»“æ„é€‰é¡¹
            from docling.datamodel.pipeline_options import TableStructureOptions, TableFormerMode
            # æ ¹æ®ç¡¬ä»¶èƒ½åŠ›é€‰æ‹©æ¨¡å¼
            table_mode = TableFormerMode.FAST if (use_gpu or use_mps) else TableFormerMode.ACCURATE
            table_options = TableStructureOptions(
                mode=table_mode,
                do_cell_matching=True
            )
            
            # åˆ›å»ºæ™ºèƒ½ç®¡é“é€‰é¡¹
            pipeline_options = PdfPipelineOptions(
                # æ ¸å¿ƒå¤„ç†é€‰é¡¹
                do_table_structure=True,
                do_ocr=self.config.docling.ocr_enabled,
                do_picture_description=use_gpu or use_mps,  # ä»…åœ¨æœ‰åŠ é€Ÿå™¨æ—¶å¯ç”¨
                do_picture_classification=True,
                
                # é…ç½®é€‰é¡¹
                ocr_options=ocr_options,
                table_structure_options=table_options,
                
                # åŠ é€Ÿå™¨é€‰é¡¹
                accelerator_options=accelerator_options,
                
                # å›¾åƒç”Ÿæˆé€‰é¡¹
                images_scale=self.config.docling.images_scale,
                generate_page_images=self.config.docling.generate_page_images,
                generate_picture_images=self.config.docling.generate_picture_images,
                
                # æ€§èƒ½é€‰é¡¹ï¼ˆæ ¹æ®ç¡¬ä»¶è°ƒæ•´è¶…æ—¶ï¼‰
                document_timeout=600.0 if device == "cpu" else 300.0,
                artifacts_path=artifacts_path
            )
            
            # åˆ›å»ºæ–‡æ¡£è½¬æ¢å™¨
            self.doc_converter = DocumentConverter(
                format_options={
                    InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)
                }
            )
            
            # è¾“å‡ºä¼˜åŒ–ä¿¡æ¯
            device_name = {
                "cuda:0": f"CUDA GPU ({torch.cuda.get_device_name(0)})",
                "mps": "Apple Silicon MPS",
                "cpu": f"CPU ({system_info})"
            }.get(device, device)
            
            print(f"âœ… Doclingè½¬æ¢å™¨åˆå§‹åŒ–æˆåŠŸ - è®¾å¤‡: {device_name}")
            print(f"ğŸ“Š çº¿ç¨‹æ•°: {optimal_threads}, è¡¨æ ¼æ¨¡å¼: {table_mode.value}")
            print(f"ğŸ”§ å›¾ç‰‡æè¿°: {'å¯ç”¨' if (use_gpu or use_mps) else 'ç¦ç”¨'}, OCR GPU: {'å¯ç”¨' if use_gpu else 'ç¦ç”¨'}")
            
        except Exception as e:
            print(f"âŒ Doclingè½¬æ¢å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            self.doc_converter = None
    
    def parse_pdf(self, pdf_path: str) -> Tuple[Any, Dict[int, str]]:
        """
        è§£æPDFæ–‡ä»¶
        
        Args:
            pdf_path: PDFæ–‡ä»¶è·¯å¾„
            
        Returns:
            Tuple[Any, Dict[int, str]]: (raw_result, page_texts)
            - raw_result: è§£æç»“æœï¼ˆDoclingæˆ–PyMuPDFï¼‰
            - page_texts: é¡µç åˆ°é¡µé¢æ–‡æœ¬çš„æ˜ å°„
        """
        if not os.path.exists(pdf_path):
            raise FileNotFoundError(f"PDFæ–‡ä»¶ä¸å­˜åœ¨: {pdf_path}")
        
        print(f"ğŸ”„ å¼€å§‹è§£æPDF: {pdf_path}")
        
        # ä¼˜å…ˆä½¿ç”¨Docling
        if DOCLING_AVAILABLE and self.doc_converter:
            try:
                # ä½¿ç”¨Doclingè§£æPDF
                raw_result = self.doc_converter.convert(Path(pdf_path))
                print("âœ… Doclingè§£æå®Œæˆ")
                
                # æå–æŒ‰é¡µæ–‡æœ¬
                page_texts = self._extract_page_texts(raw_result)
                print(f"ğŸ“„ æå–åˆ° {len(page_texts)} é¡µæ–‡æœ¬")
                
                return raw_result, page_texts
                
            except Exception as e:
                print(f"âš ï¸ Doclingè§£æå¤±è´¥ï¼Œå°è¯•é™çº§å¤„ç†: {e}")
        
        # é™çº§åˆ°PyMuPDF
        if PYMUPDF_AVAILABLE:
            try:
                return self._parse_with_pymupdf(pdf_path)
            except Exception as e:
                print(f"âŒ PyMuPDFè§£æä¹Ÿå¤±è´¥: {e}")
                raise RuntimeError(f"æ‰€æœ‰PDFè§£ææ–¹æ³•éƒ½å¤±è´¥: {str(e)}")
        
        # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½ä¸å¯ç”¨
        raise RuntimeError("æ²¡æœ‰å¯ç”¨çš„PDFè§£æå™¨ï¼ˆDoclingå’ŒPyMuPDFéƒ½ä¸å¯ç”¨ï¼‰")
    
    def _parse_with_pymupdf(self, pdf_path: str) -> Tuple[Any, Dict[int, str]]:
        """
        ä½¿ç”¨PyMuPDFè§£æPDFæ–‡ä»¶ï¼ˆé™çº§å¤„ç†ï¼‰
        
        Args:
            pdf_path: PDFæ–‡ä»¶è·¯å¾„
            
        Returns:
            Tuple[Any, Dict[int, str]]: (raw_result, page_texts)
        """
        print("ğŸ”„ ä½¿ç”¨PyMuPDFè¿›è¡Œé™çº§è§£æ...")
        
        try:
            # æ‰“å¼€PDFæ–‡æ¡£
            doc = fitz.open(pdf_path)
            page_texts = {}
            
            # é€é¡µæå–æ–‡æœ¬
            for page_num in range(len(doc)):
                page = doc.load_page(page_num)
                text = page.get_text()
                
                if text.strip():
                    page_texts[page_num + 1] = text.strip()
            
            doc.close()
            
            print(f"âœ… PyMuPDFè§£æå®Œæˆï¼Œæå–åˆ° {len(page_texts)} é¡µæ–‡æœ¬")
            
            # åˆ›å»ºä¸€ä¸ªç®€å•çš„ç»“æœå¯¹è±¡
            class PyMuPDFResult:
                def __init__(self, page_texts):
                    self.page_texts = page_texts
                    self.source = "PyMuPDF"
            
            raw_result = PyMuPDFResult(page_texts)
            return raw_result, page_texts
            
        except Exception as e:
            print(f"âŒ PyMuPDFè§£æå¤±è´¥: {e}")
            raise RuntimeError(f"PyMuPDFè§£æå¤±è´¥: {str(e)}")
    
    def _extract_page_texts(self, raw_result: Any) -> Dict[int, str]:
        """
        ä»è§£æç»“æœä¸­æå–æŒ‰é¡µæ–‡æœ¬
        
        Args:
            raw_result: è§£æç»“æœï¼ˆDoclingæˆ–PyMuPDFï¼‰
            
        Returns:
            Dict[int, str]: é¡µç åˆ°é¡µé¢æ–‡æœ¬çš„æ˜ å°„
        """
        try:
            # æ£€æŸ¥æ˜¯å¦æ˜¯PyMuPDFç»“æœ
            if hasattr(raw_result, 'source') and raw_result.source == "PyMuPDF":
                return raw_result.page_texts
            
            # Doclingç»“æœå¤„ç†
            # å¯¼å‡ºä¸ºmarkdownæ ¼å¼
            raw_markdown = raw_result.document.export_to_markdown()
            
            # æ¸…ç†markdownå†…å®¹ï¼ˆç§»é™¤HTMLæ³¨é‡Šï¼‰
            markdown_clean_pattern = re.compile(r"<!--[\s\S]*?-->")
            cleaned_markdown = markdown_clean_pattern.sub("", raw_markdown)
            
            # æŒ‰é¡µåˆ†å‰²æ–‡æœ¬
            page_texts = self._split_text_by_pages(cleaned_markdown, raw_result)
            
            return page_texts
            
        except Exception as e:
            print(f"âŒ é¡µé¢æ–‡æœ¬æå–å¤±è´¥: {e}")
            return {}
    
    def _split_text_by_pages(self, text_content: str, raw_result: Any) -> Dict[int, str]:
        """
        å°†æ–‡æœ¬æŒ‰é¡µåˆ†å‰²
        
        Args:
            text_content: æ¸…ç†åçš„æ–‡æœ¬å†…å®¹
            raw_result: Doclingè§£æç»“æœ
            
        Returns:
            Dict[int, str]: é¡µç åˆ°é¡µé¢æ–‡æœ¬çš„æ˜ å°„
        """
        try:
            # å°è¯•ä»Doclingç»“æœä¸­è·å–é¡µé¢ä¿¡æ¯
            page_texts = {}
            
            # æ–¹æ³•1ï¼šå°è¯•ä»æ–‡æ¡£ç»“æ„ä¸­æŒ‰é¡µæå– (document.pagesæ˜¯å­—å…¸)
            if hasattr(raw_result, 'document') and hasattr(raw_result.document, 'pages'):
                pages_dict = raw_result.document.pages
                print(f"ğŸ“„ å‘ç° {len(pages_dict)} ä¸ªé¡µé¢")
                
                # pagesæ˜¯å­—å…¸ï¼Œkeyæ˜¯é¡µç 
                for page_num, page in pages_dict.items():
                    page_text = ""
                    
                    # å°è¯•å¤šç§æ–¹å¼æå–é¡µé¢æ–‡æœ¬
                    try:
                        # æ–¹å¼1ï¼šä½¿ç”¨export_to_textæ–¹æ³•ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                        if hasattr(raw_result.document, 'export_to_text'):
                            # è·å–è¯¥é¡µé¢çš„æ–‡æœ¬
                            full_text = raw_result.document.export_to_text()
                            # è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªç®€å•çš„æ–¹æ³•ï¼šå°†å…¨æ–‡æŒ‰é¡µé¢æ•°é‡åˆ†å‰²
                            lines = full_text.split('\n')
                            lines_per_page = len(lines) // len(pages_dict)
                            start_idx = (page_num - 1) * lines_per_page
                            end_idx = start_idx + lines_per_page if page_num < len(pages_dict) else len(lines)
                            page_text = '\n'.join(lines[start_idx:end_idx])
                        
                        # æ–¹å¼2ï¼šå¦‚æœæœ‰elementså±æ€§
                        elif hasattr(page, 'elements'):
                            for element in page.elements:
                                if hasattr(element, 'text') and element.text:
                                    page_text += element.text + "\n"
                        
                        # æ–¹å¼3ï¼šå¦‚æœpageæœ‰textå±æ€§
                        elif hasattr(page, 'text'):
                            page_text = page.text
                        
                        # æ–¹å¼4ï¼šå…¶ä»–å¯èƒ½çš„æ–‡æœ¬å±æ€§
                        else:
                            # å°è¯•ä»pageå¯¹è±¡ä¸­æå–ä»»ä½•å¯èƒ½çš„æ–‡æœ¬
                            for attr in dir(page):
                                if not attr.startswith('_') and 'text' in attr.lower():
                                    try:
                                        attr_value = getattr(page, attr)
                                        if isinstance(attr_value, str) and attr_value.strip():
                                            page_text += attr_value + "\n"
                                    except:
                                        continue
                    
                    except Exception as e:
                        print(f"âš ï¸ é¡µé¢ {page_num} æ–‡æœ¬æå–å¤±è´¥: {e}")
                        continue
                    
                    if page_text.strip():
                        page_texts[page_num] = page_text.strip()
            
            # æ–¹æ³•2ï¼šå¦‚æœæ–¹æ³•1å¤±è´¥ï¼Œå°è¯•ä»raw_result.pagesåˆ—è¡¨ä¸­æå–
            if not page_texts and hasattr(raw_result, 'pages'):
                print("ğŸ”„ å°è¯•ä»raw_result.pagesæå–é¡µé¢æ–‡æœ¬...")
                pages_list = raw_result.pages
                if pages_list:
                    for page_num, page in enumerate(pages_list, 1):
                        page_text = ""
                        
                        # å°è¯•æå–é¡µé¢æ–‡æœ¬
                        if hasattr(page, 'text'):
                            page_text = page.text
                        elif hasattr(page, 'content'):
                            page_text = page.content
                        
                        if page_text.strip():
                            page_texts[page_num] = page_text.strip()
            
            # æ–¹æ³•3ï¼šå¦‚æœä»ç„¶æ²¡æœ‰åˆ†é¡µï¼ŒæŒ‰markdownç»“æ„æ™ºèƒ½åˆ†å‰²
            if not page_texts and text_content.strip():
                print("ğŸ”„ å°è¯•æ™ºèƒ½åˆ†å‰²æ–‡æœ¬...")
                # ä½¿ç”¨æ›´æ™ºèƒ½çš„åˆ†å‰²æ–¹æ³•
                page_texts = self._smart_split_text(text_content)
            
            # æ–¹æ³•4ï¼šå¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼Œå°†æ‰€æœ‰æ–‡æœ¬ä½œä¸ºç¬¬ä¸€é¡µ
            if not page_texts and text_content.strip():
                page_texts[1] = text_content.strip()
                print("âš ï¸ æ— æ³•è¯†åˆ«é¡µé¢åˆ†å‰²ï¼Œå°†æ‰€æœ‰æ–‡æœ¬ä½œä¸ºç¬¬ä¸€é¡µ")
            
            return page_texts
            
        except Exception as e:
            print(f"âŒ æ–‡æœ¬åˆ†é¡µå¤±è´¥: {e}")
            # ä½œä¸ºæœ€åçš„å¤‡é€‰æ–¹æ¡ˆ
            if text_content.strip():
                return {1: text_content.strip()}
            return {}
    
    def _smart_split_text(self, text_content: str) -> Dict[int, str]:
        """
        æ™ºèƒ½åˆ†å‰²æ–‡æœ¬ï¼ŒåŸºäºå†…å®¹ç»“æ„
        
        Args:
            text_content: æ–‡æœ¬å†…å®¹
            
        Returns:
            Dict[int, str]: é¡µç åˆ°é¡µé¢æ–‡æœ¬çš„æ˜ å°„
        """
        # æŒ‰ç…§å­¦æœ¯è®ºæ–‡çš„ç»“æ„ç‰¹å¾è¿›è¡Œåˆ†å‰²
        # å¯»æ‰¾ç« èŠ‚æ ‡é¢˜ã€å›¾è¡¨æ ‡é¢˜ç­‰ä½œä¸ºåˆ†å‰²ç‚¹
        
        lines = text_content.split('\n')
        page_texts = {}
        current_page = 1
        current_page_text = []
        
        # ä¼°ç®—æ¯é¡µçš„è¡Œæ•°ï¼ˆåŸºäºæ€»è¡Œæ•°å’Œé¢„æœŸé¡µé¢æ•°ï¼‰
        estimated_pages = max(1, len(lines) // 100)  # å‡è®¾æ¯é¡µçº¦100è¡Œ
        lines_per_page = len(lines) // estimated_pages
        
        for i, line in enumerate(lines):
            current_page_text.append(line)
            
            # æ¯è¾¾åˆ°é¢„ä¼°è¡Œæ•°ï¼Œæˆ–é‡åˆ°æ˜æ˜¾çš„åˆ†å‰²æ ‡è¯†ï¼Œå°±åˆ†é¡µ
            if (len(current_page_text) >= lines_per_page and 
                (self._is_page_break(line) or self._is_section_start(line))):
                
                if current_page_text:
                    page_texts[current_page] = '\n'.join(current_page_text).strip()
                current_page += 1
                current_page_text = []
        
        # ä¿å­˜æœ€åä¸€é¡µ
        if current_page_text:
            page_texts[current_page] = '\n'.join(current_page_text).strip()
        
        return page_texts
    
    def _is_section_start(self, line: str) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦æ˜¯ç« èŠ‚å¼€å§‹
        
        Args:
            line: æ–‡æœ¬è¡Œ
            
        Returns:
            bool: æ˜¯å¦æ˜¯ç« èŠ‚å¼€å§‹
        """
        # æ£€æŸ¥æ˜¯å¦æ˜¯ç« èŠ‚æ ‡é¢˜
        section_patterns = [
            r'^\s*#+\s+',  # Markdownæ ‡é¢˜
            r'^\s*\d+\.\s+',  # æ•°å­—æ ‡é¢˜
            r'^\s*[A-Z][A-Z\s]+$',  # å…¨å¤§å†™æ ‡é¢˜
            r'^\s*Figure\s+\d+',  # å›¾è¡¨æ ‡é¢˜
            r'^\s*Table\s+\d+',  # è¡¨æ ¼æ ‡é¢˜
        ]
        
        for pattern in section_patterns:
            if re.match(pattern, line):
                return True
        
        return False
    
    def _is_page_break(self, line: str) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦æ˜¯é¡µé¢åˆ†å‰²æ ‡è¯†
        
        Args:
            line: æ–‡æœ¬è¡Œ
            
        Returns:
            bool: æ˜¯å¦æ˜¯é¡µé¢åˆ†å‰²æ ‡è¯†
        """
        # å¸¸è§çš„é¡µé¢åˆ†å‰²æ ‡è¯†
        page_break_patterns = [
            r'^\s*---+\s*$',  # è¿ç»­çš„ç ´æŠ˜å·
            r'^\s*===+\s*$',  # è¿ç»­çš„ç­‰å·
            r'^\s*Page\s+\d+\s*$',  # Page æ•°å­—
            r'^\s*ç¬¬\s*\d+\s*é¡µ\s*$',  # ç¬¬Xé¡µ
            r'^\s*\d+\s*$',  # çº¯æ•°å­—ï¼ˆå¯èƒ½çš„é¡µç ï¼‰
        ]
        
        for pattern in page_break_patterns:
            if re.match(pattern, line, re.IGNORECASE):
                return True
        
        return False
    
    def get_raw_text(self, pdf_path: str) -> str:
        """
        è·å–PDFçš„åŸå§‹æ–‡æœ¬å†…å®¹ï¼ˆä¸åˆ†é¡µï¼‰
        
        Args:
            pdf_path: PDFæ–‡ä»¶è·¯å¾„
            
        Returns:
            str: åŸå§‹æ–‡æœ¬å†…å®¹
        """
        raw_result, _ = self.parse_pdf(pdf_path)
        
        try:
            # å¯¼å‡ºä¸ºmarkdownæ ¼å¼
            raw_markdown = raw_result.document.export_to_markdown()
            
            # æ¸…ç†markdownå†…å®¹
            markdown_clean_pattern = re.compile(r"<!--[\s\S]*?-->")
            cleaned_text = markdown_clean_pattern.sub("", raw_markdown)
            
            return cleaned_text.strip()
            
        except Exception as e:
            print(f"âŒ åŸå§‹æ–‡æœ¬æå–å¤±è´¥: {e}")
            return ""
    
    def get_document_info(self, pdf_path: str) -> Dict[str, Any]:
        """
        è·å–PDFæ–‡æ¡£ä¿¡æ¯
        
        Args:
            pdf_path: PDFæ–‡ä»¶è·¯å¾„
            
        Returns:
            Dict[str, Any]: æ–‡æ¡£ä¿¡æ¯
        """
        if not DOCLING_AVAILABLE or not self.doc_converter:
            return {
                "error": "Doclingä¸å¯ç”¨",
                "file_path": pdf_path,
                "file_size": os.path.getsize(pdf_path) if os.path.exists(pdf_path) else 0
            }
        
        try:
            raw_result, page_texts = self.parse_pdf(pdf_path)
            
            # è®¡ç®—æ–‡æ¡£ç»Ÿè®¡ä¿¡æ¯
            total_text_length = sum(len(text) for text in page_texts.values())
            
            return {
                "file_path": pdf_path,
                "file_name": os.path.basename(pdf_path),
                "file_size": os.path.getsize(pdf_path),
                "total_pages": len(page_texts),
                "total_text_length": total_text_length,
                "average_text_per_page": total_text_length / len(page_texts) if page_texts else 0,
                "config": {
                    "images_scale": self.config.docling.images_scale,
                    "ocr_enabled": self.config.docling.ocr_enabled,
                    "generate_page_images": self.config.docling.generate_page_images,
                    "generate_picture_images": self.config.docling.generate_picture_images
                }
            }
            
        except Exception as e:
            return {
                "error": f"æ–‡æ¡£ä¿¡æ¯è·å–å¤±è´¥: {str(e)}",
                "file_path": pdf_path,
                "file_size": os.path.getsize(pdf_path) if os.path.exists(pdf_path) else 0
            }