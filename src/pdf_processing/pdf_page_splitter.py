"""
PDF Page Splitter

è´Ÿè´£å°†PDFæŒ‰è‡ªç„¶é¡µé¢åˆ‡å‰²æˆå•é¡µPDFæ–‡ä»¶ï¼Œç„¶åæ¯é¡µå•ç‹¬è°ƒç”¨doclingå¤„ç†
è¿™è§£å†³äº†é¡µé¢æ ‡æ³¨æ¼‚ç§»é—®é¢˜ï¼Œç¡®ä¿æ¯é¡µçš„å¤„ç†éƒ½æ˜¯ç‹¬ç«‹å’Œå‡†ç¡®çš„
"""

import os
import tempfile
import shutil
import multiprocessing
from typing import List, Dict, Tuple, Optional, Any
from pathlib import Path
import asyncio
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed
import time

from .config import PDFProcessingConfig
from .data_models import PageData, ImageWithContext, TableWithContext
from .media_extractor import MediaExtractor

# å¯¼å…¥PDFå¤„ç†åº“
try:
    import fitz  # PyMuPDF
    FITZ_AVAILABLE = True
    print("âœ… PyMuPDF (fitz) å¯ç”¨")
except ImportError:
    FITZ_AVAILABLE = False
    print("âŒ PyMuPDF (fitz) ä¸å¯ç”¨ï¼Œè¯·å®‰è£…: pip install PyMuPDF")

# å¯¼å…¥doclingç»„ä»¶
try:
    from docling.datamodel.base_models import InputFormat
    from docling.datamodel.pipeline_options import PdfPipelineOptions, EasyOcrOptions
    from docling.document_converter import DocumentConverter, PdfFormatOption
    DOCLING_AVAILABLE = True
    print("âœ… Doclingç»„ä»¶å¯ç”¨")
except ImportError as e:
    DOCLING_AVAILABLE = False
    print(f"âŒ Doclingç»„ä»¶ä¸å¯ç”¨: {e}")
    
    # åˆ›å»ºå ä½ç¬¦ç±»å‹
    class DocumentConverter:
        pass
    
    class PdfPipelineOptions:
        pass


class PDFPageSplitter:
    """
    PDFé¡µé¢åˆ†å‰²å™¨
    
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. å°†PDFæŒ‰è‡ªç„¶é¡µé¢åˆ‡å‰²æˆå•é¡µPDFæ–‡ä»¶
    2. æ¯é¡µå•ç‹¬è°ƒç”¨doclingå¤„ç†
    3. æ”¯æŒå¤šç§å¹¶è¡Œå¤„ç†æ¨¡å¼ï¼ˆçº¿ç¨‹æ± /è¿›ç¨‹æ± ï¼‰
    4. åˆå¹¶æ‰€æœ‰é¡µé¢ç»“æœ
    """
    
    def __init__(self, config: Optional[PDFProcessingConfig] = None, use_process_pool: bool = True):
        """
        åˆå§‹åŒ–PDFé¡µé¢åˆ†å‰²å™¨
        
        Args:
            config: PDFå¤„ç†é…ç½®
            use_process_pool: æ˜¯å¦ä½¿ç”¨è¿›ç¨‹æ± ï¼ˆæ¨èç”¨äºCPUå¯†é›†å‹ä»»åŠ¡ï¼‰
        """
        self.config = config or PDFProcessingConfig()
        self.use_process_pool = use_process_pool
        self.doc_converter = None
        self.media_extractor = MediaExtractor()
        
        if not FITZ_AVAILABLE:
            raise RuntimeError("PyMuPDFä¸å¯ç”¨ï¼Œæ— æ³•è¿›è¡Œé¡µé¢åˆ†å‰²")
        
        if not DOCLING_AVAILABLE:
            raise RuntimeError("Doclingä¸å¯ç”¨ï¼Œæ— æ³•è¿›è¡Œé¡µé¢å¤„ç†")
        
        self._init_docling_converter()
    
    def _init_docling_converter(self) -> None:
        """åˆå§‹åŒ–Doclingè½¬æ¢å™¨"""
        try:
            # è®¾ç½®æœ¬åœ°æ¨¡å‹è·¯å¾„
            models_cache_dir = Path("models_cache")
            artifacts_path = None
            if models_cache_dir.exists():
                artifacts_path = str(models_cache_dir.absolute())
            elif self.config.docling.artifacts_path:
                artifacts_path = self.config.docling.artifacts_path
            
            # åˆ›å»ºOCRé€‰é¡¹
            ocr_options = EasyOcrOptions() if self.config.docling.ocr_enabled else None
            
            # åˆ›å»ºç®¡é“é€‰é¡¹
            pipeline_options = PdfPipelineOptions(
                ocr_options=ocr_options,
                artifacts_path=artifacts_path
            )
            
            # è®¾ç½®è§£æé€‰é¡¹
            pipeline_options.images_scale = self.config.docling.images_scale
            pipeline_options.generate_page_images = self.config.docling.generate_page_images
            pipeline_options.generate_picture_images = self.config.docling.generate_picture_images
            
            # åˆ›å»ºæ–‡æ¡£è½¬æ¢å™¨
            self.doc_converter = DocumentConverter(
                format_options={
                    InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)
                }
            )
            
            print("âœ… Doclingè½¬æ¢å™¨åˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            print(f"âŒ Doclingè½¬æ¢å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            self.doc_converter = None
    
    def _get_optimal_worker_count(self, total_tasks: int) -> int:
        """
        æ ¹æ®ä»»åŠ¡æ•°é‡å’Œç³»ç»Ÿé…ç½®è®¡ç®—æœ€ä¼˜workeræ•°é‡
        
        Args:
            total_tasks: æ€»ä»»åŠ¡æ•°é‡
            
        Returns:
            int: æœ€ä¼˜workeræ•°é‡
        """
        if self.use_process_pool:
            # è¿›ç¨‹æ± ï¼šè€ƒè™‘CPUæ ¸å¿ƒæ•°ï¼Œä½†ä¸è¶…è¿‡ä»»åŠ¡æ•°
            cpu_count = multiprocessing.cpu_count()
            # ä¸ºç³»ç»Ÿä¿ç•™1ä¸ªæ ¸å¿ƒï¼Œé¿å…ç³»ç»Ÿå¡é¡¿
            max_workers = max(1, cpu_count - 1)
        else:
            # çº¿ç¨‹æ± ï¼šå¯ä»¥è®¾ç½®æ›´å¤šçº¿ç¨‹ï¼Œå› ä¸ºdoclingæœ‰I/Oç­‰å¾…
            max_workers = self.config.media_extractor.max_workers
        
        # ä¸è¶…è¿‡ä»»åŠ¡æ•°é‡å’Œé…ç½®çš„æœ€å¤§å€¼
        configured_max = self.config.media_extractor.max_workers
        optimal_workers = min(max_workers, total_tasks, configured_max)
        
        print(f"ğŸ’» ç³»ç»Ÿé…ç½®: CPUæ ¸å¿ƒæ•°={multiprocessing.cpu_count()}, ä½¿ç”¨{'è¿›ç¨‹æ± ' if self.use_process_pool else 'çº¿ç¨‹æ± '}")
        print(f"âš™ï¸ å·¥ä½œçº¿ç¨‹æ•°: {optimal_workers} (æ€»ä»»åŠ¡: {total_tasks}, é…ç½®ä¸Šé™: {configured_max})")
        
        return optimal_workers

    def split_and_process_pdf(self, pdf_path: str, output_dir: str) -> List[PageData]:
        """
        åˆ†å‰²PDFå¹¶å¤„ç†æ¯ä¸€é¡µ
        
        Args:
            pdf_path: PDFæ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•
            
        Returns:
            List[PageData]: æ‰€æœ‰é¡µé¢çš„å¤„ç†ç»“æœ
        """
        if not os.path.exists(pdf_path):
            raise FileNotFoundError(f"PDFæ–‡ä»¶ä¸å­˜åœ¨: {pdf_path}")
        
        print(f"ğŸ”„ å¼€å§‹åˆ†å‰²å’Œå¤„ç†PDF: {pdf_path}")
        start_time = time.time()
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)
        
        # æ­¥éª¤1: åˆ†å‰²PDFä¸ºå•é¡µæ–‡ä»¶
        single_page_files = self._split_pdf_to_pages(pdf_path)
        print(f"ğŸ“„ PDFåˆ†å‰²å®Œæˆï¼Œå…± {len(single_page_files)} é¡µ")
        
        try:
            # æ­¥éª¤2: å¹¶è¡Œå¤„ç†æ‰€æœ‰é¡µé¢
            if self.config.media_extractor.parallel_processing:
                pages_data = self._process_pages_parallel(single_page_files, output_dir)
            else:
                pages_data = self._process_pages_sequential(single_page_files, output_dir)
            
            # æ­¥éª¤3: æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            self._cleanup_temp_files(single_page_files)
            
            end_time = time.time()
            processing_time = end_time - start_time
            
            print(f"âœ… PDFå¤„ç†å®Œæˆï¼Œè€—æ—¶: {processing_time:.2f} ç§’")
            print(f"ğŸ“Š æˆåŠŸå¤„ç† {len(pages_data)} é¡µ")
            
            return pages_data
            
        except Exception as e:
            # ç¡®ä¿æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            self._cleanup_temp_files(single_page_files)
            raise e
    
    def _split_pdf_to_pages(self, pdf_path: str) -> List[Tuple[int, str]]:
        """
        å°†PDFåˆ†å‰²ä¸ºå•é¡µæ–‡ä»¶
        
        Args:
            pdf_path: PDFæ–‡ä»¶è·¯å¾„
            
        Returns:
            List[Tuple[int, str]]: [(é¡µç , å•é¡µPDFæ–‡ä»¶è·¯å¾„), ...]
        """
        doc = fitz.open(pdf_path)
        total_pages = len(doc)
        
        # åˆ›å»ºä¸´æ—¶ç›®å½•
        temp_dir = tempfile.mkdtemp(prefix="pdf_pages_")
        single_page_files = []
        
        try:
            for page_num in range(total_pages):
                # åˆ›å»ºæ–°çš„PDFæ–‡æ¡£ï¼ŒåªåŒ…å«å½“å‰é¡µ
                single_page_doc = fitz.open()
                single_page_doc.insert_pdf(doc, from_page=page_num, to_page=page_num)
                
                # ä¿å­˜å•é¡µPDF
                single_page_path = os.path.join(temp_dir, f"page_{page_num + 1}.pdf")
                single_page_doc.save(single_page_path)
                single_page_doc.close()
                
                single_page_files.append((page_num + 1, single_page_path))
                
        finally:
            doc.close()
        
        return single_page_files
    
    def _process_pages_parallel(self, 
                               single_page_files: List[Tuple[int, str]], 
                               output_dir: str) -> List[PageData]:
        """å¹¶è¡Œå¤„ç†æ‰€æœ‰é¡µé¢ï¼ˆæ”¯æŒçº¿ç¨‹æ± å’Œè¿›ç¨‹æ± ï¼‰"""
        
        # è®¡ç®—æœ€ä¼˜workeræ•°é‡
        optimal_workers = self._get_optimal_worker_count(len(single_page_files))
        
        print(f"âš¡ å¯ç”¨å¹¶è¡Œå¤„ç†æ¨¡å¼: {'è¿›ç¨‹æ± ' if self.use_process_pool else 'çº¿ç¨‹æ± '}")
        print(f"ğŸ”§ å·¥ä½œè¿›ç¨‹/çº¿ç¨‹æ•°: {optimal_workers}")
        
        pages_data = [None] * len(single_page_files)
        
        # é€‰æ‹©æ‰§è¡Œå™¨ç±»å‹
        executor_class = ProcessPoolExecutor if self.use_process_pool else ThreadPoolExecutor
        
        try:
            with executor_class(max_workers=optimal_workers) as executor:
                # æäº¤æ‰€æœ‰ä»»åŠ¡
                if self.use_process_pool:
                    # è¿›ç¨‹æ± ï¼šéœ€è¦ä¼ é€’å¯åºåˆ—åŒ–çš„å‚æ•°
                    future_to_page = {
                        executor.submit(
                            _process_single_page_static,
                            page_num, 
                            single_page_path, 
                            output_dir,
                            self.config  # ä¼ é€’é…ç½®å¯¹è±¡
                        ): page_num
                        for page_num, single_page_path in single_page_files
                    }
                else:
                    # çº¿ç¨‹æ± ï¼šå¯ä»¥ä½¿ç”¨å®ä¾‹æ–¹æ³•
                    future_to_page = {
                        executor.submit(
                            self._process_single_page, 
                            page_num, 
                            single_page_path, 
                            output_dir
                        ): page_num
                        for page_num, single_page_path in single_page_files
                    }
                
                # æ”¶é›†ç»“æœ
                completed_count = 0
                for future in as_completed(future_to_page):
                    page_num = future_to_page[future]
                    try:
                        page_data = future.result()
                        pages_data[page_num - 1] = page_data  # é¡µç ä»1å¼€å§‹ï¼Œç´¢å¼•ä»0å¼€å§‹
                        completed_count += 1
                        print(f"âœ… é¡µé¢ {page_num} å¤„ç†å®Œæˆ ({completed_count}/{len(single_page_files)})")
                    except Exception as e:
                        print(f"âŒ é¡µé¢ {page_num} å¤„ç†å¤±è´¥: {e}")
                        # åˆ›å»ºç©ºçš„é¡µé¢æ•°æ®ä½œä¸ºfallback
                        pages_data[page_num - 1] = PageData(
                            page_number=page_num,
                            raw_text=f"é¡µé¢ {page_num} å¤„ç†å¤±è´¥: {str(e)}",
                            images=[],
                            tables=[]
                        )
                        completed_count += 1
                        
        except Exception as e:
            print(f"âŒ å¹¶è¡Œå¤„ç†æ‰§è¡Œå™¨åˆ›å»ºå¤±è´¥: {e}")
            # å›é€€åˆ°ä¸²è¡Œå¤„ç†
            print("ğŸ”„ å›é€€åˆ°ä¸²è¡Œå¤„ç†æ¨¡å¼...")
            return self._process_pages_sequential(single_page_files, output_dir)
        
        # è¿‡æ»¤Noneå€¼
        successful_pages = [page for page in pages_data if page is not None]
        print(f"ğŸ“Š å¹¶è¡Œå¤„ç†å®Œæˆ: {len(successful_pages)}/{len(single_page_files)} é¡µé¢æˆåŠŸå¤„ç†")
        return successful_pages
    
    def _process_pages_sequential(self, 
                                 single_page_files: List[Tuple[int, str]], 
                                 output_dir: str) -> List[PageData]:
        """é¡ºåºå¤„ç†æ‰€æœ‰é¡µé¢"""
        print("ğŸ”„ ä½¿ç”¨é¡ºåºå¤„ç†æ¨¡å¼")
        
        pages_data = []
        for page_num, single_page_path in single_page_files:
            try:
                page_data = self._process_single_page(page_num, single_page_path, output_dir)
                pages_data.append(page_data)
                print(f"âœ… é¡µé¢ {page_num} å¤„ç†å®Œæˆ")
            except Exception as e:
                print(f"âŒ é¡µé¢ {page_num} å¤„ç†å¤±è´¥: {e}")
                # åˆ›å»ºç©ºçš„é¡µé¢æ•°æ®
                pages_data.append(PageData(
                    page_number=page_num,
                    raw_text=f"é¡µé¢ {page_num} å¤„ç†å¤±è´¥: {str(e)}",
                    images=[],
                    tables=[]
                ))
        
        return pages_data
    
    def _process_single_page(self, 
                            page_num: int, 
                            single_page_path: str, 
                            output_dir: str) -> PageData:
        """
        å¤„ç†å•é¡µPDF
        
        Args:
            page_num: é¡µç 
            single_page_path: å•é¡µPDFæ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•
            
        Returns:
            PageData: é¡µé¢æ•°æ®
        """
        # åˆ›å»ºé¡µé¢ä¸“ç”¨çš„è¾“å‡ºç›®å½•
        page_output_dir = os.path.join(output_dir, f"page_{page_num}")
        os.makedirs(page_output_dir, exist_ok=True)
        
        # ä½¿ç”¨Doclingå¤„ç†å•é¡µPDF
        raw_result = self.doc_converter.convert(Path(single_page_path))
        
        # æå–é¡µé¢æ–‡æœ¬
        page_text = self._extract_page_text(raw_result)
        
        # åˆ›å»ºé¡µé¢æ•°æ®
        page_data = PageData(
            page_number=page_num,
            raw_text=page_text,
            images=[],
            tables=[]
        )
        
        # æå–å›¾ç‰‡å’Œè¡¨æ ¼ - ç”±äºæ˜¯å•é¡µPDFï¼Œæ‰€æœ‰åª’ä½“éƒ½å±äºå½“å‰é¡µ
        self._extract_media_for_single_page(raw_result, page_data, page_output_dir)
        
        return page_data
    
    def _extract_page_text(self, raw_result: Any) -> str:
        """ä»å•é¡µPDFçš„doclingç»“æœä¸­æå–æ–‡æœ¬"""
        try:
            # å¯¼å‡ºä¸ºmarkdownæ ¼å¼
            raw_markdown = raw_result.document.export_to_markdown()
            
            # æ¸…ç†markdownå†…å®¹
            import re
            markdown_clean_pattern = re.compile(r"<!--[\s\S]*?-->")
            cleaned_text = markdown_clean_pattern.sub("", raw_markdown)
            
            return cleaned_text.strip()
            
        except Exception as e:
            print(f"âš ï¸ é¡µé¢æ–‡æœ¬æå–å¤±è´¥: {e}")
            return ""
    
    def _extract_media_for_single_page(self, 
                                      raw_result: Any, 
                                      page_data: PageData, 
                                      page_output_dir: str):
        """ä¸ºå•é¡µPDFæå–å›¾ç‰‡å’Œè¡¨æ ¼"""
        try:
            # ç”±äºæ˜¯å•é¡µPDFï¼Œæ‰€æœ‰åª’ä½“éƒ½å±äºå½“å‰é¡µ
            image_counter = 0
            table_counter = 0
            
            # æå–å›¾ç‰‡
            for picture in raw_result.document.pictures:
                image_counter += 1
                try:
                    # è·å–å›¾ç‰‡
                    picture_image = picture.get_image(raw_result.document)
                    if picture_image is None:
                        continue
                    
                    # ä¿å­˜å›¾ç‰‡
                    image_filename = f"picture-{image_counter}.png"
                    image_path = os.path.join(page_output_dir, image_filename)
                    with open(image_path, "wb") as fp:
                        picture_image.save(fp, "PNG")
                    
                    # è·å–å›¾ç‰‡ä¿¡æ¯
                    from PIL import Image
                    image_img = Image.open(image_path)
                    caption = picture.caption_text(raw_result.document) if hasattr(picture, 'caption_text') else ""
                    
                    # åˆ›å»ºImageWithContextå¯¹è±¡
                    image_with_context = ImageWithContext(
                        image_path=image_path,
                        page_number=page_data.page_number,
                        page_context=page_data.raw_text,
                        caption=caption or f"å›¾ç‰‡ {image_counter}",
                        metadata={
                            'width': image_img.width,
                            'height': image_img.height,
                            'size': image_img.width * image_img.height,
                            'aspect_ratio': image_img.width / image_img.height
                        }
                    )
                    
                    page_data.images.append(image_with_context)
                    
                except Exception as e:
                    print(f"âŒ é¡µé¢ {page_data.page_number} å›¾ç‰‡ {image_counter} å¤„ç†å¤±è´¥: {e}")
            
            # æå–è¡¨æ ¼
            for table in raw_result.document.tables:
                table_counter += 1
                try:
                    # è·å–è¡¨æ ¼å›¾ç‰‡
                    table_image = table.get_image(raw_result.document)
                    if table_image is None:
                        continue
                    
                    # ä¿å­˜è¡¨æ ¼å›¾ç‰‡
                    table_filename = f"table-{table_counter}.png"
                    table_path = os.path.join(page_output_dir, table_filename)
                    with open(table_path, "wb") as fp:
                        table_image.save(fp, "PNG")
                    
                    # è·å–è¡¨æ ¼ä¿¡æ¯
                    from PIL import Image
                    table_img = Image.open(table_path)
                    caption = table.caption_text(raw_result.document) if hasattr(table, 'caption_text') else ""
                    
                    # åˆ›å»ºTableWithContextå¯¹è±¡
                    table_with_context = TableWithContext(
                        table_path=table_path,
                        page_number=page_data.page_number,
                        page_context=page_data.raw_text,
                        caption=caption or f"è¡¨æ ¼ {table_counter}",
                        metadata={
                            'width': table_img.width,
                            'height': table_img.height,
                            'size': table_img.width * table_img.height,
                            'aspect_ratio': table_img.width / table_img.height
                        }
                    )
                    
                    page_data.tables.append(table_with_context)
                    
                except Exception as e:
                    print(f"âŒ é¡µé¢ {page_data.page_number} è¡¨æ ¼ {table_counter} å¤„ç†å¤±è´¥: {e}")
            
            print(f"ğŸ“Š é¡µé¢ {page_data.page_number}: {len(page_data.images)} ä¸ªå›¾ç‰‡, {len(page_data.tables)} ä¸ªè¡¨æ ¼")
            
        except Exception as e:
            print(f"âŒ é¡µé¢ {page_data.page_number} åª’ä½“æå–å¤±è´¥: {e}")
    
    def _cleanup_temp_files(self, single_page_files: List[Tuple[int, str]]):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        if not single_page_files:
            return
        
        # è·å–ä¸´æ—¶ç›®å½•
        temp_dir = os.path.dirname(single_page_files[0][1])
        
        try:
            shutil.rmtree(temp_dir)
            print(f"ğŸ§¹ æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {temp_dir}")
        except Exception as e:
            print(f"âš ï¸ æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")
    
    def get_pdf_info(self, pdf_path: str) -> Dict[str, Any]:
        """
        è·å–PDFåŸºæœ¬ä¿¡æ¯
        
        Args:
            pdf_path: PDFæ–‡ä»¶è·¯å¾„
            
        Returns:
            Dict[str, Any]: PDFä¿¡æ¯
        """
        if not os.path.exists(pdf_path):
            raise FileNotFoundError(f"PDFæ–‡ä»¶ä¸å­˜åœ¨: {pdf_path}")
        
        doc = fitz.open(pdf_path)
        
        try:
            info = {
                "file_path": pdf_path,
                "file_name": os.path.basename(pdf_path),
                "file_size": os.path.getsize(pdf_path),
                "total_pages": len(doc),
                "metadata": doc.metadata,
                "processing_config": {
                    "parallel_processing": self.config.parallel_processing,
                    "max_workers": self.config.max_workers,
                    "images_scale": self.config.docling.images_scale,
                    "ocr_enabled": self.config.docling.ocr_enabled
                }
            }
            
            return info
            
        finally:
            doc.close() 


def _process_single_page_static(page_num: int, 
                               single_page_path: str, 
                               output_dir: str,
                               config: PDFProcessingConfig) -> PageData:
    """
    å¤„ç†å•é¡µPDFçš„é™æ€å‡½æ•°ï¼ˆç”¨äºè¿›ç¨‹æ± ï¼‰
    
    Args:
        page_num: é¡µç 
        single_page_path: å•é¡µPDFæ–‡ä»¶è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•
        config: PDFå¤„ç†é…ç½®
        
    Returns:
        PageData: é¡µé¢æ•°æ®
    """
    try:
        # åœ¨è¿›ç¨‹å†…åˆå§‹åŒ–doclingè½¬æ¢å™¨
        from docling.datamodel.base_models import InputFormat
        from docling.datamodel.pipeline_options import PdfPipelineOptions, EasyOcrOptions
        from docling.document_converter import DocumentConverter, PdfFormatOption
        
        # è®¾ç½®æœ¬åœ°æ¨¡å‹è·¯å¾„
        models_cache_dir = Path("models_cache")
        artifacts_path = None
        if models_cache_dir.exists():
            artifacts_path = str(models_cache_dir.absolute())
        elif config.docling.artifacts_path:
            artifacts_path = config.docling.artifacts_path
        
        # åˆ›å»ºOCRé€‰é¡¹
        ocr_options = EasyOcrOptions() if config.docling.ocr_enabled else None
        
        # åˆ›å»ºç®¡é“é€‰é¡¹
        pipeline_options = PdfPipelineOptions(
            ocr_options=ocr_options,
            artifacts_path=artifacts_path
        )
        
        # è®¾ç½®è§£æé€‰é¡¹
        pipeline_options.images_scale = config.docling.images_scale
        pipeline_options.generate_page_images = config.docling.generate_page_images
        pipeline_options.generate_picture_images = config.docling.generate_picture_images
        
        # åˆ›å»ºæ–‡æ¡£è½¬æ¢å™¨
        doc_converter = DocumentConverter(
            format_options={
                InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)
            }
        )
        
        # åˆ›å»ºé¡µé¢ä¸“ç”¨çš„è¾“å‡ºç›®å½•
        page_output_dir = os.path.join(output_dir, f"page_{page_num}")
        os.makedirs(page_output_dir, exist_ok=True)
        
        # ä½¿ç”¨Doclingå¤„ç†å•é¡µPDF
        raw_result = doc_converter.convert(Path(single_page_path))
        
        # æå–é¡µé¢æ–‡æœ¬
        try:
            raw_markdown = raw_result.document.export_to_markdown()
            page_text = raw_markdown
        except Exception as e:
            print(f"âš ï¸ é¡µé¢ {page_num} æ–‡æœ¬æå–å¤±è´¥: {e}")
            page_text = f"é¡µé¢ {page_num} æ–‡æœ¬æå–å¤±è´¥"
        
        # åˆ›å»ºé¡µé¢æ•°æ®
        page_data = PageData(
            page_number=page_num,
            raw_text=page_text,
            images=[],
            tables=[]
        )
        
        # ç®€åŒ–çš„åª’ä½“æå–ï¼ˆè¿›ç¨‹æ± ç‰ˆæœ¬ï¼‰
        try:
            # ç›´æ¥ä½¿ç”¨doclingç»“æœä¸­çš„å›¾ç‰‡å’Œè¡¨æ ¼ä¿¡æ¯
            if hasattr(raw_result.document, 'pictures'):
                for i, picture in enumerate(raw_result.document.pictures):
                    try:
                        # ä¿å­˜å›¾ç‰‡
                        image_filename = f"page_{page_num}_image_{i+1}.png"
                        image_path = os.path.join(page_output_dir, image_filename)
                        
                        # åˆ›å»ºå›¾ç‰‡ä¸Šä¸‹æ–‡å¯¹è±¡
                        image_with_context = ImageWithContext(
                            image_path=image_path,
                            page_number=page_num,
                            page_context=page_text,
                            ai_description=None,
                            caption=getattr(picture, 'caption', None)
                        )
                        
                        page_data.images.append(image_with_context)
                    except Exception as e:
                        print(f"âš ï¸ é¡µé¢ {page_num} å›¾ç‰‡ {i+1} å¤„ç†å¤±è´¥: {e}")
            
            if hasattr(raw_result.document, 'tables'):
                for i, table in enumerate(raw_result.document.tables):
                    try:
                        # ä¿å­˜è¡¨æ ¼
                        table_filename = f"page_{page_num}_table_{i+1}.csv"
                        table_path = os.path.join(page_output_dir, table_filename)
                        
                        # åˆ›å»ºè¡¨æ ¼ä¸Šä¸‹æ–‡å¯¹è±¡
                        table_with_context = TableWithContext(
                            table_path=table_path,
                            page_number=page_num,
                            page_context=page_text,
                            ai_description=None,
                            caption=getattr(table, 'caption', None)
                        )
                        
                        page_data.tables.append(table_with_context)
                    except Exception as e:
                        print(f"âš ï¸ é¡µé¢ {page_num} è¡¨æ ¼ {i+1} å¤„ç†å¤±è´¥: {e}")
                        
        except Exception as e:
            print(f"âš ï¸ é¡µé¢ {page_num} åª’ä½“æå–å¤±è´¥: {e}")
        
        return page_data
        
    except Exception as e:
        print(f"âŒ é™æ€å‡½æ•°å¤„ç†é¡µé¢ {page_num} å¤±è´¥: {e}")
        # è¿”å›å¤±è´¥çš„é¡µé¢æ•°æ®
        return PageData(
            page_number=page_num,
            raw_text=f"é¡µé¢ {page_num} å¤„ç†å¤±è´¥: {str(e)}",
            images=[],
            tables=[]
        ) 