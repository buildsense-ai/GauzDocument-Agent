#!/usr/bin/env python3
"""
ç®€åŒ–çš„metadataæµ‹è¯•è„šæœ¬
ç›´æ¥éªŒè¯ä¿®å¤åçš„å­—æ®µæå–åŠŸèƒ½
"""

import json
import os

def test_field_extraction():
    """æµ‹è¯•å­—æ®µæå–åŠŸèƒ½"""
    
    print("ğŸ”§ æµ‹è¯•å›¾ç‰‡/è¡¨æ ¼metadataå­—æ®µæå–...")
    
    # æµ‹è¯•æ•°æ®æ–‡ä»¶
    page_split_file = "parser_output/20250715_131307_page_split/page_split_processing_result.json"
    
    if not os.path.exists(page_split_file):
        print(f"âŒ æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {page_split_file}")
        return
    
    # è¯»å–åŸå§‹æ•°æ®
    with open(page_split_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ")
    print(f"ğŸ“„ æ€»é¡µæ•°: {len(data.get('pages', []))}")
    
    # ç»Ÿè®¡å›¾ç‰‡å’Œè¡¨æ ¼
    total_images = 0
    total_tables = 0
    
    for page_num, page_data in enumerate(data.get("pages", []), 1):
        images = page_data.get("images", [])
        tables = page_data.get("tables", [])
        
        total_images += len(images)
        total_tables += len(tables)
        
        # æµ‹è¯•ç¬¬ä¸€ä¸ªå›¾ç‰‡çš„å­—æ®µæå–
        if images and total_images == 1:
            first_image = images[0]
            print(f"\nğŸ–¼ï¸ ç¬¬ä¸€ä¸ªå›¾ç‰‡å­—æ®µéªŒè¯:")
            print(f"   image_path: {first_image.get('image_path', 'MISSING')}")
            print(f"   page_number: {first_image.get('page_number', 'MISSING')}")
            print(f"   ai_description: {first_image.get('ai_description', 'MISSING')}")
            
            metadata = first_image.get("metadata", {})
            print(f"   metadata.width: {metadata.get('width', 'MISSING')}")
            print(f"   metadata.height: {metadata.get('height', 'MISSING')}")
            print(f"   metadata.size: {metadata.get('size', 'MISSING')}")
            print(f"   metadata.aspect_ratio: {metadata.get('aspect_ratio', 'MISSING')}")
        
        # æµ‹è¯•ç¬¬ä¸€ä¸ªè¡¨æ ¼çš„å­—æ®µæå–
        if tables and total_tables == 1:
            first_table = tables[0]
            print(f"\nğŸ“Š ç¬¬ä¸€ä¸ªè¡¨æ ¼å­—æ®µéªŒè¯:")
            print(f"   table_path: {first_table.get('table_path', 'MISSING')}")
            print(f"   page_number: {first_table.get('page_number', 'MISSING')}")
            print(f"   ai_description: {first_table.get('ai_description', 'MISSING')}")
            
            metadata = first_table.get("metadata", {})
            print(f"   metadata.width: {metadata.get('width', 'MISSING')}")
            print(f"   metadata.height: {metadata.get('height', 'MISSING')}")
            print(f"   metadata.size: {metadata.get('size', 'MISSING')}")
            print(f"   metadata.aspect_ratio: {metadata.get('aspect_ratio', 'MISSING')}")
    
    print(f"\nğŸ“Š ç»Ÿè®¡ç»“æœ:")
    print(f"   æ€»å›¾ç‰‡æ•°: {total_images}")
    print(f"   æ€»è¡¨æ ¼æ•°: {total_tables}")

def test_stitch_text_with_ids():
    """æµ‹è¯•åŒ…å«IDçš„æ–‡æœ¬ç¼åˆåŠŸèƒ½"""
    
    print("\nğŸ§µ æµ‹è¯•æ–‡æœ¬ç¼åˆåŠŸèƒ½...")
    
    page_split_file = "parser_output/20250715_131307_page_split/page_split_processing_result.json"
    
    if not os.path.exists(page_split_file):
        print(f"âŒ æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {page_split_file}")
        return
    
    with open(page_split_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    pages = data.get('pages', [])
    full_text_parts = []
    
    # å…¨å±€è®¡æ•°å™¨ï¼Œç”¨äºç”Ÿæˆå”¯ä¸€ID
    global_image_counter = 0
    global_table_counter = 0
    
    for page in pages:
        cleaned_text = page.get('cleaned_text', '') or ''
        images = page.get('images', [])
        tables = page.get('tables', [])
        
        # æ·»åŠ é¡µé¢æ–‡æœ¬
        if cleaned_text and cleaned_text.strip():
            full_text_parts.append(cleaned_text.strip())
        
        # æ·»åŠ å›¾ç‰‡æè¿°ï¼ˆåŒ…å«å”¯ä¸€æ ‡è¯†ç¬¦ï¼‰
        for image in images:
            global_image_counter += 1
            description = image.get('ai_description', 'å›¾ç‰‡æè¿°') or 'å›¾ç‰‡æè¿°'
            image_path = image.get('image_path', '')
            # æ ¼å¼ï¼š[å›¾ç‰‡|ID:xxx|PATH:xxx: æè¿°]
            full_text_parts.append(f"[å›¾ç‰‡|ID:{global_image_counter}|PATH:{image_path}: {description}]")
        
        # æ·»åŠ è¡¨æ ¼æè¿°ï¼ˆåŒ…å«å”¯ä¸€æ ‡è¯†ç¬¦ï¼‰
        for table in tables:
            global_table_counter += 1
            description = table.get('ai_description', 'è¡¨æ ¼æè¿°') or 'è¡¨æ ¼æè¿°'
            table_path = table.get('table_path', '')
            # æ ¼å¼ï¼š[è¡¨æ ¼|ID:xxx|PATH:xxx: æè¿°]
            full_text_parts.append(f"[è¡¨æ ¼|ID:{global_table_counter}|PATH:{table_path}: {description}]")
    
    # ç”¨åŒæ¢è¡Œè¿æ¥ï¼Œä¿æŒæ®µè½åˆ†éš”
    full_text = "\n\n".join(full_text_parts)
    
    print(f"âœ… æ–‡æœ¬ç¼åˆå®Œæˆï¼Œæ€»é•¿åº¦: {len(full_text)} å­—ç¬¦")
    print(f"ğŸ–¼ï¸ åŒ…å«å›¾ç‰‡: {global_image_counter} ä¸ª")
    print(f"ğŸ“Š åŒ…å«è¡¨æ ¼: {global_table_counter} ä¸ª")
    
    # éªŒè¯æ–°æ ¼å¼çš„å¼•ç”¨
    import re
    image_refs = re.findall(r'\[å›¾ç‰‡\|ID:(\d+)\|PATH:([^:]+):', full_text)
    table_refs = re.findall(r'\[è¡¨æ ¼\|ID:(\d+)\|PATH:([^:]+):', full_text)
    
    print(f"ğŸ” å‘ç°å›¾ç‰‡å¼•ç”¨: {len(image_refs)} ä¸ª")
    print(f"ğŸ” å‘ç°è¡¨æ ¼å¼•ç”¨: {len(table_refs)} ä¸ª")
    
    if image_refs:
        print(f"   ç¤ºä¾‹å›¾ç‰‡å¼•ç”¨: ID={image_refs[0][0]}, PATH={os.path.basename(image_refs[0][1])}")
    if table_refs:
        print(f"   ç¤ºä¾‹è¡¨æ ¼å¼•ç”¨: ID={table_refs[0][0]}, PATH={os.path.basename(table_refs[0][1])}")
    
    # ä¿å­˜æµ‹è¯•ç»“æœ
    output_file = "parser_output/full_text_with_ids.txt"
    os.makedirs(os.path.dirname(output_file), exist_ok=True)
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(full_text)
    
    print(f"ğŸ’¾ å¸¦IDçš„å®Œæ•´æ–‡æœ¬å·²ä¿å­˜åˆ°: {output_file}")

if __name__ == "__main__":
    test_field_extraction()
    test_stitch_text_with_ids()
    print("\nâœ… ç®€åŒ–æµ‹è¯•å®Œæˆ!") 